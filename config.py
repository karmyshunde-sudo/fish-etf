#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é…ç½®æ¨¡å—
æä¾›é¡¹ç›®å…¨å±€é…ç½®å‚æ•°ï¼ŒåŒ…æ‹¬è·¯å¾„ã€æ—¥å¿—ã€ç­–ç•¥å‚æ•°ç­‰
ç‰¹åˆ«ä¼˜åŒ–äº†æ—¶åŒºç›¸å…³é…ç½®ï¼Œç¡®ä¿æ‰€æœ‰æ—¶é—´æ˜¾ç¤ºä¸ºåŒ—äº¬æ—¶é—´
"""

import os
import logging
import sys
from typing import Dict, Any, Optional
from pathlib import Path
from datetime import datetime, timezone, timedelta

# å…ˆå®šä¹‰è·å–åŸºç¡€ç›®å½•çš„å‡½æ•°ï¼Œé¿å…ç±»å®šä¹‰æ—¶çš„å¾ªç¯å¼•ç”¨é—®é¢˜
def _get_base_dir() -> str:
    """è·å–é¡¹ç›®æ ¹ç›®å½•è·¯å¾„"""
    try:
        # ä¼˜å…ˆä½¿ç”¨GITHUB_WORKSPACEç¯å¢ƒå˜é‡ï¼ˆGitHub Actionsç¯å¢ƒï¼‰
        base_dir = os.environ.get('GITHUB_WORKSPACE')
        if base_dir and os.path.exists(base_dir):
            return os.path.abspath(base_dir)
        
        # å°è¯•åŸºäºå½“å‰æ–‡ä»¶ä½ç½®è®¡ç®—é¡¹ç›®æ ¹ç›®å½•
        current_file_path = os.path.abspath(__file__)
        base_dir = os.path.dirname(os.path.dirname(current_file_path))
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        if os.path.exists(base_dir):
            return os.path.abspath(base_dir)
        
        # ä½œä¸ºæœ€åæ‰‹æ®µï¼Œä½¿ç”¨å½“å‰å·¥ä½œç›®å½•
        return os.path.abspath(os.getcwd())
    except Exception as e:
        print(f"è·å–é¡¹ç›®æ ¹ç›®å½•å¤±è´¥: {str(e)}", file=sys.stderr)
        # é€€å›åˆ°å½“å‰å·¥ä½œç›®å½•
        return os.path.abspath(os.getcwd())

class Config:
    """
    å…¨å±€é…ç½®ç±»ï¼šæ•°æ®æºé…ç½®ã€ç­–ç•¥å‚æ•°ã€æ–‡ä»¶è·¯å¾„ç®¡ç†
    æ‰€æœ‰é…ç½®é¡¹å‡æœ‰é»˜è®¤å€¼ï¼Œå¹¶æ”¯æŒä»ç¯å¢ƒå˜é‡è¦†ç›–
    """
    
    # -------------------------
    # 1. æ•°æ®æºé…ç½®
    # -------------------------
    # åˆæ¬¡çˆ¬å–é»˜è®¤æ—¶é—´èŒƒå›´ï¼ˆ1å¹´ï¼‰
    INITIAL_CRAWL_DAYS: int = 365

    # ETFåˆ—è¡¨æ›´æ–°é—´éš”ï¼ˆå¤©ï¼‰
    ETF_LIST_UPDATE_INTERVAL: int = 7  
    # æ¯7å¤©æ›´æ–°ä¸€æ¬¡ETFåˆ—è¡¨
    
    # ä¸­æ–‡åˆ—åæ˜ å°„ï¼ˆå›ºåŒ–ï¼Œæ‰€æœ‰æ•°æ®æºç»Ÿä¸€ï¼‰
    STANDARD_COLUMNS: Dict[str, str] = {
        "æ—¥æœŸ": "date",
        "å¼€ç›˜": "open",
        "æ”¶ç›˜": "close",
        "æœ€é«˜": "high",
        "æœ€ä½": "low",
        "æˆäº¤é‡": "volume",
        "æˆäº¤é¢": "amount",
        "æŒ¯å¹…": "amplitude",
        "æ¶¨è·Œå¹…": "pct_change",
        "æ¶¨è·Œé¢": "price_change",
        "æ¢æ‰‹ç‡": "turnover",
        "ETFä»£ç ": "etf_code",
        "ETFåç§°": "etf_name",
        "çˆ¬å–æ—¶é—´": "crawl_time"
    }
    
    # ETFåˆ—è¡¨æ ‡å‡†åˆ—ï¼ˆç¡®ä¿all_etfs.csvå’Œkarmy_etf.csvç»“æ„ä¸€è‡´ï¼‰
    ETF_STANDARD_COLUMNS: list = ["ETFä»£ç ", "ETFåç§°", "å®Œæ•´ä»£ç ", "åŸºé‡‘è§„æ¨¡"]
    
    # æ–°æµªæ•°æ®æºå¤‡ç”¨æ¥å£
    SINA_ETF_HIST_URL: str = "https://finance.sina.com.cn/realstock/company/  {etf_code}/hisdata/klc_kl.js"
    
    # æ‰¹é‡çˆ¬å–æ‰¹æ¬¡å¤§å°
    CRAWL_BATCH_SIZE: int = 50  # æ¯æ‰¹50åªETF

    # -------------------------
    # 2. ç­–ç•¥å‚æ•°é…ç½®
    # -------------------------
    # å¥—åˆ©ç­–ç•¥ï¼šäº¤æ˜“æˆæœ¬ï¼ˆå°èŠ±ç¨0.1%+ä½£é‡‘0.02%ï¼‰
    TRADE_COST_RATE: float = 0.0012  # 0.12%
    
    # å¥—åˆ©é˜ˆå€¼ï¼ˆæ”¶ç›Šç‡è¶…è¿‡è¯¥å€¼æ‰æ¨é€ï¼‰
    ARBITRAGE_PROFIT_THRESHOLD: float = 0.005  # 0.5%
    
    # ç»¼åˆè¯„åˆ†ç­›é€‰é˜ˆå€¼ï¼ˆä»…ä¿ç•™è¯„åˆ†å‰N%çš„ETFï¼‰
    SCORE_TOP_PERCENT: int = 20  # ä¿ç•™å‰20%é«˜åˆ†ETF
    
    # æœ€ä½è§„æ¨¡é˜ˆå€¼ï¼ˆäº¿å…ƒï¼‰
    MIN_ETP_SIZE: float = 10.0  # è§„æ¨¡â‰¥10äº¿
    
    # æœ€ä½æ—¥å‡æˆäº¤é¢é˜ˆå€¼ï¼ˆä¸‡å…ƒï¼‰
    MIN_DAILY_VOLUME: float = 5000.0  # æ—¥å‡æˆäº¤é¢â‰¥5000ä¸‡
    
    # ä»“ä½ç­–ç•¥å‚æ•°ï¼ˆå‡çº¿ç­–ç•¥ï¼‰
    MA_SHORT_PERIOD: int = 5    # çŸ­æœŸå‡çº¿ï¼ˆ5æ—¥ï¼‰
    MA_LONG_PERIOD: int = 20    # é•¿æœŸå‡çº¿ï¼ˆ20æ—¥ï¼‰
    ADD_POSITION_THRESHOLD: float = 0.03  # åŠ ä»“é˜ˆå€¼ï¼ˆæ¶¨å¹…è¶…3%ï¼‰
    STOP_LOSS_THRESHOLD: float = -0.05    # æ­¢æŸé˜ˆå€¼ï¼ˆè·Œå¹…è¶…5%")
    
    # è¯„åˆ†ç»´åº¦æƒé‡
    SCORE_WEIGHTS: Dict[str, float] = {
        'liquidity': 0.20,  # æµåŠ¨æ€§è¯„åˆ†æƒé‡
        'risk': 0.25,       # é£é™©æ§åˆ¶è¯„åˆ†æƒé‡
        'return': 0.25,     # æ”¶ç›Šèƒ½åŠ›è¯„åˆ†æƒé‡
        'premium': 0.15,    # æº¢ä»·ç‡è¯„åˆ†æƒé‡
        'sentiment': 0.15   # æƒ…ç»ªæŒ‡æ ‡è¯„åˆ†æƒé‡
    }
    
    # ä¹°å…¥ä¿¡å·æ¡ä»¶
    BUY_SIGNAL_DAYS: int = 2  # è¿ç»­å‡ å¤©ä¿¡å·æŒç»­æ‰ä¹°å…¥
    
    # æ¢è‚¡æ¡ä»¶
    SWITCH_THRESHOLD: float = 0.3  # æ–°ETFæ¯”åŸETFç»¼åˆè¯„åˆ†é«˜å‡º30%åˆ™æ¢è‚¡

    # -------------------------
    # 3. æ–‡ä»¶è·¯å¾„é…ç½® - åŸºäºä»“åº“æ ¹ç›®å½•çš„è·¯å¾„
    # -------------------------
    # è·å–ä»“åº“æ ¹ç›®å½•ï¼ˆä¼˜å…ˆä½¿ç”¨GITHUB_WORKSPACEç¯å¢ƒå˜é‡ï¼‰
    @staticmethod
    def get_base_dir() -> str:
        """è·å–é¡¹ç›®æ ¹ç›®å½•è·¯å¾„"""
        return _get_base_dir()
    
    # ä¿®å¤ï¼šä½¿ç”¨é™æ€æ–¹æ³•è°ƒç”¨è€Œä¸æ˜¯ç±»æ–¹æ³•è°ƒç”¨
    BASE_DIR: str = _get_base_dir()
    
    # æ•°æ®å­˜å‚¨è·¯å¾„
    DATA_DIR: str = os.path.join(BASE_DIR, "data")
    ETFS_DAILY_DIR: str = os.path.join(DATA_DIR, "etf_daily")
    
    # ETFå…ƒæ•°æ®ï¼ˆè®°å½•æœ€åçˆ¬å–æ—¥æœŸï¼‰
    METADATA_PATH: str = os.path.join(DATA_DIR, "etf_metadata.csv")
    
    # ç­–ç•¥ç»“æœæ ‡è®°ï¼ˆé¿å…å•æ—¥é‡å¤æ¨é€ï¼‰
    FLAG_DIR: str = os.path.join(DATA_DIR, "flags")
    
    # å¥—åˆ©ç»“æœæ ‡è®°æ–‡ä»¶
    @staticmethod
    def get_arbitrage_flag_file(date_str: Optional[str] = None) -> str:
        """è·å–å¥—åˆ©æ ‡è®°æ–‡ä»¶è·¯å¾„"""
        try:
            # å°è¯•ä½¿ç”¨åŒ—äº¬æ—¶é—´
            from utils.date_utils import get_beijing_time
            date = date_str or get_beijing_time().strftime("%Y-%m-%d")
            return os.path.join(Config.FLAG_DIR, f"arbitrage_pushed_{date}.txt")
        except ImportError:
            # å›é€€åˆ°ç®€å•å®ç°ï¼ˆä»…ç”¨äºåˆå§‹åŒ–é˜¶æ®µï¼‰
            date = date_str or datetime.now().strftime("%Y-%m-%d")
            return os.path.join(Config.FLAG_DIR, f"arbitrage_pushed_{date}.txt")
        except Exception as e:
            logging.error(f"è·å–å¥—åˆ©æ ‡è®°æ–‡ä»¶è·¯å¾„å¤±è´¥: {str(e)}", exc_info=True)
            return os.path.join(Config.FLAG_DIR, "arbitrage_pushed_error.txt")
    
    # ä»“ä½ç­–ç•¥ç»“æœæ ‡è®°æ–‡ä»¶
    @staticmethod
    def get_position_flag_file(date_str: Optional[str] = None) -> str:
        """è·å–ä»“ä½æ ‡è®°æ–‡ä»¶è·¯å¾„"""
        try:
            # å°è¯•ä½¿ç”¨åŒ—äº¬æ—¶é—´
            from utils.date_utils import get_beijing_time
            date = date_str or get_beijing_time().strftime("%Y-%m-%d")
            return os.path.join(Config.FLAG_DIR, f"position_pushed_{date}.txt")
        except ImportError:
            # å›é€€åˆ°ç®€å•å®ç°ï¼ˆä»…ç”¨äºåˆå§‹åŒ–é˜¶æ®µï¼‰
            date = date_str or datetime.now().strftime("%Y-%m-%d")
            return os.path.join(Config.FLAG_DIR, f"position_pushed_{date}.txt")
        except Exception as e:
            logging.error(f"è·å–ä»“ä½æ ‡è®°æ–‡ä»¶è·¯å¾„å¤±è´¥: {str(e)}", exc_info=True)
            return os.path.join(Config.FLAG_DIR, "position_pushed_error.txt")
    
    # äº¤æ˜“è®°å½•æ–‡ä»¶
    TRADE_RECORD_FILE: str = os.path.join(DATA_DIR, "trade_records.csv")
    
    # å…¨å¸‚åœºETFåˆ—è¡¨å­˜å‚¨è·¯å¾„
    ALL_ETFS_PATH: str = os.path.join(DATA_DIR, "all_etfs.csv")
    
    # å…œåº•ETFåˆ—è¡¨è·¯å¾„
    BACKUP_ETFS_PATH: str = os.path.join(DATA_DIR, "karmy_etf.csv")

    # -------------------------
    # 4. æ—¥å¿—é…ç½®
    # -------------------------
    @staticmethod
    def setup_logging(log_level: Optional[str] = None,
                     log_file: Optional[str] = None) -> None:
        """
        é…ç½®æ—¥å¿—ç³»ç»Ÿ
        :param log_level: æ—¥å¿—çº§åˆ« (DEBUG, INFO, WARNING, ERROR, CRITICAL)
        :param log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™åªè¾“å‡ºåˆ°æ§åˆ¶å°
        """
        try:
            level = log_level or Config.LOG_LEVEL
            log_format = Config.LOG_FORMAT
            
            # åˆ›å»ºæ ¹æ—¥å¿—è®°å½•å™¨
            root_logger = logging.getLogger()
            root_logger.setLevel(level)
            
            # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
            for handler in root_logger.handlers[:]:
                root_logger.removeHandler(handler)
            
            # åˆ›å»ºæ ¼å¼åŒ–å™¨
            formatter = logging.Formatter(log_format)
            
            # åˆ›å»ºæ§åˆ¶å°å¤„ç†å™¨
            console_handler = logging.StreamHandler()
            console_handler.setLevel(level)
            console_handler.setFormatter(formatter)
            root_logger.addHandler(console_handler)
            
            # åˆ›å»ºæ–‡ä»¶å¤„ç†å™¨ï¼ˆå¦‚æœæŒ‡å®šäº†æ—¥å¿—æ–‡ä»¶ï¼‰
            if log_file:
                try:
                    # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
                    log_dir = os.path.dirname(log_file)
                    if log_dir and not os.path.exists(log_dir):
                        os.makedirs(log_dir, exist_ok=True)
                    
                    file_handler = logging.FileHandler(log_file, encoding='utf-8')
                    file_handler.setLevel(level)
                    file_handler.setFormatter(formatter)
                    root_logger.addHandler(file_handler)
                    logging.info(f"æ—¥å¿—æ–‡ä»¶å·²é…ç½®: {log_file}")
                except Exception as e:
                    logging.error(f"é…ç½®æ—¥å¿—æ–‡ä»¶å¤±è´¥: {str(e)}", exc_info=True)
        except Exception as e:
            logging.error(f"é…ç½®æ—¥å¿—ç³»ç»Ÿå¤±è´¥: {str(e)}", exc_info=True)
    
    LOG_LEVEL: str = "INFO"
    LOG_FORMAT: str = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    LOG_DIR: str = os.path.join(BASE_DIR, "logs")  # æ—¥å¿—ç›®å½•é…ç½®
    LOG_FILE: str = os.path.join(LOG_DIR, "etf_strategy.log")  # æ—¥å¿—æ–‡ä»¶è·¯å¾„

    # -------------------------
    # 5. æ–°å¢ï¼šç½‘ç»œè¯·æ±‚é…ç½®
    # -------------------------
    # è¯·æ±‚è¶…æ—¶è®¾ç½®ï¼ˆç§’ï¼‰
    REQUEST_TIMEOUT: int = 30
    
    # -------------------------
    # 6. ä¼ä¸šå¾®ä¿¡æœºå™¨äººé…ç½®
    # ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯å›ºå®šæœ«å°¾ï¼ˆç”¨äºæ ‡è¯†æ¶ˆæ¯æ¥æºï¼‰
    # -------------------------
    # ç›´æ¥ä½œä¸ºç±»å±æ€§ï¼Œç¡®ä¿å…¶ä»–æ¨¡å—èƒ½ç›´æ¥è®¿é—®
    WECOM_WEBHOOK: str = os.getenv("WECOM_WEBHOOK", "")

    WECOM_MESFOOTER: str = (
        "\n\n"
        "ã€GIT-fish-etfã€‘\n"
        "ğŸ“Š æ•°æ®æ¥æºï¼šAkShare | ç¯å¢ƒï¼šç”Ÿäº§\n"
        "ğŸŒ UTCæ—¶é—´ï¼š{utc_time}\n"
        "â° åŒ—äº¬æ—¶é—´ï¼š{beijing_time}"
    )
    
    # -------------------------
    # 7. ETFç­›é€‰é…ç½®
    # -------------------------
    # ETFç­›é€‰å‚æ•° - å…¨å±€é»˜è®¤å€¼
    GLOBAL_MIN_FUND_SIZE: float = 10.0  # é»˜è®¤åŸºé‡‘è§„æ¨¡â‰¥10äº¿å…ƒ
    GLOBAL_MIN_AVG_VOLUME: float = 5000.0  # é»˜è®¤æ—¥å‡æˆäº¤é¢â‰¥5000ä¸‡å…ƒ

    # ä»“ä½ç±»å‹ç‰¹å®šå‚æ•°
    STRATEGY_PARAMETERS = {
        "ç¨³å¥ä»“": {
            "min_fund_size": GLOBAL_MIN_FUND_SIZE,
            "min_avg_volume": GLOBAL_MIN_AVG_VOLUME
        },
        "æ¿€è¿›ä»“": {
            "min_fund_size": 2.0,  # æ”¾å®½è‡³2äº¿å…ƒ
            "min_avg_volume": 1000.0  # æ”¾å®½è‡³1000ä¸‡å…ƒ
        }
    }


    # -------------------------
    # 8. é…ç½®éªŒè¯æ–¹æ³•
    # -------------------------
    @staticmethod
    def validate_config() -> Dict[str, Any]:
        """
        éªŒè¯é…ç½®æ˜¯å¦æœ‰æ•ˆï¼Œè¿”å›éªŒè¯ç»“æœ
        :return: åŒ…å«éªŒè¯ç»“æœçš„å­—å…¸
        """
        results = {}
        
        try:
            # æ£€æŸ¥å¿…è¦çš„ç›®å½•æ˜¯å¦å­˜åœ¨æˆ–å¯åˆ›å»º
            required_dirs = [
                Config.DATA_DIR, 
                Config.ETFS_DAILY_DIR,
                Config.FLAG_DIR, 
                Config.LOG_DIR
            ]
            for dir_path in required_dirs:
                try:
                    if not os.path.exists(dir_path):
                        os.makedirs(dir_path, exist_ok=True)
                    results[f"dir_{os.path.basename(dir_path)}"] = {
                        "status": "OK", 
                        "path": dir_path,
                        "writable": os.access(dir_path, os.W_OK)
                    }
                except Exception as e:
                    results[f"dir_{os.path.basename(dir_path)}"] = {
                        "status": "ERROR", 
                        "path": dir_path,
                        "error": str(e)
                    }
            
            # æ£€æŸ¥æƒé‡é…ç½®æ˜¯å¦åˆç†
            total_weight = sum(Config.SCORE_WEIGHTS.values())
            results["weights"] = {
                "status": "OK" if abs(total_weight - 1.0) < 0.001 else "WARNING",
                "total": total_weight,
                "expected": 1.0
            }

            # æ£€æŸ¥å¾®ä¿¡é…ç½®
            results["wechat"] = {
                "status": "OK" if Config.WECOM_WEBHOOK else "WARNING",
                "webhook_configured": bool(Config.WECOM_WEBHOOK)
            }
            
            return results
        except Exception as e:
            logging.error(f"é…ç½®éªŒè¯å¤±è´¥: {str(e)}", exc_info=True)
            return {
                "error": {
                    "status": "ERROR",
                    "message": str(e)
                }
            }

    # -------------------------
    # 9. è·¯å¾„åˆå§‹åŒ–æ–¹æ³•
    # -------------------------
    @staticmethod
    def init_dirs() -> bool:
        """
        åˆå§‹åŒ–æ‰€æœ‰å¿…è¦ç›®å½•
        :return: æ˜¯å¦æˆåŠŸåˆå§‹åŒ–æ‰€æœ‰ç›®å½•
        """
        try:
            # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
            dirs_to_create = [
                Config.DATA_DIR,
                Config.ETFS_DAILY_DIR,
                Config.FLAG_DIR,
                Config.LOG_DIR,
                os.path.dirname(Config.TRADE_RECORD_FILE),
                os.path.dirname(Config.ALL_ETFS_PATH),
                os.path.dirname(Config.BACKUP_ETFS_PATH)
            ]
            
            for dir_path in dirs_to_create:
                if dir_path and not os.path.exists(dir_path):
                    os.makedirs(dir_path, exist_ok=True)
                    logging.info(f"åˆ›å»ºç›®å½•: {dir_path}")
            
            # åˆå§‹åŒ–æ—¥å¿—
            Config.setup_logging(log_file=Config.LOG_FILE)
            
            # éªŒè¯é…ç½®
            validation = Config.validate_config()
            has_errors = any(result["status"] == "ERROR" for result in validation.values())
            
            if has_errors:
                logging.warning("é…ç½®éªŒè¯å‘ç°é”™è¯¯:")
                for key, result in validation.items():
                    if result["status"] == "ERROR":
                        logging.warning(f"  {key}: {result}")
            
            return not has_errors
            
        except Exception as e:
            logging.error(f"åˆå§‹åŒ–ç›®å½•å¤±è´¥: {str(e)}", exc_info=True)
            return False

# -------------------------
# åˆå§‹åŒ–é…ç½®
# -------------------------
try:
    # é¦–å…ˆå°è¯•åˆå§‹åŒ–åŸºç¡€ç›®å½•
    base_dir = _get_base_dir()
    
    # é‡æ–°å®šä¹‰å…³é”®è·¯å¾„ï¼Œç¡®ä¿å®ƒä»¬åŸºäºæ­£ç¡®çš„base_dir
    Config.BASE_DIR = base_dir
    Config.DATA_DIR = os.path.join(base_dir, "data")
    Config.ETFS_DAILY_DIR = os.path.join(Config.DATA_DIR, "etf_daily")
    Config.FLAG_DIR = os.path.join(Config.DATA_DIR, "flags")
    Config.LOG_DIR = os.path.join(base_dir, "logs")
    Config.LOG_FILE = os.path.join(Config.LOG_DIR, "etf_strategy.log")
    
    # è®¾ç½®åŸºç¡€æ—¥å¿—é…ç½®
    logging.basicConfig(
        level=Config.LOG_LEVEL,
        format=Config.LOG_FORMAT,
        handlers=[
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    # åˆå§‹åŒ–ç›®å½•
    if Config.init_dirs():
        logging.info("é…ç½®åˆå§‹åŒ–å®Œæˆ")
    else:
        logging.warning("é…ç½®åˆå§‹åŒ–å®Œæˆï¼Œä½†å­˜åœ¨è­¦å‘Š")
        
except Exception as e:
    # åˆ›å»ºä¸€ä¸ªä¸´æ—¶çš„ã€åŸºæœ¬çš„æ—¥å¿—é…ç½®
    logging.basicConfig(
        level="INFO",
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
        handlers=[
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    # è®°å½•é”™è¯¯ä½†ç»§ç»­æ‰§è¡Œ
    logging.error(f"é…ç½®åˆå§‹åŒ–å¤±è´¥: {str(e)}", exc_info=True)
    logging.info("å·²è®¾ç½®åŸºç¡€æ—¥å¿—é…ç½®ï¼Œç»§ç»­æ‰§è¡Œ")

# -------------------------
# é¢å¤–éªŒè¯ - ç¡®ä¿å…³é”®é…ç½®é¡¹å­˜åœ¨
# -------------------------
def _validate_critical_config():
    """éªŒè¯å…³é”®é…ç½®é¡¹æ˜¯å¦å­˜åœ¨"""
    try:
        critical_configs = [
            "WECOM_WEBHOOK",
            "REQUEST_TIMEOUT",
            "BASE_DIR",
            "DATA_DIR",
            "ETFS_DAILY_DIR",
            "LOG_DIR",
            "LOG_FILE",
            "ALL_ETFS_PATH",
            "BACKUP_ETFS_PATH"
        ]
        
        for config_name in critical_configs:
            if not hasattr(Config, config_name):
                logging.error(f"å…³é”®é…ç½®é¡¹ç¼ºå¤±: {config_name}")
                # å°è¯•ä¿®å¤
                if config_name == "WECOM_WEBHOOK":
                    setattr(Config, "WECOM_WEBHOOK", "")
                    logging.warning("å·²æ·»åŠ ç¼ºå¤±çš„WECOM_WEBHOOKé…ç½®é¡¹")
                elif config_name == "REQUEST_TIMEOUT":
                    setattr(Config, "REQUEST_TIMEOUT", 30)
                    logging.warning("å·²æ·»åŠ ç¼ºå¤±çš„REQUEST_TIMEOUTé…ç½®é¡¹")
                elif config_name == "ETFS_DAILY_DIR":
                    setattr(Config, "ETFS_DAILY_DIR", os.path.join(Config.DATA_DIR, "etf_daily"))
                    logging.warning("å·²æ·»åŠ ç¼ºå¤±çš„ETFS_DAILY_DIRé…ç½®é¡¹")
    except Exception as e:
        logging.error(f"é…ç½®éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}", exc_info=True)

# æ‰§è¡Œé¢å¤–éªŒè¯
try:
    _validate_critical_config()
except Exception as e:
    logging.error(f"é…ç½®éªŒè¯è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}", exc_info=True)

# -------------------------
# æ£€æŸ¥ç¯å¢ƒå˜é‡
# -------------------------
try:
    wecom_webhook = os.getenv("WECOM_WEBHOOK")
    if wecom_webhook:
        logging.info("æ£€æµ‹åˆ°WECOM_WEBHOOKç¯å¢ƒå˜é‡å·²è®¾ç½®")
    else:
        logging.warning("WECOM_WEBHOOKç¯å¢ƒå˜é‡æœªè®¾ç½®ï¼Œå¾®ä¿¡æ¨é€å¯èƒ½æ— æ³•å·¥ä½œ")
        
    # ç¡®ä¿Configä¸­çš„WECOM_WEBHOOKä¸ç¯å¢ƒå˜é‡ä¸€è‡´
    Config.WECOM_WEBHOOK = wecom_webhook or ""
except Exception as e:
    logging.error(f"æ£€æŸ¥ç¯å¢ƒå˜é‡æ—¶å‡ºé”™: {str(e)}", exc_info=True)

# -------------------------
# æ—¶åŒºæ£€æŸ¥
# -------------------------
try:
    # å°è¯•è·å–å½“å‰åŒ—äº¬æ—¶é—´
    from utils.date_utils import get_beijing_time, get_utc_time
    beijing_time = get_beijing_time()
    utc_time = get_utc_time()
    
    logging.info(f"å½“å‰åŒ—äº¬æ—¶é—´: {beijing_time.strftime('%Y-%m-%d %H:%M:%S')}")
    logging.info(f"å½“å‰UTCæ—¶é—´: {utc_time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    # éªŒè¯æ—¶åŒºè®¾ç½®
    if beijing_time.tzinfo is None or utc_time.tzinfo is None:
        logging.warning("æ—¶åŒºä¿¡æ¯ä¸å®Œæ•´ï¼Œå¯èƒ½å­˜åœ¨æ—¶åŒºé—®é¢˜")
    else:
        logging.info(f"åŒ—äº¬æ—¶é—´æ—¶åŒº: {beijing_time.tzname()}")
        logging.info(f"UTCæ—¶é—´æ—¶åŒº: {utc_time.tzname()}")
        
        # éªŒè¯æ—¶å·®æ˜¯å¦æ­£ç¡®ï¼ˆåŒ—äº¬æ—¶é—´åº”æ¯”UTCæ—¶é—´æ—©8å°æ—¶ï¼‰
        time_diff = beijing_time - utc_time
        if abs(time_diff.total_seconds() - 28800) > 60:  # 8å°æ—¶=28800ç§’ï¼Œå…è®¸1åˆ†é’Ÿè¯¯å·®
            logging.warning(f"æ—¶åŒºåç§»ä¸æ­£ç¡®: åŒ—äº¬æ—¶é—´ä¸UTCæ—¶é—´ç›¸å·® {time_diff.total_seconds()/3600:.2f} å°æ—¶")
        else:
            logging.info("æ—¶åŒºè®¾ç½®éªŒè¯é€šè¿‡")
            
except ImportError:
    logging.warning("æ— æ³•å¯¼å…¥date_utilsæ¨¡å—ï¼Œæ—¶åŒºæ£€æŸ¥è·³è¿‡")
except Exception as e:
    logging.error(f"æ—¶åŒºæ£€æŸ¥å¤±è´¥: {str(e)}", exc_info=True)
