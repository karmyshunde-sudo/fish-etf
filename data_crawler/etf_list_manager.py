import akshare as ak
import pandas as pd
import os
from datetime import datetime
from utils.date_utils import get_beijing_time
from utils.file_utils import init_dirs
from retrying import retry
from config import Config  # å¯¼å…¥å®Œæ•´é…ç½®

# åˆ—è¡¨æ›´æ–°é¢‘ç‡ï¼ˆå¤©ï¼‰
LIST_UPDATE_INTERVAL = 7

def is_list_need_update():
    """åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°å…¨å¸‚åœºETFåˆ—è¡¨"""
    if not os.path.exists(Config.ALL_ETFS_PATH):
        return True
    last_modify_time = datetime.fromtimestamp(os.path.getmtime(Config.ALL_ETFS_PATH))
    days_since_update = (get_beijing_time() - last_modify_time).days
    return days_since_update >= LIST_UPDATE_INTERVAL

@retry(stop_max_attempt_number=3, wait_fixed=2000)
def fetch_all_etfs_akshare():
    """ä»AkShareè·å–ETFåˆ—è¡¨ï¼ˆé€‚é…1.17.41ç‰ˆæœ¬ï¼Œæ”¹ç”¨æ–°æ¥å£ï¼‰"""
    try:
        # ä½¿ç”¨ akshare 1.17.41 å¯ç”¨çš„ ETF ä¿¡æ¯æ¥å£
        etf_info = ak.etf_fund_info_em()  # å…¨å¸‚åœºETFåŸºç¡€ä¿¡æ¯
        # ç­›é€‰åœºå†…ETFï¼ˆæ’é™¤åœºå¤–è”æ¥åŸºé‡‘ï¼‰
        etf_list = etf_info[etf_info["äº¤æ˜“åœºæ‰€"] != "åœºå¤–"]  
        # æå–å¿…è¦åˆ—å¹¶æ¸…æ´—
        etf_list = etf_list.rename(columns={
            "åŸºé‡‘ä»£ç ": "ETFä»£ç ",
            "åŸºé‡‘ç®€ç§°": "ETFåç§°"
        })[["ETFä»£ç ", "ETFåç§°"]]
        # ç¡®ä¿ä»£ç ä¸º6ä½æ•°å­—
        etf_list["ETFä»£ç "] = etf_list["ETFä»£ç "].astype(str).str.zfill(6)
        etf_list = etf_list[etf_list["ETFä»£ç "].str.match(r'^\d{6}$')]
        return etf_list.drop_duplicates(subset="ETFä»£ç ")
    except Exception as e:
        print(f"âš ï¸ AkShare 1.17.41 è·å–ETFåˆ—è¡¨å¤±è´¥: {str(e)}")
        raise

@retry(stop_max_attempt_number=3, wait_fixed=2000)
def fetch_all_etfs_sina():
    """æ–°æµªæ¥å£å…œåº•ï¼ˆAkShareå¤±è´¥æ—¶ç”¨ï¼‰"""
    try:
        # æ–°æµªETFåˆ—è¡¨æ¥å£ï¼ˆç›´æ¥è·å–åœºå†…ETFï¼‰
        url = "https://vip.stock.finance.sina.com.cn/quotes_service/api/json_v2.php/Market_Center.getETFList"
        params = {"page": 1, "num": 1000, "sort": "symbol", "asc": 1}
        response = ak.session.get(url, params=params, timeout=10)
        response.raise_for_status()
        # å…¼å®¹æ–°æµªè¿”å›çš„ JSON æ ¼å¼
        etf_data = response.json() if response.text.startswith("[") else eval(response.text)
        etf_list = pd.DataFrame(etf_data)[["symbol", "name"]]
        etf_list = etf_list.rename(columns={
            "symbol": "ETFä»£ç ",
            "name": "ETFåç§°"
        })
        # æ¸…æ´—ä»£ç ï¼ˆå»æ‰å¸‚åœºå‰ç¼€ï¼Œå¦‚ sh510050 â†’ 510050ï¼‰
        etf_list["ETFä»£ç "] = etf_list["ETFä»£ç "].str[-6:]
        return etf_list.drop_duplicates(subset="ETFä»£ç ")
    except Exception as e:
        print(f"âš ï¸ æ–°æµªæ¥å£è·å–ETFåˆ—è¡¨å¤±è´¥: {str(e)}")
        raise

def update_all_etf_list():
    """æ›´æ–°å…¨å¸‚åœºETFåˆ—è¡¨ï¼ˆAkShare â†’ æ–°æµª â†’ å…œåº•æ–‡ä»¶ ä¸‰çº§é™çº§ï¼‰"""
    # åˆå§‹åŒ–å¿…è¦ç›®å½•ï¼ˆç¡®ä¿é…ç½®ä¸­çš„è·¯å¾„å­˜åœ¨ï¼‰
    Config.init_dirs()
    
    if is_list_need_update():
        print("ğŸ” å°è¯•ç”¨ AkShare æ›´æ–°å…¨å¸‚åœºETFåˆ—è¡¨...")
        try:
            etf_list = fetch_all_etfs_akshare()
            etf_list.to_csv(Config.ALL_ETFS_PATH, index=False, encoding="utf-8")
            print(f"âœ… AkShare æ›´æ–°æˆåŠŸï¼ˆ{len(etf_list)}åªETFï¼‰")
            return etf_list
        except:
            print("âŒ AkShare å¤±è´¥ï¼Œå°è¯•æ–°æµªæ¥å£...")
            try:
                etf_list = fetch_all_etfs_sina()
                etf_list.to_csv(Config.ALL_ETFS_PATH, index=False, encoding="utf-8")
                print(f"âœ… æ–°æµªæ¥å£æ›´æ–°æˆåŠŸï¼ˆ{len(etf_list)}åªETFï¼‰")
                return etf_list
            except:
                print("âŒ æ–°æµªæ¥å£å¤±è´¥ï¼Œå¯ç”¨å…œåº•æ–‡ä»¶...")
                if os.path.exists(Config.BACKUP_ETFS_PATH):
                    # å¼ºåˆ¶ç¼–ç å…¼å®¹ï¼ˆUTF-8ä¼˜å…ˆï¼ŒGBK fallbackï¼‰
                    try:
                        backup_df = pd.read_csv(Config.BACKUP_ETFS_PATH, encoding="utf-8")
                    except:
                        backup_df = pd.read_csv(Config.BACKUP_ETFS_PATH, encoding="gbk")
                    
                    # å¼ºåˆ¶è¡¥å…¨å¿…è¦åˆ—ï¼ˆåŒ¹é…STANDARD_COLUMNSï¼‰
                    if "ETFåç§°" not in backup_df.columns:
                        backup_df["ETFåç§°"] = backup_df["ETFä»£ç "].apply(lambda x: f"ETF-{x}")
                    
                    # æ¸…æ´—ä»£ç æ ¼å¼
                    backup_df["ETFä»£ç "] = backup_df["ETFä»£ç "].astype(str).str.zfill(6)
                    backup_df = backup_df[backup_df["ETFä»£ç "].str.match(r'^\d{6}$')]
                    backup_df = backup_df[["ETFä»£ç ", "ETFåç§°"]].drop_duplicates()
                    
                    print(f"âœ… å…œåº•æ–‡ä»¶åŠ è½½æˆåŠŸï¼ˆ{len(backup_df)}åªETFï¼‰")
                    return backup_df
                else:
                    print(f"âŒ å…œåº•æ–‡ä»¶ {Config.BACKUP_ETFS_PATH} ä¸å­˜åœ¨")
                    return pd.DataFrame()
    else:
        print("â„¹ï¸  å…¨å¸‚åœºETFåˆ—è¡¨æ— éœ€æ›´æ–°ï¼Œç›´æ¥åŠ è½½æœ¬åœ°æ–‡ä»¶")
        # åŠ è½½æ—¶åŒæ ·å¤„ç†ç¼–ç å…¼å®¹
        try:
            return pd.read_csv(Config.ALL_ETFS_PATH, encoding="utf-8")
        except:
            return pd.read_csv(Config.ALL_ETFS_PATH, encoding="gbk")

def get_filtered_etf_codes():
    """è·å–éœ€çˆ¬å–çš„ETFä»£ç ï¼ˆè‡ªåŠ¨è¿‡æ»¤æ— æ•ˆä»£ç ï¼‰"""
    etf_list = update_all_etf_list()
    if etf_list.empty:
        print("âš ï¸  æ— æœ‰æ•ˆETFåˆ—è¡¨ï¼Œè¿”å›ç©º")
        return []
    # ä»…è¿”å›6ä½æ•°å­—ä»£ç 
    return etf_list[etf_list["ETFä»£ç "].str.match(r'^\d{6}$')]["ETFä»£ç "].tolist()
