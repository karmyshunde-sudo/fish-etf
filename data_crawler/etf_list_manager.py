# etf_list_manager.py
import akshare as ak
import pandas as pd
import os
import logging
import requests
import time
from datetime import datetime, timezone, timedelta
from typing import List, Optional, Dict, Any
from retrying import retry
from config import Config

# åˆå§‹åŒ–æ—¥å¿—
logger = logging.getLogger(__name__)

# åˆ—è¡¨æ›´æ–°é¢‘ç‡ï¼ˆå¤©ï¼‰
LIST_UPDATE_INTERVAL = 7

# è¯·æ±‚è¶…æ—¶è®¾ç½®ï¼ˆç§’ï¼‰
REQUEST_TIMEOUT = 30

# ç¼“å­˜å˜é‡ï¼Œé¿å…é‡å¤åŠ è½½
_etf_list_cache = None
_last_load_time = None

def load_all_etf_list() -> pd.DataFrame:
    """
    åŠ è½½å…¨å¸‚åœºETFåˆ—è¡¨ï¼Œä½¿ç”¨ç¼“å­˜æœºåˆ¶é¿å…é‡å¤åŠ è½½
    :return: åŒ…å«ETFä¿¡æ¯çš„DataFrame
    """
    global _etf_list_cache, _last_load_time
    
    # æ£€æŸ¥ç¼“å­˜æ˜¯å¦æœ‰æ•ˆï¼ˆ5åˆ†é’Ÿå†…ï¼‰
    if (_etf_list_cache is not None and 
        _last_load_time is not None and 
        (datetime.now() - _last_load_time).total_seconds() < 300):
        logger.debug("ä½¿ç”¨ç¼“å­˜çš„ETFåˆ—è¡¨")
        return _etf_list_cache.copy()
    
    # æ›´æ–°ETFåˆ—è¡¨
    _etf_list_cache = update_all_etf_list()
    _last_load_time = datetime.now()
    
    return _etf_list_cache.copy() if _etf_list_cache is not None else pd.DataFrame()

def is_list_need_update() -> bool:
    """
    åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°å…¨å¸‚åœºETFåˆ—è¡¨
    :return: å¦‚æœéœ€è¦æ›´æ–°è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
    """
    if not os.path.exists(Config.ALL_ETFS_PATH):
        logger.info("ETFåˆ—è¡¨æ–‡ä»¶ä¸å­˜åœ¨ï¼Œéœ€è¦æ›´æ–°")
        return True
        
    try:
        # è·å–æ–‡ä»¶æœ€åä¿®æ”¹æ—¶é—´ï¼ˆè½¬æ¢ä¸ºä¸œå…«åŒºæ—¶åŒºï¼‰
        last_modify_time = datetime.fromtimestamp(os.path.getmtime(Config.ALL_ETFS_PATH))
        last_modify_time = last_modify_time.replace(tzinfo=timezone.utc).astimezone(timezone(timedelta(hours=8)))
        
        # è®¡ç®—è·ç¦»ä¸Šæ¬¡æ›´æ–°çš„å¤©æ•°
        days_since_update = (datetime.now(timezone(timedelta(hours=8))) - last_modify_time).days
        need_update = days_since_update >= LIST_UPDATE_INTERVAL
        
        if need_update:
            logger.info(f"ETFåˆ—è¡¨å·²è¿‡æœŸ({days_since_update}å¤©)ï¼Œéœ€è¦æ›´æ–°")
        else:
            logger.debug(f"ETFåˆ—è¡¨æœªè¿‡æœŸ({days_since_update}å¤©)ï¼Œæ— éœ€æ›´æ–°")
            
        return need_update
    except Exception as e:
        logger.error(f"æ£€æŸ¥ETFåˆ—è¡¨æ›´æ–°çŠ¶æ€å¤±è´¥: {str(e)}")
        # å‡ºé”™æ—¶ä¿å®ˆç­–ç•¥æ˜¯è¦æ±‚æ›´æ–°
        return True

def retry_if_network_error(exception: Exception) -> bool:
    """
    é‡è¯•æ¡ä»¶ï¼šç½‘ç»œç›¸å…³é”™è¯¯
    :param exception: å¼‚å¸¸å¯¹è±¡
    :return: å¦‚æœæ˜¯ç½‘ç»œé”™è¯¯è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
    """
    return isinstance(exception, (requests.RequestException, ConnectionError, TimeoutError))

@retry(
    stop_max_attempt_number=3,
    wait_exponential_multiplier=1000,
    wait_exponential_max=10000,
    retry_on_exception=retry_if_network_error
)
def fetch_all_etfs_akshare() -> pd.DataFrame:
    """
    ä½¿ç”¨AkShareæ¥å£è·å–ETFåˆ—è¡¨ï¼ˆå¸¦è§„æ¨¡å’Œæˆäº¤é¢ç­›é€‰ï¼‰
    :return: åŒ…å«ETFä¿¡æ¯çš„DataFrame
    """
    try:
        logger.info("å°è¯•ä»AkShareè·å–ETFåˆ—è¡¨...")
        # è°ƒç”¨fund_etf_spot_emæ¥å£
        etf_info = ak.fund_etf_spot_em()
        
        if etf_info.empty:
            logger.warning("AkShareè¿”å›ç©ºçš„ETFåˆ—è¡¨")
            return pd.DataFrame()
        
        # è®°å½•è¿”å›çš„åˆ—åï¼Œç”¨äºè°ƒè¯•
        logger.debug(f"AkShareè¿”å›åˆ—å: {list(etf_info.columns)}")
        
        # æ ‡å‡†åŒ–åˆ—åæ˜ å°„
        column_mapping = {}
        for col in etf_info.columns:
            if "ä»£ç " in col:
                column_mapping[col] = "ETFä»£ç "
            elif "åç§°" in col:
                column_mapping[col] = "ETFåç§°"
            elif "è§„æ¨¡" in col:
                column_mapping[col] = "åŸºé‡‘è§„æ¨¡"
            elif "æˆäº¤é¢" in col or "é‡‘é¢" in col:
                column_mapping[col] = "æ—¥å‡æˆäº¤é¢"
        
        # é‡å‘½ååˆ—
        etf_info = etf_info.rename(columns=column_mapping)
        
        # ç¡®ä¿åŒ…å«æ‰€æœ‰éœ€è¦çš„åˆ—
        required_columns = Config.ETF_STANDARD_COLUMNS + ["æ—¥å‡æˆäº¤é¢"]
        for col in required_columns:
            if col not in etf_info.columns:
                etf_info[col] = ""
        
        # æ•°æ®æ¸…æ´—ï¼šç¡®ä¿ä»£ç ä¸º6ä½æ•°å­—
        etf_info["ETFä»£ç "] = etf_info["ETFä»£ç "].astype(str).str.strip().str.zfill(6)
        etf_info = etf_info[etf_info["ETFä»£ç "].str.match(r'^\d{6}$')]
        
        # ç­›é€‰æ¡ä»¶ï¼šåŸºé‡‘è§„æ¨¡å’Œæ—¥å‡æˆäº¤é¢
        etf_info["åŸºé‡‘è§„æ¨¡"] = etf_info["åŸºé‡‘è§„æ¨¡"].apply(convert_fund_size)
        etf_info["æ—¥å‡æˆäº¤é¢"] = etf_info["æ—¥å‡æˆäº¤é¢"].apply(convert_volume)
        
        # åº”ç”¨ç­›é€‰æ¡ä»¶
        filtered_etfs = etf_info[
            (etf_info["åŸºé‡‘è§„æ¨¡"] >= Config.MIN_FUND_SIZE) &
            (etf_info["æ—¥å‡æˆäº¤é¢"] >= Config.MIN_AVG_VOLUME)
        ].copy()
        
        # æ·»åŠ å®Œæ•´ä»£ç åˆ—ï¼ˆå¸¦å¸‚åœºå‰ç¼€ï¼‰
        filtered_etfs["å®Œæ•´ä»£ç "] = filtered_etfs["ETFä»£ç "].apply(get_full_etf_code)
        
        # æŒ‰åŸºé‡‘è§„æ¨¡é™åºæ’åº
        filtered_etfs = filtered_etfs.sort_values("åŸºé‡‘è§„æ¨¡", ascending=False)
        
        # ç§»é™¤æ—¥å‡æˆäº¤é¢åˆ—ï¼ˆä¸ä¿å­˜åœ¨æ–‡ä»¶ä¸­ï¼‰
        filtered_etfs = filtered_etfs[Config.ETF_STANDARD_COLUMNS]
        
        logger.info(f"AkShareè·å–åˆ°{len(etf_info)}åªETFï¼Œç­›é€‰åå‰©ä½™{len(filtered_etfs)}åª")
        return filtered_etfs.drop_duplicates(subset="ETFä»£ç ")
        
    except Exception as e:
        error_msg = f"AkShareæ¥å£é”™è¯¯: {str(e)}"
        logger.error(f"âŒ {error_msg}")
        raise Exception(error_msg)

def get_full_etf_code(etf_code: str) -> str:
    """
    æ ¹æ®ETFä»£ç è·å–å®Œæ•´ä»£ç ï¼ˆå¸¦å¸‚åœºå‰ç¼€ï¼‰
    :param etf_code: ETFä»£ç 
    :return: å®Œæ•´ä»£ç ï¼ˆå¸¦å¸‚åœºå‰ç¼€ï¼‰
    """
    if not etf_code or not isinstance(etf_code, str):
        return ""
        
    etf_code = str(etf_code).strip().zfill(6)
    if etf_code.startswith(('5', '6', '9')):
        return f"sh.{etf_code}"
    else:
        return f"sz.{etf_code}"

def convert_fund_size(size_str: Any) -> float:
    """
    å°†åŸºé‡‘è§„æ¨¡å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ•°å€¼ï¼ˆå•ä½ï¼šäº¿å…ƒï¼‰
    :param size_str: è§„æ¨¡å­—ç¬¦ä¸²
    :return: è§„æ¨¡æ•°å€¼ï¼ˆäº¿å…ƒï¼‰
    """
    try:
        if isinstance(size_str, (int, float)):
            return float(size_str)
        
        size_str = str(size_str).strip()
        if "äº¿" in size_str:
            return float(size_str.replace("äº¿", "").replace(",", "").strip())
        elif "ä¸‡" in size_str:
            return float(size_str.replace("ä¸‡", "").replace(",", "").strip()) / 10000
        else:
            return float(size_str) if size_str else 0.0
    except (ValueError, TypeError):
        logger.warning(f"è½¬æ¢åŸºé‡‘è§„æ¨¡å¤±è´¥: {size_str}")
        return 0.0

def convert_volume(volume_str: Any) -> float:
    """
    å°†æˆäº¤é¢å­—ç¬¦ä¸²è½¬æ¢ä¸ºæ•°å€¼ï¼ˆå•ä½ï¼šä¸‡å…ƒï¼‰
    :param volume_str: æˆäº¤é¢å­—ç¬¦ä¸²
    :return: æˆäº¤é¢æ•°å€¼ï¼ˆä¸‡å…ƒï¼‰
    """
    try:
        if isinstance(volume_str, (int, float)):
            return float(volume_str)
        
        volume_str = str(volume_str).strip()
        if "äº¿" in volume_str:
            return float(volume_str.replace("äº¿", "").replace(",", "").strip()) * 10000
        elif "ä¸‡" in volume_str:
            return float(volume_str.replace("ä¸‡", "").replace(",", "").strip())
        else:
            return float(volume_str) if volume_str else 0.0
    except (ValueError, TypeError):
        logger.warning(f"è½¬æ¢æˆäº¤é¢å¤±è´¥: {volume_str}")
        return 0.0

@retry(
    stop_max_attempt_number=2,
    wait_exponential_multiplier=1000,
    wait_exponential_max=5000,
    retry_on_exception=retry_if_network_error
)
def fetch_all_etfs_sina() -> pd.DataFrame:
    """
    æ–°æµªæ¥å£å…œåº•è·å–ETFåˆ—è¡¨ï¼ˆå¸¦è¶…æ—¶æ§åˆ¶ï¼‰
    :return: åŒ…å«ETFä¿¡æ¯çš„DataFrame
    """
    try:
        logger.info("å°è¯•ä»æ–°æµªè·å–ETFåˆ—è¡¨...")
        url = "https://vip.stock.finance.sina.com.cn/quotes_service/api/json_v2.php/Market_Center.getETFList"
        params = {"page": 1, "num": 1000, "sort": "symbol", "asc": 1}
        
        response = requests.get(url, params=params, timeout=REQUEST_TIMEOUT)
        response.raise_for_status()
        
        # å¤„ç†æ–°æµªæ¥å£è¿”å›çš„æ•°æ®
        try:
            etf_data = response.json()
        except ValueError:
            # å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•eval
            try:
                etf_data = eval(response.text)
            except:
                logger.error("æ–°æµªæ¥å£è¿”å›çš„æ•°æ®æ ¼å¼æ— æ³•è§£æ")
                return pd.DataFrame()
        
        # ç¡®ä¿æ•°æ®æ˜¯åˆ—è¡¨æ ¼å¼
        if not isinstance(etf_data, list):
            logger.warning("æ–°æµªæ¥å£è¿”å›çš„æ•°æ®ä¸æ˜¯åˆ—è¡¨æ ¼å¼")
            return pd.DataFrame()
        
        # åˆ›å»ºDataFrame
        if etf_data:
            etf_list = pd.DataFrame(etf_data)
            # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
            if "symbol" in etf_list.columns and "name" in etf_list.columns:
                etf_list = etf_list.rename(columns={
                    "symbol": "å®Œæ•´ä»£ç ",
                    "name": "ETFåç§°"
                })
                
                # æå–çº¯æ•°å­—ä»£ç 
                etf_list["ETFä»£ç "] = etf_list["å®Œæ•´ä»£ç "].str[-6:].str.strip()
                
                # æ·»åŠ ç©ºç™½çš„åŸºé‡‘è§„æ¨¡åˆ—
                etf_list["åŸºé‡‘è§„æ¨¡"] = 0.0
                
                # ç¡®ä¿åŒ…å«æ‰€æœ‰éœ€è¦çš„åˆ—
                for col in Config.ETF_STANDARD_COLUMNS:
                    if col not in etf_list.columns:
                        etf_list[col] = ""
                
                etf_list = etf_list[Config.ETF_STANDARD_COLUMNS]
                
                # æŒ‰åŸºé‡‘è§„æ¨¡é™åºæ’åº
                etf_list = etf_list.sort_values("åŸºé‡‘è§„æ¨¡", ascending=False)
                
                logger.info(f"æ–°æµªè·å–åˆ°{len(etf_list)}åªETF")
                return etf_list.drop_duplicates(subset="ETFä»£ç ")
            else:
                logger.warning("æ–°æµªæ¥å£è¿”å›çš„æ•°æ®ç¼ºå°‘å¿…è¦åˆ—")
                return pd.DataFrame(columns=Config.ETF_STANDARD_COLUMNS)
        else:
            logger.warning("æ–°æµªæ¥å£è¿”å›ç©ºæ•°æ®")
            return pd.DataFrame(columns=Config.ETF_STANDARD_COLUMNS)
            
    except Exception as e:
        error_msg = f"æ–°æµªæ¥å£é”™è¯¯: {str(e)}"
        logger.error(f"âŒ {error_msg}")
        raise Exception(error_msg)

def read_csv_with_encoding(file_path: str) -> pd.DataFrame:
    """
    è¯»å–CSVæ–‡ä»¶ï¼Œè‡ªåŠ¨å…¼å®¹UTF-8å’ŒGBKç¼–ç 
    :param file_path: æ–‡ä»¶è·¯å¾„
    :return: è¯»å–çš„DataFrame
    """
    encodings = ["utf-8", "gbk", "latin-1", "utf-8-sig"]
    for encoding in encodings:
        try:
            df = pd.read_csv(file_path, encoding=encoding)
            # ç¡®ä¿åŒ…å«æ‰€æœ‰éœ€è¦çš„åˆ—
            required_columns = Config.ETF_STANDARD_COLUMNS
            for col in required_columns:
                if col not in df.columns:
                    df[col] = ""
            return df[required_columns].copy()
        except (UnicodeDecodeError, LookupError, KeyError) as e:
            logger.debug(f"å°è¯•ç¼–ç  {encoding} å¤±è´¥: {str(e)}")
            continue
    raise Exception(f"æ— æ³•è§£ææ–‡ä»¶ {file_path}ï¼Œå°è¯•äº†ç¼–ç : {encodings}")

def update_all_etf_list() -> pd.DataFrame:
    """
    æ›´æ–°å…¨å¸‚åœºETFåˆ—è¡¨ï¼ˆä¸‰çº§é™çº§ç­–ç•¥ï¼‰
    :return: åŒ…å«ETFä¿¡æ¯çš„DataFrame
    """
    try:
        Config.init_dirs()
        primary_etf_list = None
        
        if is_list_need_update():
            logger.info("ğŸ” å°è¯•æ›´æ–°å…¨å¸‚åœºETFåˆ—è¡¨...")
            
            # 1. å°è¯•AkShareæ¥å£
            try:
                etf_list = fetch_all_etfs_akshare()
                if not etf_list.empty:
                    # ç¡®ä¿åŒ…å«æ‰€æœ‰éœ€è¦çš„åˆ—
                    required_columns = Config.ETF_STANDARD_COLUMNS
                    for col in required_columns:
                        if col not in etf_list.columns:
                            etf_list[col] = ""
                    etf_list = etf_list[required_columns]
                    
                    # æŒ‰åŸºé‡‘è§„æ¨¡é™åºæ’åº
                    etf_list = etf_list.sort_values("åŸºé‡‘è§„æ¨¡", ascending=False)
                    
                    etf_list.to_csv(Config.ALL_ETFS_PATH, index=False, encoding="utf-8")
                    logger.info(f"âœ… AkShareæ›´æ–°æˆåŠŸï¼ˆ{len(etf_list)}åªETFï¼‰")
                    primary_etf_list = etf_list
                else:
                    logger.warning("AkShareè¿”å›ç©ºçš„ETFåˆ—è¡¨")
            except Exception as e:
                logger.error(f"âŒ AkShareæ›´æ–°å¤±è´¥: {str(e)}")
            
            # 2. å°è¯•æ–°æµªæ¥å£ï¼ˆä»…å½“AkShareå¤±è´¥æ—¶ï¼‰
            if primary_etf_list is None:
                try:
                    etf_list = fetch_all_etfs_sina()
                    if not etf_list.empty:
                        # ç¡®ä¿åŒ…å«æ‰€æœ‰éœ€è¦çš„åˆ—
                        required_columns = Config.ETF_STANDARD_COLUMNS
                        for col in required_columns:
                            if col not in etf_list.columns:
                                etf_list[col] = ""
                        etf_list = etf_list[required_columns]
                        
                        etf_list.to_csv(Config.ALL_ETFS_PATH, index=False, encoding="utf-8")
                        logger.info(f"âœ… æ–°æµªæ¥å£æ›´æ–°æˆåŠŸï¼ˆ{len(etf_list)}åªETFï¼‰")
                        primary_etf_list = etf_list
                    else:
                        logger.warning("æ–°æµªæ¥å£è¿”å›ç©ºçš„ETFåˆ—è¡¨")
                except Exception as e:
                    logger.error(f"âŒ æ–°æµªæ¥å£æ›´æ–°å¤±è´¥: {str(e)}")
            
            # æ–°å¢é€»è¾‘ï¼šç¬¬ä¸€æ¬¡åˆå§‹åŒ–æ—¶åŒæ­¥è¡¥å……å…œåº•æ–‡ä»¶
            backup_file_exists = os.path.exists(Config.BACKUP_ETFS_PATH)
            backup_file_empty = False
            if backup_file_exists:
                backup_file_empty = os.path.getsize(Config.BACKUP_ETFS_PATH) == 0
            
            if not backup_file_exists or backup_file_empty:
                logger.info("ğŸ”„ æ£€æµ‹åˆ°å…œåº•æ–‡ä»¶æœªåˆå§‹åŒ–ï¼Œå¼€å§‹åŒæ­¥æ•°æ®...")
                
                if primary_etf_list is not None and not primary_etf_list.empty:
                    backup_df = primary_etf_list.copy()
                    backup_df.to_csv(Config.BACKUP_ETFS_PATH, index=False, encoding="utf-8")
                    logger.info(f"âœ… å·²ä»æ–°è·å–æ•°æ®åŒæ­¥å…œåº•æ–‡ä»¶ï¼ˆ{len(backup_df)}æ¡è®°å½•ï¼‰")
                
                elif os.path.exists(Config.ALL_ETFS_PATH) and os.path.getsize(Config.ALL_ETFS_PATH) > 0:
                    try:
                        all_etfs_df = read_csv_with_encoding(Config.ALL_ETFS_PATH)
                        all_etfs_df.to_csv(Config.BACKUP_ETFS_PATH, index=False, encoding="utf-8")
                        logger.info(f"âœ… å·²ä»æœ¬åœ°all_etfs.csvåŒæ­¥å…œåº•æ–‡ä»¶ï¼ˆ{len(all_etfs_df)}æ¡è®°å½•ï¼‰")
                    except Exception as e:
                        logger.error(f"âŒ ä»all_etfs.csvåŒæ­¥å…œåº•æ–‡ä»¶å¤±è´¥: {str(e)}")
            
            # 3. å°è¯•å…œåº•æ–‡ä»¶ï¼ˆå¦‚æœä¸»æ•°æ®æºéƒ½å¤±è´¥ï¼‰
            if primary_etf_list is None:
                if os.path.exists(Config.BACKUP_ETFS_PATH):
                    try:
                        backup_df = read_csv_with_encoding(Config.BACKUP_ETFS_PATH)
                        
                        # éªŒè¯å¿…è¦åˆ—
                        required_columns = Config.ETF_STANDARD_COLUMNS
                        for col in required_columns:
                            if col not in backup_df.columns:
                                backup_df[col] = ""
                        
                        # æ•°æ®æ¸…æ´—
                        backup_df["ETFä»£ç "] = backup_df["ETFä»£ç "].astype(str).str.strip().str.zfill(6)
                        backup_df = backup_df[backup_df["ETFä»£ç "].str.match(r'^\d{6}$')]
                        backup_df = backup_df[required_columns].drop_duplicates()
                        
                        # æŒ‰åŸºé‡‘è§„æ¨¡é™åºæ’åº
                        backup_df = backup_df.sort_values("åŸºé‡‘è§„æ¨¡", ascending=False)
                        
                        logger.info(f"âœ… å…œåº•æ–‡ä»¶åŠ è½½æˆåŠŸï¼ˆ{len(backup_df)}åªETFï¼‰")
                        return backup_df
                    except Exception as e:
                        logger.error(f"âŒ å…œåº•æ–‡ä»¶å¤„ç†å¤±è´¥: {str(e)}")
                        # è¿”å›ç©ºDataFrameä½†åŒ…å«æ‰€æœ‰åˆ—
                        empty_df = pd.DataFrame(columns=Config.ETF_STANDARD_COLUMNS)
                        return empty_df
                else:
                    logger.error(f"âŒ å…œåº•æ–‡ä»¶ä¸å­˜åœ¨: {Config.BACKUP_ETFS_PATH}")
                    # è¿”å›ç©ºDataFrameä½†åŒ…å«æ‰€æœ‰åˆ—
                    empty_df = pd.DataFrame(columns=Config.ETF_STANDARD_COLUMNS)
                    return empty_df
            
            return primary_etf_list
        
        else:
            logger.info("â„¹ï¸ æ— éœ€æ›´æ–°ï¼ŒåŠ è½½æœ¬åœ°ETFåˆ—è¡¨")
            try:
                etf_list = read_csv_with_encoding(Config.ALL_ETFS_PATH)
                # ç¡®ä¿åŒ…å«æ‰€æœ‰éœ€è¦çš„åˆ—
                required_columns = Config.ETF_STANDARD_COLUMNS
                for col in required_columns:
                    if col not in etf_list.columns:
                        etf_list[col] = ""
                
                # æŒ‰åŸºé‡‘è§„æ¨¡é™åºæ’åº
                etf_list = etf_list.sort_values("åŸºé‡‘è§„æ¨¡", ascending=False)
                
                return etf_list
            except Exception as e:
                logger.error(f"âŒ æœ¬åœ°æ–‡ä»¶åŠ è½½å¤±è´¥: {str(e)}")
                # è¿”å›ç©ºDataFrameä½†åŒ…å«æ‰€æœ‰åˆ—
                empty_df = pd.DataFrame(columns=Config.ETF_STANDARD_COLUMNS)
                return empty_df
                
    except Exception as e:
        logger.error(f"âŒ æ›´æ–°ETFåˆ—è¡¨æ—¶å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {str(e)}")
        # è¿”å›ç©ºDataFrameä½†åŒ…å«æ‰€æœ‰åˆ—
        return pd.DataFrame(columns=Config.ETF_STANDARD_COLUMNS)

def get_filtered_etf_codes() -> List[str]:
    """
    è·å–è¿‡æ»¤åçš„æœ‰æ•ˆETFä»£ç åˆ—è¡¨
    :return: ETFä»£ç åˆ—è¡¨
    """
    try:
        etf_list = update_all_etf_list()
        if etf_list.empty:
            logger.warning("âš ï¸ æ— æœ‰æ•ˆETFä»£ç åˆ—è¡¨")
            return []
        
        # ç¡®ä¿ETFä»£ç ä¸ºå­—ç¬¦ä¸²ç±»å‹
        etf_list["ETFä»£ç "] = etf_list["ETFä»£ç "].astype(str).str.strip()
        valid_codes = etf_list[etf_list["ETFä»£ç "].str.match(r'^\d{6}$')]["ETFä»£ç "].tolist()
        logger.info(f"ğŸ“Š æœ‰æ•ˆETFä»£ç æ•°é‡: {len(valid_codes)}")
        return valid_codes
    except Exception as e:
        logger.error(f"è·å–æœ‰æ•ˆETFä»£ç åˆ—è¡¨å¤±è´¥: {str(e)}")
        return []

# åˆå§‹åŒ–æ¨¡å—
try:
    Config.init_dirs()
    logger.info("ETFåˆ—è¡¨ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
except Exception as e:
    logger.error(f"ETFåˆ—è¡¨ç®¡ç†å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
# 0828-1256ã€etf_list_manager.pyä»£ç ã€‘ä¸€å…±389è¡Œä»£ç 
