#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸ªè‚¡è¶‹åŠ¿è·Ÿè¸ªç­–ç•¥ï¼ˆTickTenç­–ç•¥ï¼‰
åŸºäºæœ¬åœ°å·²ä¿å­˜çš„è‚¡ç¥¨æ—¥çº¿æ•°æ®ï¼Œåº”ç”¨æµåŠ¨æ€§ã€æ³¢åŠ¨ç‡ã€å¸‚å€¼ä¸‰é‡è¿‡æ»¤ï¼Œç­›é€‰ä¼˜è´¨ä¸ªè‚¡
æŒ‰æ¿å—åˆ†ç±»æ¨é€ï¼Œæ¯ä¸ªæ¿å—æœ€å¤š10åªï¼Œå…±40åª
"""

import os
import logging
import pandas as pd
import numpy as np
import time
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Any
# ========== ä»¥ä¸‹æ˜¯å…³é”®ä¿®æ”¹ ==========
from concurrent.futures import ThreadPoolExecutor
# ========== ä»¥ä¸Šæ˜¯å…³é”®ä¿®æ”¹ ==========

# ===== æ–°å¢å¯¼å…¥ =====
import sys
import traceback
# ===== æ–°å¢å¯¼å…¥ç»“æŸ =====

from config import Config
from utils.date_utils import (
    get_current_times,
    get_beijing_time,
    get_utc_time
)
from wechat_push.push import send_wechat_message
from utils.git_utils import commit_and_push_file  # ç¡®ä¿å¯¼å…¥è¿™ä¸ªå‡½æ•°

# åˆå§‹åŒ–æ—¥å¿—
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
handler = logging.StreamHandler()
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

# ========== ä»¥ä¸‹æ˜¯å…³é”®ä¿®æ”¹ ==========
# å®šä¹‰è‚¡ç¥¨åŸºç¡€ä¿¡æ¯æ–‡ä»¶è·¯å¾„
BASIC_INFO_FILE = "data/all_stocks.csv"

# æ•°æ®æ›´æ–°é—´éš”ï¼ˆå¤©ï¼‰
DATA_UPDATE_INTERVAL = 1
# ========== ä»¥ä¸Šæ˜¯å…³é”®ä¿®æ”¹ ==========

# è‚¡ç¥¨æ¿å—é…ç½®
MARKET_SECTIONS = {
    "æ²ªå¸‚ä¸»æ¿": {
        "prefix": ["60"],
        "min_daily_volume": 5 * 10000,  # æ—¥å‡æˆäº¤é¢é˜ˆå€¼(å…ƒ)
        "min_volatility": 0.05,  # æœ€å°æ³¢åŠ¨ç‡
        "max_volatility": 0.40,  # æœ€å¤§æ³¢åŠ¨ç‡
        "min_market_cap": 5,  # æœ€å°å¸‚å€¼(äº¿å…ƒ)
        "max_market_cap": 2000  # æœ€å¤§å¸‚å€¼(äº¿å…ƒ)
    },
    "æ·±å¸‚ä¸»æ¿": {
        "prefix": ["00"],
        "min_daily_volume": 5 * 10000,
        "min_volatility": 0.05,
        "max_volatility": 0.40,
        "min_market_cap": 5,
        "max_market_cap": 2000
    },
    "åˆ›ä¸šæ¿": {
        "prefix": ["30"],
        "min_daily_volume": 5 * 10000,  # ä¿®å¤ï¼šç»Ÿä¸€å•ä½ä¸ºå…ƒ
        "min_volatility": 0.05,
        "max_volatility": 0.40,
        "min_market_cap": 5,
        "max_market_cap": 2000
    },
    "ç§‘åˆ›æ¿": {
        "prefix": ["688"],
        "min_daily_volume": 5 * 10000,  # ä¿®å¤ï¼šç»Ÿä¸€å•ä½ä¸ºå…ƒ
        "min_volatility": 0.05,
        "max_volatility": 0.40,
        "min_market_cap": 5,
        "max_market_cap": 2000
    }
}

# å…¶ä»–å‚æ•°
MIN_DATA_DAYS = 30  # æœ€å°æ•°æ®å¤©æ•°ï¼ˆç”¨äºè®¡ç®—æŒ‡æ ‡ï¼‰
MAX_STOCKS_TO_ANALYZE = 300  # å‡å°‘æ¯æ¬¡åˆ†æçš„æœ€å¤§è‚¡ç¥¨æ•°é‡ï¼ˆé¿å…è¯·æ±‚è¿‡å¤šï¼‰
MAX_STOCKS_PER_SECTION = 8  # æ¯ä¸ªæ¿å—æœ€å¤šæŠ¥å‘Šçš„è‚¡ç¥¨æ•°é‡
CRITICAL_VALUE_DAYS = 40  # ä¸´ç•Œå€¼è®¡ç®—å¤©æ•°


def check_data_integrity(df: pd.DataFrame) -> Tuple[str, int]:
    """æ£€æŸ¥æ•°æ®å®Œæ•´æ€§å¹¶è¿”å›çº§åˆ«
    
    Returns:
        (str, int): (å®Œæ•´æ€§çº§åˆ«, æ•°æ®å¤©æ•°)
    """
    if df is None or df.empty:
        return "none", 0
    
    # è®¡ç®—æ•°æ®å¤©æ•°
    data_days = len(df)
    
    # æ£€æŸ¥å¿…è¦åˆ—
    required_columns = ["æ—¥æœŸ", "å¼€ç›˜", "æœ€é«˜", "æœ€ä½", "æ”¶ç›˜", "æˆäº¤é‡"]
    missing_columns = [col for col in required_columns if col not in df.columns]
    
    if missing_columns:
        return "corrupted", data_days
    
    # æ£€æŸ¥æ•°æ®è¿ç»­æ€§
    df = df.copy()
    # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯datetimeç±»å‹
    try:
        df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"])
    except:
        return "corrupted", data_days
    
    df = df.sort_values("æ—¥æœŸ")
    
    # æ£€æŸ¥æ—¥æœŸé—´éš”
    df["æ—¥æœŸ_diff"] = df["æ—¥æœŸ"].diff().dt.days
    gaps = df[df["æ—¥æœŸ_diff"] > 1]
    
    # è®¡ç®—ç¼ºå¤±ç‡
    expected_days = (df["æ—¥æœŸ"].iloc[-1] - df["æ—¥æœŸ"].iloc[0]).days + 1
    missing_rate = 1 - (data_days / expected_days) if expected_days > 0 else 1
    
    # æ•°æ®å®Œæ•´æ€§åˆ†çº§
    if data_days < MIN_DATA_DAYS:
        return "insufficient", data_days
    elif missing_rate > 0.2:  # ç¼ºå¤±ç‡è¶…è¿‡20%
        return "partial", data_days
    elif gaps.shape[0] > 5:  # æœ‰5ä¸ªä»¥ä¸Šå¤§é—´éš”
        return "gapped", data_days
    else:
        return "complete", data_days

# ========== ä»¥ä¸‹æ˜¯å…³é”®ä¿®æ”¹ ==========
def load_stock_basic_info() -> pd.DataFrame:
    """åŠ è½½è‚¡ç¥¨åŸºç¡€ä¿¡æ¯"""
    try:
        if os.path.exists(BASIC_INFO_FILE):
            df = pd.read_csv(BASIC_INFO_FILE)
            
            # ç¡®ä¿æ‰€æœ‰å¿…è¦åˆ—å­˜åœ¨
            if "code" not in df.columns:
                logger.error(f"è‚¡ç¥¨åŸºç¡€ä¿¡æ¯æ–‡ä»¶ç¼ºå°‘ 'code' åˆ—")
                return pd.DataFrame()
            
            # ç¡®ä¿è‚¡ç¥¨ä»£ç æ˜¯å­—ç¬¦ä¸²æ ¼å¼ï¼Œå¹¶ä¸”æ˜¯6ä½ï¼ˆå‰é¢è¡¥é›¶ï¼‰
            df["code"] = df["code"].astype(str).str.zfill(6)
            
            # å¦‚æœæ²¡æœ‰ section åˆ—ï¼Œæ·»åŠ å¹¶è®¡ç®—
            if "section" not in df.columns:
                df["section"] = df["code"].apply(get_stock_section)
            
            # å¦‚æœæ²¡æœ‰ market_cap åˆ—ï¼Œæ·»åŠ å¹¶åˆå§‹åŒ–
            if "market_cap" not in df.columns:
                df["market_cap"] = 0.0
                
            # å¦‚æœæ²¡æœ‰ score åˆ—ï¼Œæ·»åŠ å¹¶åˆå§‹åŒ–
            if "score" not in df.columns:
                df["score"] = 0.0
                
            # å¦‚æœæ²¡æœ‰ last_update åˆ—ï¼Œæ·»åŠ å¹¶åˆå§‹åŒ–
            if "last_update" not in df.columns:
                df["last_update"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            logger.info(f"æˆåŠŸåŠ è½½è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ï¼Œå…± {len(df)} æ¡è®°å½•")
            return df
        else:
            logger.error(f"è‚¡ç¥¨åŸºç¡€ä¿¡æ¯æ–‡ä»¶ {BASIC_INFO_FILE} ä¸å­˜åœ¨")
            return pd.DataFrame()
    except Exception as e:
        logger.error(f"åŠ è½½è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å¤±è´¥: {str(e)}")
        logger.error(traceback.format_exc())
        return pd.DataFrame()

def get_last_update_time(df: pd.DataFrame, stock_code: str) -> Optional[datetime]:
    """è·å–è‚¡ç¥¨æœ€åæ›´æ–°æ—¶é—´"""
    if df.empty:
        return None
    
    stock_info = df[df["code"] == stock_code]
    if not stock_info.empty:
        last_update = stock_info["last_update"].values[0]
        try:
            # å°è¯•è§£ææ—¶é—´å­—ç¬¦ä¸²
            return datetime.strptime(last_update, "%Y-%m-%d %H:%M:%S")
        except Exception as e:
            logger.debug(f"è§£ææ›´æ–°æ—¶é—´å¤±è´¥: {str(e)}")
            return None
    return None
# ========== ä»¥ä¸Šæ˜¯å…³é”®ä¿®æ”¹ ==========

def get_stock_section(stock_code: str) -> str:
    """
    è·å–è‚¡ç¥¨æ‰€å±æ¿å—
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç ï¼ˆä¸å¸¦å¸‚åœºå‰ç¼€ï¼‰
    
    Returns:
        str: æ¿å—åç§°
    """
    # ç¡®ä¿è‚¡ç¥¨ä»£ç æ˜¯å­—ç¬¦ä¸²
    stock_code = str(stock_code).zfill(6)
    
    # ç§»é™¤å¯èƒ½çš„å¸‚åœºå‰ç¼€
    if stock_code.lower().startswith(('sh', 'sz')):
        stock_code = stock_code[2:]
    
    # ç¡®ä¿è‚¡ç¥¨ä»£ç æ˜¯6ä½æ•°å­—
    stock_code = stock_code.zfill(6)
    
    # æ ¹æ®è‚¡ç¥¨ä»£ç å‰ç¼€åˆ¤æ–­æ¿å—
    for section, config in MARKET_SECTIONS.items():
        for prefix in config["prefix"]:
            if stock_code.startswith(prefix):
                return section
    
    return "å…¶ä»–æ¿å—"

def get_stock_daily_data(stock_code: str) -> pd.DataFrame:
    """ä»æœ¬åœ°åŠ è½½è‚¡ç¥¨æ—¥çº¿æ•°æ®"""
    try:
        # ç¡®ä¿è‚¡ç¥¨ä»£ç æ˜¯å­—ç¬¦ä¸²ï¼Œå¹¶ä¸”æ˜¯6ä½ï¼ˆå‰é¢è¡¥é›¶ï¼‰
        stock_code = str(stock_code).zfill(6)
        
        # æ—¥çº¿æ•°æ®ç›®å½•
        daily_dir = os.path.join(Config.DATA_DIR, "daily")
        
        # æ£€æŸ¥æœ¬åœ°æ˜¯å¦æœ‰å†å²æ•°æ®
        file_path = os.path.join(daily_dir, f"{stock_code}.csv")
        if os.path.exists(file_path):
            try:
                df = pd.read_csv(file_path)
                
                # ç¡®ä¿å¿…è¦åˆ—å­˜åœ¨
                required_columns = ["æ—¥æœŸ", "å¼€ç›˜", "æœ€é«˜", "æœ€ä½", "æ”¶ç›˜", "æˆäº¤é‡"]
                for col in required_columns:
                    if col not in df.columns:
                        logger.warning(f"è‚¡ç¥¨ {stock_code} æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {col}")
                        return pd.DataFrame()
                
                # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯å­—ç¬¦ä¸²ç±»å‹
                if "æ—¥æœŸ" in df.columns:
                    df["æ—¥æœŸ"] = df["æ—¥æœŸ"].astype(str)
                    # ç¡®ä¿æ—¥æœŸæ ¼å¼ä¸ºYYYY-MM-DD
                    df["æ—¥æœŸ"] = df["æ—¥æœŸ"].str.replace(r'(\d{4})/(\d{1,2})/(\d{1,2})', 
                                                      lambda m: f"{m.group(1)}-{int(m.group(2)):02d}-{int(m.group(3)):02d}", 
                                                      regex=True)
                    # å¤„ç†å…¶ä»–å¯èƒ½çš„æ ¼å¼
                    df["æ—¥æœŸ"] = df["æ—¥æœŸ"].str.replace(r'(\d{4})-(\d{1,2}) (\d{1,2})', 
                                                      lambda m: f"{m.group(1)}-{int(m.group(2)):02d}-{int(m.group(3)):02d}", 
                                                      regex=True)
                    # ç§»é™¤å¯èƒ½å­˜åœ¨çš„ç©ºæ ¼
                    df["æ—¥æœŸ"] = df["æ—¥æœŸ"].str.strip()
                    df = df.sort_values("æ—¥æœŸ", ascending=True)
                
                # ç§»é™¤NaNå€¼
                df = df.dropna(subset=['æ”¶ç›˜', 'æˆäº¤é‡'])
                
                logger.info(f"æˆåŠŸåŠ è½½è‚¡ç¥¨ {stock_code} çš„æœ¬åœ°æ—¥çº¿æ•°æ®ï¼Œå…± {len(df)} æ¡æœ‰æ•ˆè®°å½•")
                return df
            except Exception as e:
                logger.warning(f"è¯»å–è‚¡ç¥¨ {stock_code} æ•°æ®å¤±è´¥: {str(e)}")
                logger.debug(traceback.format_exc())
        
        logger.warning(f"è‚¡ç¥¨ {stock_code} çš„æ—¥çº¿æ•°æ®ä¸å­˜åœ¨")
        return pd.DataFrame()
    
    except Exception as e:
        logger.error(f"è·å–è‚¡ç¥¨ {stock_code} æ—¥çº¿æ•°æ®å¤±è´¥: {str(e)}", exc_info=True)
        return pd.DataFrame()

def calculate_annual_volatility(df: pd.DataFrame) -> float:
    """è®¡ç®—å¹´åŒ–æ³¢åŠ¨ç‡"""
    if len(df) < 20:
        logger.warning(f"æ•°æ®ä¸è¶³20å¤©ï¼Œæ— æ³•å‡†ç¡®è®¡ç®—æ³¢åŠ¨ç‡")
        return 0.2  # é»˜è®¤æ³¢åŠ¨ç‡
    
    # ç›´æ¥ä½¿ç”¨"æ”¶ç›˜"åˆ—è®¡ç®—æ—¥æ”¶ç›Šç‡ï¼ˆä¸è¿›è¡Œä»»ä½•åˆ—åæ˜ å°„ï¼‰
    daily_returns = df["æ”¶ç›˜"].pct_change().dropna()
    
    # è®¡ç®—å¹´åŒ–æ³¢åŠ¨ç‡
    if len(daily_returns) >= 20:
        volatility = daily_returns.std() * np.sqrt(252)
    else:
        volatility = 0.2  # é»˜è®¤æ³¢åŠ¨ç‡
    
    # é™åˆ¶æ³¢åŠ¨ç‡åœ¨åˆç†èŒƒå›´å†…
    volatility = max(0.05, min(1.0, volatility))
    
    return volatility

def calculate_market_cap(df: pd.DataFrame, stock_code: str) -> Optional[float]:
    """è®¡ç®—è‚¡ç¥¨å¸‚å€¼ï¼ˆä¼˜å…ˆä½¿ç”¨ç¼“å­˜æ•°æ®ï¼‰
    
    Returns:
        Optional[float]: å¸‚å€¼(äº¿å…ƒ)ï¼ŒNoneè¡¨ç¤ºå¸‚å€¼æ•°æ®ä¸å¯é 
    """
    try:
        # æ£€æŸ¥æ˜¯å¦éœ€è¦ç¼“å­˜å¸‚å€¼æ•°æ®
        cache_file = os.path.join(os.path.dirname(BASIC_INFO_FILE), "market_cap_cache.csv")
        cache_days = 3  # å¸‚å€¼æ•°æ®ç¼“å­˜3å¤©
        
        # å¦‚æœå­˜åœ¨ç¼“å­˜æ–‡ä»¶ï¼Œå°è¯•è¯»å–
        if os.path.exists(cache_file):
            try:
                cache_df = pd.read_csv(cache_file)
                record = cache_df[cache_df["code"] == stock_code]
                if not record.empty:
                    last_update = record["last_update"].values[0]
                    try:
                        last_update_time = datetime.strptime(last_update, "%Y-%m-%d %H:%M:%S")
                        if (datetime.now() - last_update_time).days <= cache_days:
                            market_cap = record["market_cap"].values[0]
                            if not pd.isna(market_cap) and market_cap > 0:
                                logger.debug(f"ä½¿ç”¨ç¼“å­˜çš„å¸‚å€¼æ•°æ®: {market_cap:.2f}äº¿å…ƒ (æœ€åæ›´æ–°: {last_update})")
                                return market_cap
                    except Exception as e:
                        logger.warning(f"è§£æå¸‚å€¼ç¼“å­˜æ›´æ–°æ—¶é—´å¤±è´¥: {str(e)}")
            except Exception as e:
                logger.warning(f"è¯»å–å¸‚å€¼ç¼“å­˜æ–‡ä»¶å¤±è´¥: {str(e)}")
        
        # ä»åŸºç¡€ä¿¡æ¯æ–‡ä»¶ä¸­è·å–å¸‚å€¼
        basic_info_df = load_stock_basic_info()
        if not basic_info_df.empty:
            stock_info = basic_info_df[basic_info_df["code"] == stock_code]
            if not stock_info.empty:
                market_cap = stock_info["market_cap"].values[0]
                if not pd.isna(market_cap) and market_cap > 0:
                    # æ›´æ–°ç¼“å­˜
                    if not os.path.exists(os.path.dirname(cache_file)):
                        os.makedirs(os.path.dirname(cache_file))
                    
                    if os.path.exists(cache_file):
                        cache_df = pd.read_csv(cache_file)
                        cache_df = cache_df[cache_df["code"] != stock_code]
                        new_record = pd.DataFrame([{
                            "code": stock_code,
                            "market_cap": market_cap,
                            "last_update": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        }])
                        cache_df = pd.concat([cache_df, new_record], ignore_index=True)
                    else:
                        cache_df = pd.DataFrame([{
                            "code": stock_code,
                            "market_cap": market_cap,
                            "last_update": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                        }])
                    
                    cache_df.to_csv(cache_file, index=False)
                    logger.debug(f"å¸‚å€¼ç¼“å­˜å·²æ›´æ–°: {stock_code} - {market_cap:.2f}äº¿å…ƒ")
                    
                    return market_cap
        
        # å¦‚æœæ— æ³•è·å–å¸‚å€¼ï¼Œè¿”å›é»˜è®¤å€¼ï¼ˆä½†ä¸è¿”å›Noneï¼Œé¿å…åç»­é—®é¢˜ï¼‰
        logger.warning(f"âš ï¸ æ— æ³•è·å–è‚¡ç¥¨ {stock_code} çš„å‡†ç¡®å¸‚å€¼ï¼Œä½¿ç”¨é»˜è®¤å¸‚å€¼ 50äº¿å…ƒ")
        return 50.0
    
    except Exception as e:
        logger.error(f"ä¼°ç®—{stock_code}å¸‚å€¼å¤±è´¥: {str(e)}", exc_info=True)
        return 50.0  # è¿”å›é»˜è®¤å¸‚å€¼

def is_stock_suitable(stock_code: str, df: pd.DataFrame, data_level: str, data_days: int) -> bool:
    """åˆ¤æ–­ä¸ªè‚¡æ˜¯å¦é€‚åˆç­–ç•¥ï¼ˆæµåŠ¨æ€§ã€æ³¢åŠ¨ç‡ã€å¸‚å€¼ä¸‰é‡è¿‡æ»¤ï¼‰"""
    try:
        # 1. æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
        if data_level == "insufficient" or data_level == "corrupted":
            logger.debug(f"è‚¡ç¥¨ {stock_code} è¢«è¿‡æ»¤ - æ•°æ®é‡ä¸è¶³({data_days}å¤©)")
            return False
            
        # è·å–è‚¡ç¥¨æ‰€å±æ¿å—
        section = get_stock_section(stock_code)
        if section not in MARKET_SECTIONS:
            logger.debug(f"è‚¡ç¥¨ {stock_code} ä¸å±äºä»»ä½•æ¿å—ï¼Œè·³è¿‡")
            return False
            
        # è·å–æ¿å—é…ç½®
        section_config = MARKET_SECTIONS[section]
        
        # 2. å¸‚å€¼è¿‡æ»¤ - ä½¿ç”¨æ¿å—ç‰¹å®šçš„é˜ˆå€¼
        market_cap = calculate_market_cap(df, stock_code)
        if market_cap < section_config["min_market_cap"]:
            logger.debug(f"è‚¡ç¥¨ {stock_code}({section}) è¢«è¿‡æ»¤ - å¸‚å€¼ä¸è¶³({market_cap:.2f}äº¿å…ƒ < {section_config['min_market_cap']}äº¿å…ƒ)")
            return False
        if market_cap > section_config["max_market_cap"]:
            logger.debug(f"è‚¡ç¥¨ {stock_code}({section}) è¢«è¿‡æ»¤ - å¸‚å€¼è¿‡å¤§({market_cap:.2f}äº¿å…ƒ > {section_config['max_market_cap']}äº¿å…ƒ)")
            return False
            
        # 3. æ³¢åŠ¨ç‡è¿‡æ»¤ - ä½¿ç”¨æ¿å—ç‰¹å®šçš„é˜ˆå€¼
        volatility = calculate_annual_volatility(df)
        if volatility < section_config["min_volatility"] or volatility > section_config["max_volatility"]:
            logger.debug(f"è‚¡ç¥¨ {stock_code}({section}) è¢«è¿‡æ»¤ - æ³¢åŠ¨ç‡å¼‚å¸¸({volatility:.2%}ä¸åœ¨{section_config['min_volatility']:.2%}-{section_config['max_volatility']:.2%}èŒƒå›´å†…)")
            return False
            
        # 4. æµåŠ¨æ€§è¿‡æ»¤ - ä½¿ç”¨æ¿å—ç‰¹å®šçš„é˜ˆå€¼
        avg_volume = calculate_avg_volume(df)
        if avg_volume < section_config["min_daily_volume"] / 10000:  # è½¬æ¢ä¸ºä¸‡å…ƒ
            logger.debug(f"è‚¡ç¥¨ {stock_code}({section}) è¢«è¿‡æ»¤ - æµåŠ¨æ€§ä¸è¶³(æ—¥å‡æˆäº¤é¢{avg_volume:.2f}ä¸‡å…ƒ < {section_config['min_daily_volume']/10000:.2f}ä¸‡å…ƒ)")
            return False
            
        logger.debug(f"è‚¡ç¥¨ {stock_code}({section}) é€šè¿‡æ‰€æœ‰è¿‡æ»¤æ¡ä»¶")
        return True
        
    except Exception as e:
        logger.error(f"è‚¡ç¥¨ {stock_code} è¿‡æ»¤æ£€æŸ¥å¤±è´¥: {str(e)}", exc_info=True)
        return False

def calculate_avg_volume(df: pd.DataFrame) -> float:
    """è®¡ç®—æ—¥å‡æˆäº¤é¢ï¼ˆä¸‡å…ƒï¼‰"""
    if df is None or df.empty or "æˆäº¤é‡" not in df.columns or "æ”¶ç›˜" not in df.columns:
        return 0.0
    
    # è®¡ç®—æ—¥å‡æˆäº¤é¢ï¼ˆå…ƒï¼‰
    avg_volume = df["æˆäº¤é‡"].iloc[-20:].mean() * 100 * df["æ”¶ç›˜"].iloc[-20:].mean()
    # è½¬æ¢ä¸ºä¸‡å…ƒ
    return avg_volume / 10000

def calculate_stock_strategy_score(stock_code: str, df: pd.DataFrame) -> float:
    """è®¡ç®—è‚¡ç¥¨ç­–ç•¥è¯„åˆ†
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        df: é¢„å¤„ç†åçš„è‚¡ç¥¨æ•°æ®
    
    Returns:
        float: è¯„åˆ†(0-100)
    """
    try:
        if df is None or df.empty or len(df) < 40:
            logger.debug(f"è‚¡ç¥¨ {stock_code} æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—ç­–ç•¥è¯„åˆ†")
            return 0.0
        
        # æ£€æŸ¥å¿…è¦åˆ—
        required_columns = ['å¼€ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æ”¶ç›˜', 'æˆäº¤é‡']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            logger.debug(f"è‚¡ç¥¨ {stock_code} æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {', '.join(missing_columns)}ï¼Œæ— æ³•è®¡ç®—ç­–ç•¥è¯„åˆ†")
            return 0.0
        
        # è·å–æœ€æ–°æ•°æ®
        current = df["æ”¶ç›˜"].iloc[-1]
        if pd.isna(current) or current <= 0:
            logger.debug(f"è‚¡ç¥¨ {stock_code} æ— æ•ˆçš„æ”¶ç›˜ä»·: {current}")
            return 0.0
        
        volume = df["æˆäº¤é‡"].iloc[-1] if "æˆäº¤é‡" in df.columns and len(df) >= 1 else 0
        
        # è·å–è‚¡ç¥¨æ‰€å±æ¿å—
        section = get_stock_section(stock_code)
        
        # 1. è¶‹åŠ¿è¯„åˆ† (40%)
        trend_score = 0.0
        if len(df) >= 40:
            # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
            df["ma5"] = df["æ”¶ç›˜"].rolling(window=5).mean()
            df["ma10"] = df["æ”¶ç›˜"].rolling(window=10).mean()
            df["ma20"] = df["æ”¶ç›˜"].rolling(window=20).mean()
            df["ma40"] = df["æ”¶ç›˜"].rolling(window=CRITICAL_VALUE_DAYS).mean()
            
            ma5 = df["ma5"].iloc[-1] if "ma5" in df.columns else current
            ma10 = df["ma10"].iloc[-1] if "ma10" in df.columns else current
            ma20 = df["ma20"].iloc[-1] if "ma20" in df.columns else current
            ma40 = df["ma40"].iloc[-1] if "ma40" in df.columns else current
            
            # æ£€æŸ¥çŸ­æœŸå‡çº¿æ˜¯å¦åœ¨é•¿æœŸå‡çº¿ä¸Šæ–¹ï¼ˆå¤šå¤´æ’åˆ—ï¼‰
            if (not pd.isna(ma5) and not pd.isna(ma10) and not pd.isna(ma20) and not pd.isna(ma40) and
                ma5 > ma10 > ma20 > ma40):
                trend_score += 20  # å¤šå¤´æ’åˆ—ï¼ŒåŠ 20åˆ†
            
            # æ£€æŸ¥ä»·æ ¼æ˜¯å¦åœ¨å‡çº¿ä¸Šæ–¹
            if not pd.isna(ma20) and current > ma20:
                trend_score += 10  # ä»·æ ¼åœ¨20æ—¥å‡çº¿ä¸Šæ–¹ï¼ŒåŠ 10åˆ†
            
            # æ£€æŸ¥è¶‹åŠ¿å¼ºåº¦
            if len(df) >= 20:
                price_change_20 = (current - df["æ”¶ç›˜"].iloc[-20]) / df["æ”¶ç›˜"].iloc[-20] * 100
                if not pd.isna(price_change_20) and price_change_20 > 5:
                    trend_score += 10  # 20æ—¥æ¶¨å¹…å¤§äº5%ï¼ŒåŠ 10åˆ†
        
        # 2. åŠ¨é‡è¯„åˆ† (20%)
        momentum_score = 0.0
        # è®¡ç®—MACD
        if "æ”¶ç›˜" in df.columns:
            df["ema12"] = df["æ”¶ç›˜"].ewm(span=12, adjust=False).mean()
            df["ema26"] = df["æ”¶ç›˜"].ewm(span=26, adjust=False).mean()
            df["macd"] = df["ema12"] - df["ema26"]
            df["signal"] = df["macd"].ewm(span=9, adjust=False).mean()
            df["hist"] = df["macd"] - df["signal"]
        
        if "hist" in df.columns and len(df) >= 2:
            macd_hist = df["hist"].iloc[-1]
            macd_hist_prev = df["hist"].iloc[-2]
            
            # MACDæŸ±çŠ¶ä½“å¢åŠ 
            if (not pd.isna(macd_hist) and not pd.isna(macd_hist_prev) and 
                macd_hist > macd_hist_prev and macd_hist > 0):
                momentum_score += 10  # MACDæŸ±çŠ¶ä½“å¢åŠ ä¸”ä¸ºæ­£ï¼ŒåŠ 10åˆ†
            
            # RSIæŒ‡æ ‡
            if "æ”¶ç›˜" in df.columns:
                delta = df["æ”¶ç›˜"].diff()
                gain = delta.where(delta > 0, 0)
                loss = -delta.where(delta < 0, 0)
                avg_gain = gain.rolling(window=14).mean()
                avg_loss = loss.rolling(window=14).mean()
                rs = avg_gain / avg_loss.replace(0, np.nan)  # é¿å…é™¤é›¶é”™è¯¯
                df["rsi"] = 100 - (100 / (1 + rs))
            
            if "rsi" in df.columns:
                rsi = df["rsi"].iloc[-1]
                if not pd.isna(rsi):
                    if 50 < rsi < 70:
                        momentum_score += 10  # RSIåœ¨50-70ä¹‹é—´ï¼ŒåŠ 10åˆ†
                    elif rsi >= 70:
                        momentum_score += 5  # RSIå¤§äº70ï¼ŒåŠ 5åˆ†
        
        # 3. é‡èƒ½è¯„åˆ† (20%)
        volume_score = 0.0
        if "æˆäº¤é‡" in df.columns:
            df["volume_ma5"] = df["æˆäº¤é‡"].rolling(window=5).mean()
        
        volume_ma5 = df["volume_ma5"].iloc[-1] if "volume_ma5" in df.columns and len(df) >= 1 else 0
        if volume_ma5 > 0 and volume > 0:
            volume_ratio = volume / volume_ma5
            
            # é‡èƒ½æ”¾å¤§
            if volume_ratio > 1.5:
                volume_score += 10  # é‡èƒ½æ”¾å¤§50%ä»¥ä¸Šï¼ŒåŠ 10åˆ†
            elif volume_ratio > 1.2:
                volume_score += 5  # é‡èƒ½æ”¾å¤§20%ä»¥ä¸Šï¼ŒåŠ 5åˆ†
            
            # é‡ä»·é…åˆ
            if len(df) >= 2:
                price_change = (current - df["æ”¶ç›˜"].iloc[-2]) / df["æ”¶ç›˜"].iloc[-2] * 100
                if price_change > 0 and volume_ratio > 1.0:
                    volume_score += 10  # ä»·æ ¼ä¸Šæ¶¨ä¸”é‡èƒ½æ”¾å¤§ï¼ŒåŠ 10åˆ†
        
        # 4. æ³¢åŠ¨ç‡è¯„åˆ† (20%)
        volatility_score = 0.0
        # è®¡ç®—æ³¢åŠ¨ç‡ï¼ˆ20æ—¥å¹´åŒ–æ³¢åŠ¨ç‡ï¼‰
        if "æ”¶ç›˜" in df.columns:
            df["pct_change"] = df["æ”¶ç›˜"].pct_change() * 100
        
        if "pct_change" in df.columns:
            df["volatility"] = df["pct_change"].rolling(window=20).std() * np.sqrt(252)
        
        if "volatility" in df.columns and len(df) >= 20:
            volatility = df["volatility"].iloc[-1]
            
            if not pd.isna(volatility):
                # æ ¹æ®ä¸åŒæ¿å—è®¾ç½®ä¸åŒçš„æ³¢åŠ¨ç‡è¯„åˆ†æ ‡å‡†
                if section == "æ²ªå¸‚ä¸»æ¿":
                    # æ²ªå¸‚ä¸»æ¿ï¼šæ³¢åŠ¨ç‡åœ¨15%-25%ä¸ºæœ€ä½³
                    if 0.15 <= volatility <= 0.25:
                        volatility_score += 10
                    elif volatility > 0.25:
                        volatility_score += 5
                elif section == "æ·±å¸‚ä¸»æ¿":
                    # æ·±å¸‚ä¸»æ¿ï¼šæ³¢åŠ¨ç‡åœ¨18%-28%ä¸ºæœ€ä½³
                    if 0.18 <= volatility <= 0.28:
                        volatility_score += 10
                    elif volatility > 0.28:
                        volatility_score += 5
                elif section == "åˆ›ä¸šæ¿":
                    # åˆ›ä¸šæ¿ï¼šæ³¢åŠ¨ç‡åœ¨20%-35%ä¸ºæœ€ä½³
                    if 0.20 <= volatility <= 0.35:
                        volatility_score += 10
                    elif volatility > 0.35:
                        volatility_score += 5
                elif section == "ç§‘åˆ›æ¿":
                    # ç§‘åˆ›æ¿ï¼šæ³¢åŠ¨ç‡åœ¨25%-40%ä¸ºæœ€ä½³
                    if 0.25 <= volatility <= 0.40:
                        volatility_score += 10
                    elif volatility > 0.40:
                        volatility_score += 5
                
                # æ³¢åŠ¨ç‡è¶‹åŠ¿
                if len(df) >= 21:
                    prev_volatility = df["volatility"].iloc[-21]
                    if not pd.isna(prev_volatility) and prev_volatility > 0:
                        volatility_change = (volatility - prev_volatility) / prev_volatility
                        
                        if -0.1 <= volatility_change <= 0.1:
                            volatility_score += 10  # æ³¢åŠ¨ç‡ç¨³å®šï¼ŒåŠ 10åˆ†
        
        # ç»¼åˆè¯„åˆ†
        total_score = trend_score + momentum_score + volume_score + volatility_score
        total_score = max(0, min(100, total_score))  # é™åˆ¶åœ¨0-100èŒƒå›´å†…
        
        logger.debug(f"è‚¡ç¥¨ {stock_code}({section}) ç­–ç•¥è¯„åˆ†: {total_score:.2f} "
                     f"(è¶‹åŠ¿={trend_score:.1f}, åŠ¨é‡={momentum_score:.1f}, "
                     f"é‡èƒ½={volume_score:.1f}, æ³¢åŠ¨ç‡={volatility_score:.1f})")
        
        return total_score
    
    except Exception as e:
        logger.error(f"è®¡ç®—è‚¡ç¥¨ {stock_code} ç­–ç•¥è¯„åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        return 0.0

# ========== ä»¥ä¸‹æ˜¯å…³é”®ä¿®æ”¹ ==========
# ç¼“å­˜å­—å…¸
FILTER_CACHE = {}
SCORE_CACHE = {}
CACHE_EXPIRY = timedelta(hours=1)  # ç¼“å­˜æœ‰æ•ˆæœŸ
def get_cached_filter_result(stock_code: str, last_update: datetime) -> Optional[bool]:
    """è·å–ç¼“å­˜çš„ç­›é€‰ç»“æœ"""
    if stock_code in FILTER_CACHE:
        cached_result, cache_time = FILTER_CACHE[stock_code]
        if datetime.now() - cache_time < CACHE_EXPIRY:
            return cached_result
    return None

def cache_filter_result(stock_code: str, result: bool):
    """ç¼“å­˜ç­›é€‰ç»“æœ"""
    FILTER_CACHE[stock_code] = (result, datetime.now())

def get_cached_score(stock_code: str, last_update: datetime) -> Optional[float]:
    """è·å–ç¼“å­˜çš„è¯„åˆ†ç»“æœ"""
    if stock_code in SCORE_CACHE:
        cached_score, cache_time = SCORE_CACHE[stock_code]
        if datetime.now() - cache_time < CACHE_EXPIRY:
            return cached_score
    return None

def cache_score(stock_code: str, score: float):
    """ç¼“å­˜è¯„åˆ†ç»“æœ"""
    SCORE_CACHE[stock_code] = (score, datetime.now())
# ========== ä»¥ä¸Šæ˜¯å…³é”®ä¿®æ”¹ ==========

def get_top_stocks_for_strategy() -> Dict[str, List[Dict]]:
    """æŒ‰æ¿å—è·å–é€‚åˆç­–ç•¥çš„è‚¡ç¥¨ï¼ˆä½¿ç”¨æœ¬åœ°å·²ä¿å­˜æ•°æ®ï¼‰"""
    try:
        logger.info("===== å¼€å§‹æ‰§è¡Œä¸ªè‚¡è¶‹åŠ¿ç­–ç•¥(TickTen) =====")
        
        # 1. è·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
        basic_info_df = load_stock_basic_info()
        if basic_info_df.empty:
            logger.error("è·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
            return {}
        
        logger.info(f"å·²åŠ è½½è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ï¼Œå…± {len(basic_info_df)} æ¡è®°å½•")
        
        # 2. æŒ‰æ¿å—åˆ†ç»„å¤„ç†
        section_stocks = {section: [] for section in MARKET_SECTIONS.keys()}
        
        # 3. åˆå§‹åŒ–å„æ¿å—è®¡æ•°å™¨ï¼ˆæ·»åŠ è¯¦ç»†è¿‡æ»¤åŸå› ç»Ÿè®¡ï¼‰
        section_counts = {section: {
            "total": 0, 
            "data_ok": 0, 
            "market_cap_filtered": 0,
            "volatility_filtered": 0,
            "liquidity_filtered": 0,
            "data_filtered": 0,
            "suitable": 0,
            "scored": 0
        } for section in MARKET_SECTIONS.keys()}
        
        # 4. å¤„ç†æ¯åªè‚¡ç¥¨
        stock_list = basic_info_df.to_dict('records')
        logger.info(f"å¼€å§‹å¤„ç† {len(stock_list)} åªè‚¡ç¥¨...")
        
        # ç¡®ä¿æ‰€æœ‰è‚¡ç¥¨ä»£ç æ˜¯å­—ç¬¦ä¸²æ ¼å¼ï¼ˆ6ä½ï¼Œå‰é¢è¡¥é›¶ï¼‰
        for stock in stock_list:
            stock["code"] = str(stock["code"]).zfill(6)
        
        logger.info(f"ä»Šå¤©å®é™…å¤„ç† {len(stock_list)} åªè‚¡ç¥¨ï¼ˆå®Œæ•´å¤„ç†ï¼‰")
        
        def process_stock(stock):
            # ç¡®ä¿è‚¡ç¥¨ä»£ç æ˜¯å­—ç¬¦ä¸²ï¼Œå¹¶ä¸”æ˜¯6ä½ï¼ˆå‰é¢è¡¥é›¶ï¼‰
            stock_code = str(stock["code"]).zfill(6)
            stock_name = stock["name"]
            section = stock["section"]
            
            # æ£€æŸ¥æ¿å—æ˜¯å¦æœ‰æ•ˆ
            if section not in MARKET_SECTIONS:
                return None
            
            # æ›´æ–°æ¿å—è®¡æ•°å™¨
            section_counts[section]["total"] += 1
            
            # 1. å°è¯•ä»ç¼“å­˜è·å–ç»“æœ
            last_update = get_last_update_time(basic_info_df, stock_code)
            cached_result = get_cached_filter_result(stock_code, last_update)
            if cached_result is not None:
                logger.debug(f"è‚¡ç¥¨ {stock_code} ä½¿ç”¨ç¼“å­˜ç­›é€‰ç»“æœ: {cached_result}")
                if not cached_result:
                    return None
                
                cached_score = get_cached_score(stock_code, last_update)
                if cached_score is not None and cached_score > 0:
                    # ä»æœ¬åœ°åŠ è½½æ•°æ®
                    df = get_stock_daily_data(stock_code)
                    if not df.empty:
                        return {
                            "code": stock_code,
                            "name": stock_name,
                            "score": cached_score,
                            "df": df,
                            "section": section
                        }
            
            # 2. è·å–æ—¥çº¿æ•°æ®ï¼ˆä»æœ¬åœ°åŠ è½½ï¼‰
            df = get_stock_daily_data(stock_code)
            
            # 3. æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
            data_level, data_days = check_data_integrity(df)
            logger.debug(f"è‚¡ç¥¨ {stock_code} æ•°æ®å®Œæ•´æ€§: {data_level} ({data_days}å¤©)")
            
            # 4. æ ¹æ®æ•°æ®å®Œæ•´æ€§åº”ç”¨ä¸åŒç­–ç•¥
            if data_level == "insufficient" or data_level == "corrupted":
                section_counts[section]["data_filtered"] += 1
                logger.debug(f"è‚¡ç¥¨ {stock_code} è¢«è¿‡æ»¤ - æ•°æ®é‡ä¸è¶³({data_days}å¤©)")
                cache_filter_result(stock_code, False)
                return None
            
            # æ£€æŸ¥å¸‚å€¼æ•°æ®æ˜¯å¦å¯é 
            market_cap = calculate_market_cap(df, stock_code)
            if market_cap <= 0:
                logger.warning(f"âš ï¸ è‚¡ç¥¨ {stock_code} å¸‚å€¼æ•°æ®ä¸å¯é ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                market_cap = 50.0  # ä½¿ç”¨é»˜è®¤å¸‚å€¼
            
            # æ£€æŸ¥æ˜¯å¦é€‚åˆç­–ç•¥
            if not is_stock_suitable(stock_code, df, data_level, data_days):
                # è®°å½•å…·ä½“è¿‡æ»¤åŸå› 
                if market_cap < MARKET_SECTIONS[section]["min_market_cap"]:
                    section_counts[section]["market_cap_filtered"] += 1
                    logger.debug(f"è‚¡ç¥¨ {stock_code} è¢«è¿‡æ»¤ - å¸‚å€¼ä¸è¶³")
                elif calculate_annual_volatility(df) < MARKET_SECTIONS[section]["min_volatility"] or \
                     calculate_annual_volatility(df) > MARKET_SECTIONS[section]["max_volatility"]:
                    section_counts[section]["volatility_filtered"] += 1
                    logger.debug(f"è‚¡ç¥¨ {stock_code} è¢«è¿‡æ»¤ - æ³¢åŠ¨ç‡å¼‚å¸¸")
                elif calculate_avg_volume(df) < MARKET_SECTIONS[section]["min_daily_volume"] / 10000:
                    section_counts[section]["liquidity_filtered"] += 1
                    logger.debug(f"è‚¡ç¥¨ {stock_code} è¢«è¿‡æ»¤ - æµåŠ¨æ€§ä¸è¶³")
                else:
                    logger.debug(f"è‚¡ç¥¨ {stock_code} è¢«è¿‡æ»¤ - æœªçŸ¥åŸå› ")
                
                cache_filter_result(stock_code, False)
                return None
            
            section_counts[section]["suitable"] += 1
            
            # 5. è®¡ç®—ç­–ç•¥å¾—åˆ†
            score = calculate_stock_strategy_score(stock_code, df)
            
            if score > 0:
                # 6. ç¼“å­˜ç»“æœ
                cache_filter_result(stock_code, True)
                cache_score(stock_code, score)
                
                # 7. æ›´æ–°æ¿å—è®¡æ•°å™¨
                section_counts[section]["scored"] += 1
                
                return {
                    "code": stock_code,
                    "name": stock_name,
                    "score": score,
                    "df": df,
                    "section": section
                }
            
            # 7. ç¼“å­˜ç­›é€‰å¤±è´¥ç»“æœ
            cache_filter_result(stock_code, False)
            return None
        
        # 6. å¹¶è¡Œå¤„ç†è‚¡ç¥¨ï¼ˆä¼˜åŒ–å¹¶å‘å‚æ•°ï¼‰
        results = []
        # é™ä½å¹¶å‘æ•°ï¼Œç¡®ä¿ä¸ä¼šè§¦å‘AkShareé™åˆ¶
        with ThreadPoolExecutor(max_workers=5) as executor:
            # å¢åŠ æ¯æ‰¹å¤„ç†çš„è‚¡ç¥¨æ•°é‡
            for i in range(0, len(stock_list), 15):
                batch = stock_list[i:i+15]
                batch_results = list(executor.map(process_stock, batch))
                results.extend(batch_results)
                # å‡å°‘ç­‰å¾…æ—¶é—´
                time.sleep(0.8)
        
        # 7. æ”¶é›†ç»“æœ
        for result in results:
            if result is not None:
                section = result["section"]
                section_stocks[section].append(result)
        
        # 8. è®°å½•å„æ¿å—ç­›é€‰ç»“æœï¼ˆåŒ…å«è¯¦ç»†è¿‡æ»¤åŸå› ï¼‰
        for section, counts in section_counts.items():
            if counts["total"] > 0:
                logger.info(f"ã€ç­›é€‰è¯¦ç»†ç»Ÿè®¡ã€‘æ¿å— {section}:")
                logger.info(f"  - æ€»è‚¡ç¥¨æ•°é‡: {counts['total']}")
                logger.info(f"  - æ•°æ®é‡ä¸è¶³: {counts['data_filtered']} ({counts['data_filtered']/counts['total']*100:.1f}%)")
                logger.info(f"  - å¸‚å€¼è¿‡æ»¤: {counts['market_cap_filtered']} ({counts['market_cap_filtered']/counts['total']*100:.1f}%)")
                logger.info(f"  - æ³¢åŠ¨ç‡è¿‡æ»¤: {counts['volatility_filtered']} ({counts['volatility_filtered']/counts['total']*100:.1f}%)")
                logger.info(f"  - æµåŠ¨æ€§è¿‡æ»¤: {counts['liquidity_filtered']} ({counts['liquidity_filtered']/counts['total']*100:.1f}%)")
                logger.info(f"  - é€šè¿‡ä¸‰é‡è¿‡æ»¤: {counts['suitable']} ({counts['suitable']/counts['total']*100:.1f}%)")
                logger.info(f"  - è¯„åˆ†>0: {counts['scored']} ({counts['scored']/counts['total']*100:.1f}%)")
        
        # 9. å¯¹æ¯ä¸ªæ¿å—çš„è‚¡ç¥¨æŒ‰å¾—åˆ†æ’åºï¼Œå¹¶å–å‰Nåª
        top_stocks_by_section = {}
        for section, stocks in section_stocks.items():
            if stocks:
                stocks.sort(key=lambda x: x["score"], reverse=True)
                top_stocks = stocks[:MAX_STOCKS_PER_SECTION]
                top_stocks_by_section[section] = top_stocks
                logger.info(f"ã€æœ€ç»ˆç»“æœã€‘æ¿å— {section} ç­›é€‰å‡º {len(top_stocks)} åªè‚¡ç¥¨")
                # è®°å½•ç­›é€‰å‡ºçš„è‚¡ç¥¨è¯¦æƒ…
                for i, stock in enumerate(top_stocks):
                    logger.info(f"  {i+1}. {stock['name']}({stock['code']}) - è¯„åˆ†: {stock['score']:.2f}")
            else:
                logger.info(f"ã€æœ€ç»ˆç»“æœã€‘æ¿å— {section} æ— ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
        
        # 10. æ›´æ–°åŸºç¡€ä¿¡æ¯ä¸­çš„å¸‚å€¼å’Œè¯„åˆ†
        updated_records = []
        for section, stocks in top_stocks_by_section.items():
            for stock in stocks:
                stock_code = str(stock["code"]).zfill(6)
                stock_name = stock["name"]
                section = stock["section"]
                market_cap = calculate_market_cap(stock["df"], stock_code)
                score = stock["score"]
                
                # æ›´æ–°åŸºç¡€ä¿¡æ¯
                updated_records.append({
                    "code": stock_code,
                    "name": stock_name,
                    "section": section,
                    "market_cap": market_cap,
                    "score": score,
                    "last_update": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                })
        
        # 11. ä¿å­˜æ›´æ–°åçš„åŸºç¡€ä¿¡æ¯
        if updated_records:
            # åˆ›å»ºä¸´æ—¶DataFrameç”¨äºæ›´æ–°
            update_df = pd.DataFrame(updated_records)
            
            # ä»…æ›´æ–°å¸‚å€¼å’Œè¯„åˆ†ï¼Œä¸æ”¹å˜åŸºç¡€ä¿¡æ¯ç»“æ„
            for _, record in update_df.iterrows():
                mask = basic_info_df["code"] == record["code"]
                if mask.any():
                    # æ›´æ–°ç°æœ‰è®°å½•çš„å¸‚å€¼å’Œè¯„åˆ†
                    basic_info_df.loc[mask, "market_cap"] = record["market_cap"]
                    basic_info_df.loc[mask, "score"] = record["score"]
                    basic_info_df.loc[mask, "last_update"] = record["last_update"]
            
            # 12. ä¿å­˜æ›´æ–°
            basic_info_df.to_csv(BASIC_INFO_FILE, index=False)
            logger.info(f"è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å·²æ›´æ–°ï¼Œå…± {len(basic_info_df)} æ¡è®°å½•")
            
            # ä½¿ç”¨ git_utils.py ä¸­å·²æœ‰çš„å·¥å…·å‡½æ•°
            try:
                logger.info("æ­£åœ¨æäº¤æ›´æ–°åçš„è‚¡ç¥¨åŸºç¡€ä¿¡æ¯åˆ°GitHubä»“åº“...")
                commit_message = "è‡ªåŠ¨æ›´æ–°è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ [ç­–ç•¥æ‰§è¡Œ]"
                if commit_and_push_file(BASIC_INFO_FILE, commit_message):
                    logger.info("æ›´æ–°åçš„è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å·²æˆåŠŸæäº¤å¹¶æ¨é€åˆ°GitHubä»“åº“")
                else:
                    logger.warning("æäº¤æ›´æ–°åçš„è‚¡ç¥¨åŸºç¡€ä¿¡æ¯åˆ°GitHubä»“åº“å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œç­–ç•¥")
            except Exception as e:
                logger.warning(f"æäº¤æ›´æ–°åçš„è‚¡ç¥¨åŸºç¡€ä¿¡æ¯åˆ°GitHubä»“åº“å¤±è´¥: {str(e)}")
                logger.warning(traceback.format_exc())
        
        return top_stocks_by_section
    
    except Exception as e:
        logger.error(f"è·å–ä¼˜è´¨è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {str(e)}", exc_info=True)
        logger.error(traceback.format_exc())
        return {}

def generate_strategy_summary(top_stocks_by_section: Dict[str, List[Dict]]) -> str:
    """ç”Ÿæˆç­–ç•¥æ€»ç»“æ¶ˆæ¯
    
    Args:
        top_stocks_by_section: æŒ‰æ¿å—ç»„ç»‡çš„è‚¡ç¥¨ä¿¡æ¯
    
    Returns:
        str: ç­–ç•¥æ€»ç»“æ¶ˆæ¯
    """
    summary_lines = []
    
    # æ·»åŠ æ ‡é¢˜
    beijing_time = get_beijing_time()
    summary_lines.append(f"ğŸ“Š ä¸ªè‚¡è¶‹åŠ¿ç­–ç•¥æŠ¥å‘Š ({beijing_time.strftime('%Y-%m-%d %H:%M')})")
    summary_lines.append("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    
    # æ·»åŠ å„æ¿å—ç»“æœ
    total_stocks = 0
    for section, stocks in top_stocks_by_section.items():
        if stocks:
            summary_lines.append(f"ğŸ“Œ {section}æ¿å— ({len(stocks)}åª):")
            for stock in stocks:
                stock_code = stock["code"]
                stock_name = stock["name"]
                score = stock["score"]
                summary_lines.append(f"   â€¢ {stock_name}({stock_code}) {score:.1f}åˆ†")
            total_stocks += len(stocks)
    
    summary_lines.append(f"ğŸ“Š æ€»è®¡: {total_stocks}åªè‚¡ç¥¨ï¼ˆæ¯æ¿å—æœ€å¤š{MAX_STOCKS_PER_SECTION}åªï¼‰")
    summary_lines.append("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    
    # æ·»åŠ æ“ä½œæŒ‡å—
    summary_lines.append("ğŸ’¡ æ“ä½œæŒ‡å—:")
    summary_lines.append("1. è¯„åˆ†è¶Šé«˜ï¼Œè¶‹åŠ¿è¶Šå¼ºï¼Œå¯è€ƒè™‘é€‚å½“å¢åŠ ä»“ä½")
    summary_lines.append("2. æ¯åªä¸ªè‚¡ä»“ä½â‰¤15%ï¼Œåˆ†æ•£æŠ•èµ„5-8åª")
    
    summary_message = "\n".join(summary_lines)
    return summary_message

def main():
    """ä¸»å‡½æ•°"""
    try:
        logger.info("===== å¼€å§‹æ‰§è¡Œä¸ªè‚¡è¶‹åŠ¿ç­–ç•¥(TickTen) =====")
        
        # 1. è·å–é€‚åˆç­–ç•¥çš„è‚¡ç¥¨
        top_stocks_by_section = get_top_stocks_for_strategy()
        
        # 2. ç”Ÿæˆç­–ç•¥æ€»ç»“æ¶ˆæ¯
        summary_message = generate_strategy_summary(top_stocks_by_section)
        
        # 3. æ¨é€å…¨å¸‚åœºç­–ç•¥æ€»ç»“æ¶ˆæ¯
        logger.info("æ¨é€å…¨å¸‚åœºç­–ç•¥æ€»ç»“æ¶ˆæ¯")
        send_wechat_message(summary_message, message_type="stock_tickten")
        
        logger.info("ä¸ªè‚¡ç­–ç•¥æŠ¥å‘Šå·²æˆåŠŸå‘é€è‡³ä¼ä¸šå¾®ä¿¡")
        logger.info("===== ä¸ªè‚¡è¶‹åŠ¿ç­–ç•¥(TickTen)æ‰§è¡Œå®Œæˆ =====")
    
    except Exception as e:
        error_msg = f"ä¸ªè‚¡è¶‹åŠ¿ç­–ç•¥æ‰§è¡Œå¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        logger.error(traceback.format_exc())
        send_wechat_message(error_msg, message_type="error")

if __name__ == "__main__":
    main()
