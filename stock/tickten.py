#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸ªè‚¡è¶‹åŠ¿è·Ÿè¸ªç­–ç•¥ï¼ˆTickTenç­–ç•¥ï¼‰
åŸºäºæœ¬åœ°å·²ä¿å­˜çš„è‚¡ç¥¨æ—¥çº¿æ•°æ®ï¼Œåº”ç”¨æµåŠ¨æ€§ã€æ³¢åŠ¨ç‡ã€å¸‚å€¼ä¸‰é‡è¿‡æ»¤ï¼Œç­›é€‰ä¼˜è´¨ä¸ªè‚¡
æŒ‰æ¿å—åˆ†ç±»æ¨é€ï¼Œæ¯ä¸ªæ¿å—æœ€å¤š10åªï¼Œå…±40åª
"""

import os
import logging
import pandas as pd
import numpy as np
import time
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Any
# ========== ä»¥ä¸‹æ˜¯å…³é”®ä¿®æ”¹ ==========
from concurrent.futures import ThreadPoolExecutor
# ========== ä»¥ä¸Šæ˜¯å…³é”®ä¿®æ”¹ ==========

# ===== æ–°å¢å¯¼å…¥ =====
import sys
import traceback
# ===== æ–°å¢å¯¼å…¥ç»“æŸ =====

from config import Config
from utils.date_utils import (
    get_current_times,
    get_beijing_time,
    get_utc_time
)
from wechat_push.push import send_wechat_message
from utils.git_utils import commit_and_push_file  # ç¡®ä¿å¯¼å…¥è¿™ä¸ªå‡½æ•°

# åˆå§‹åŒ–æ—¥å¿—
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
handler = logging.StreamHandler()
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

# ========== ä»¥ä¸‹æ˜¯å…³é”®ä¿®æ”¹ ==========
# å®šä¹‰è‚¡ç¥¨åŸºç¡€ä¿¡æ¯æ–‡ä»¶è·¯å¾„
BASIC_INFO_FILE = "data/all_stocks.csv"

# æ•°æ®æ›´æ–°é—´éš”ï¼ˆå¤©ï¼‰
DATA_UPDATE_INTERVAL = 1
# ========== ä»¥ä¸Šæ˜¯å…³é”®ä¿®æ”¹ ==========

# è‚¡ç¥¨æ¿å—é…ç½®
MARKET_SECTIONS = {
    "æ²ªå¸‚ä¸»æ¿": {
        "prefix": ["60"],
        "min_daily_volume": 5 * 10000,  # æ—¥å‡æˆäº¤é¢é˜ˆå€¼(å…ƒ)
        "min_volatility": 0.05,  # æœ€å°æ³¢åŠ¨ç‡
        "max_volatility": 0.40,  # æœ€å¤§æ³¢åŠ¨ç‡
        "min_market_cap": 5,  # æœ€å°å¸‚å€¼(äº¿å…ƒ)
        "max_market_cap": 2000  # æœ€å¤§å¸‚å€¼(äº¿å…ƒ)
    },
    "æ·±å¸‚ä¸»æ¿": {
        "prefix": ["00"],
        "min_daily_volume": 5 * 10000,
        "min_volatility": 0.05,
        "max_volatility": 0.40,
        "min_market_cap": 5,
        "max_market_cap": 2000
    },
    "åˆ›ä¸šæ¿": {
        "prefix": ["30"],
        "min_daily_volume": 5 * 10000,  # ä¿®å¤ï¼šç»Ÿä¸€å•ä½ä¸ºå…ƒ
        "min_volatility": 0.05,
        "max_volatility": 0.40,
        "min_market_cap": 5,
        "max_market_cap": 2000
    },
    "ç§‘åˆ›æ¿": {
        "prefix": ["688"],
        "min_daily_volume": 5 * 10000,  # ä¿®å¤ï¼šç»Ÿä¸€å•ä½ä¸ºå…ƒ
        "min_volatility": 0.05,
        "max_volatility": 0.40,
        "min_market_cap": 5,
        "max_market_cap": 2000
    }
}

# å…¶ä»–å‚æ•°
MIN_DATA_DAYS = 30  # æœ€å°æ•°æ®å¤©æ•°ï¼ˆç”¨äºè®¡ç®—æŒ‡æ ‡ï¼‰
MAX_STOCKS_TO_ANALYZE = 300  # å‡å°‘æ¯æ¬¡åˆ†æçš„æœ€å¤§è‚¡ç¥¨æ•°é‡ï¼ˆé¿å…è¯·æ±‚è¿‡å¤šï¼‰
MAX_STOCKS_PER_SECTION = 8  # æ¯ä¸ªæ¿å—æœ€å¤šæŠ¥å‘Šçš„è‚¡ç¥¨æ•°é‡
CRITICAL_VALUE_DAYS = 40  # ä¸´ç•Œå€¼è®¡ç®—å¤©æ•°


def check_data_integrity(df: pd.DataFrame) -> Tuple[str, int]:
    """æ£€æŸ¥æ•°æ®å®Œæ•´æ€§å¹¶è¿”å›çº§åˆ«
    
    Returns:
        (str, int): (å®Œæ•´æ€§çº§åˆ«, æ•°æ®å¤©æ•°)
    """
    if df is None or df.empty:
        return "none", 0
    
    # è®¡ç®—æ•°æ®å¤©æ•°
    data_days = len(df)
    
    # æ£€æŸ¥å¿…è¦åˆ—
    required_columns = ["æ—¥æœŸ", "å¼€ç›˜", "æœ€é«˜", "æœ€ä½", "æ”¶ç›˜", "æˆäº¤é‡"]
    missing_columns = [col for col in required_columns if col not in df.columns]
    
    if missing_columns:
        return "corrupted", data_days
    
    # æ£€æŸ¥æ•°æ®è¿ç»­æ€§
    df = df.copy()
    # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯datetimeç±»å‹
    try:
        df["æ—¥æœŸ"] = pd.to_datetime(df["æ—¥æœŸ"])
    except:
        return "corrupted", data_days
    
    df = df.sort_values("æ—¥æœŸ")
    
    # æ£€æŸ¥æ—¥æœŸé—´éš”
    df["æ—¥æœŸ_diff"] = df["æ—¥æœŸ"].diff().dt.days
    gaps = df[df["æ—¥æœŸ_diff"] > 1]
    
    # è®¡ç®—ç¼ºå¤±ç‡
    expected_days = (df["æ—¥æœŸ"].iloc[-1] - df["æ—¥æœŸ"].iloc[0]).days + 1
    missing_rate = 1 - (data_days / expected_days) if expected_days > 0 else 1
    
    # æ•°æ®å®Œæ•´æ€§åˆ†çº§
    if data_days < MIN_DATA_DAYS:
        return "insufficient", data_days
    elif missing_rate > 0.2:  # ç¼ºå¤±ç‡è¶…è¿‡20%
        return "partial", data_days
    elif gaps.shape[0] > 5:  # æœ‰5ä¸ªä»¥ä¸Šå¤§é—´éš”
        return "gapped", data_days
    else:
        return "complete", data_days

# ========== ä»¥ä¸‹æ˜¯å…³é”®ä¿®æ”¹ ==========
def load_stock_basic_info() -> pd.DataFrame:
    """åŠ è½½è‚¡ç¥¨åŸºç¡€ä¿¡æ¯"""
    try:
        if os.path.exists(BASIC_INFO_FILE):
            df = pd.read_csv(BASIC_INFO_FILE)
            
            # ç¡®ä¿æ‰€æœ‰å¿…è¦åˆ—å­˜åœ¨
            if "code" not in df.columns:
                logger.error(f"è‚¡ç¥¨åŸºç¡€ä¿¡æ¯æ–‡ä»¶ç¼ºå°‘ 'code' åˆ—")
                return pd.DataFrame()
            
            # ç¡®ä¿è‚¡ç¥¨ä»£ç æ˜¯å­—ç¬¦ä¸²æ ¼å¼ï¼Œå¹¶ä¸”æ˜¯6ä½ï¼ˆå‰é¢è¡¥é›¶ï¼‰
            df["code"] = df["code"].astype(str).str.zfill(6)
            
            # å¦‚æœæ²¡æœ‰ section åˆ—ï¼Œæ·»åŠ å¹¶è®¡ç®—
            if "section" not in df.columns:
                df["section"] = df["code"].apply(get_stock_section)
            
            # å¦‚æœæ²¡æœ‰ market_cap åˆ—ï¼Œæ·»åŠ å¹¶åˆå§‹åŒ–
            if "market_cap" not in df.columns:
                df["market_cap"] = 0.0
                
            # å¦‚æœæ²¡æœ‰ score åˆ—ï¼Œæ·»åŠ å¹¶åˆå§‹åŒ–
            if "score" not in df.columns:
                df["score"] = 0.0
                
            # å¦‚æœæ²¡æœ‰ last_update åˆ—ï¼Œæ·»åŠ å¹¶åˆå§‹åŒ–
            if "last_update" not in df.columns:
                df["last_update"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            
            logger.info(f"æˆåŠŸåŠ è½½è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ï¼Œå…± {len(df)} æ¡è®°å½•")
            return df
        else:
            logger.error(f"è‚¡ç¥¨åŸºç¡€ä¿¡æ¯æ–‡ä»¶ {BASIC_INFO_FILE} ä¸å­˜åœ¨")
            return pd.DataFrame()
    except Exception as e:
        logger.error(f"åŠ è½½è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å¤±è´¥: {str(e)}")
        logger.error(traceback.format_exc())
        return pd.DataFrame()

def get_last_update_time(df: pd.DataFrame, stock_code: str) -> Optional[datetime]:
    """è·å–è‚¡ç¥¨æœ€åæ›´æ–°æ—¶é—´"""
    if df.empty:
        return None
    
    stock_info = df[df["code"] == stock_code]
    if not stock_info.empty:
        last_update = stock_info["last_update"].values[0]
        try:
            # å°è¯•è§£ææ—¶é—´å­—ç¬¦ä¸²
            return datetime.strptime(last_update, "%Y-%m-%d %H:%M:%S")
        except Exception as e:
            logger.debug(f"è§£ææ›´æ–°æ—¶é—´å¤±è´¥: {str(e)}")
            return None
    return None
# ========== ä»¥ä¸Šæ˜¯å…³é”®ä¿®æ”¹ ==========

def get_stock_section(stock_code: str) -> str:
    """
    è·å–è‚¡ç¥¨æ‰€å±æ¿å—
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç ï¼ˆä¸å¸¦å¸‚åœºå‰ç¼€ï¼‰
    
    Returns:
        str: æ¿å—åç§°
    """
    # ç¡®ä¿è‚¡ç¥¨ä»£ç æ˜¯å­—ç¬¦ä¸²
    stock_code = str(stock_code).zfill(6)
    
    # ç§»é™¤å¯èƒ½çš„å¸‚åœºå‰ç¼€
    if stock_code.lower().startswith(('sh', 'sz')):
        stock_code = stock_code[2:]
    
    # ç¡®ä¿è‚¡ç¥¨ä»£ç æ˜¯6ä½æ•°å­—
    stock_code = stock_code.zfill(6)
    
    # æ ¹æ®è‚¡ç¥¨ä»£ç å‰ç¼€åˆ¤æ–­æ¿å—
    for section, config in MARKET_SECTIONS.items():
        for prefix in config["prefix"]:
            if stock_code.startswith(prefix):
                return section
    
    return "å…¶ä»–æ¿å—"

def get_stock_daily_data(stock_code: str) -> pd.DataFrame:
    """ä»æœ¬åœ°åŠ è½½è‚¡ç¥¨æ—¥çº¿æ•°æ®"""
    try:
        # ç¡®ä¿è‚¡ç¥¨ä»£ç æ˜¯å­—ç¬¦ä¸²ï¼Œå¹¶ä¸”æ˜¯6ä½ï¼ˆå‰é¢è¡¥é›¶ï¼‰
        stock_code = str(stock_code).zfill(6)
        
        # æ—¥çº¿æ•°æ®ç›®å½•
        daily_dir = os.path.join(Config.DATA_DIR, "daily")
        
        # æ£€æŸ¥æœ¬åœ°æ˜¯å¦æœ‰å†å²æ•°æ®
        file_path = os.path.join(daily_dir, f"{stock_code}.csv")
        if os.path.exists(file_path):
            try:
                df = pd.read_csv(file_path)
                
                # ç¡®ä¿å¿…è¦åˆ—å­˜åœ¨
                required_columns = ["æ—¥æœŸ", "å¼€ç›˜", "æœ€é«˜", "æœ€ä½", "æ”¶ç›˜", "æˆäº¤é‡"]
                for col in required_columns:
                    if col not in df.columns:
                        logger.warning(f"è‚¡ç¥¨ {stock_code} æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {col}")
                        return pd.DataFrame()
                
                # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯å­—ç¬¦ä¸²ç±»å‹
                if "æ—¥æœŸ" in df.columns:
                    df["æ—¥æœŸ"] = df["æ—¥æœŸ"].astype(str)
                    # ç¡®ä¿æ—¥æœŸæ ¼å¼ä¸ºYYYY-MM-DD
                    df["æ—¥æœŸ"] = df["æ—¥æœŸ"].str.replace(r'(\d{4})/(\d{1,2})/(\d{1,2})', 
                                                      lambda m: f"{m.group(1)}-{int(m.group(2)):02d}-{int(m.group(3)):02d}", 
                                                      regex=True)
                    # å¤„ç†å…¶ä»–å¯èƒ½çš„æ ¼å¼
                    df["æ—¥æœŸ"] = df["æ—¥æœŸ"].str.replace(r'(\d{4})-(\d{1,2}) (\d{1,2})', 
                                                      lambda m: f"{m.group(1)}-{int(m.group(2)):02d}-{int(m.group(3)):02d}", 
                                                      regex=True)
                    # ç§»é™¤å¯èƒ½å­˜åœ¨çš„ç©ºæ ¼
                    df["æ—¥æœŸ"] = df["æ—¥æœŸ"].str.strip()
                    df = df.sort_values("æ—¥æœŸ", ascending=True)
                
                # ç§»é™¤NaNå€¼
                df = df.dropna(subset=['æ”¶ç›˜', 'æˆäº¤é‡'])
                
                logger.info(f"æˆåŠŸåŠ è½½è‚¡ç¥¨ {stock_code} çš„æœ¬åœ°æ—¥çº¿æ•°æ®ï¼Œå…± {len(df)} æ¡æœ‰æ•ˆè®°å½•")
                return df
            except Exception as e:
                logger.warning(f"è¯»å–è‚¡ç¥¨ {stock_code} æ•°æ®å¤±è´¥: {str(e)}")
                logger.debug(traceback.format_exc())
        
        logger.warning(f"è‚¡ç¥¨ {stock_code} çš„æ—¥çº¿æ•°æ®ä¸å­˜åœ¨")
        return pd.DataFrame()
    
    except Exception as e:
        logger.error(f"è·å–è‚¡ç¥¨ {stock_code} æ—¥çº¿æ•°æ®å¤±è´¥: {str(e)}", exc_info=True)
        return pd.DataFrame()

def calculate_annual_volatility(df: pd.DataFrame) -> float:
    """è®¡ç®—å¹´åŒ–æ³¢åŠ¨ç‡"""
    if len(df) < 20:
        logger.warning(f"æ•°æ®ä¸è¶³20å¤©ï¼Œæ— æ³•å‡†ç¡®è®¡ç®—æ³¢åŠ¨ç‡")
        return 0.2  # é»˜è®¤æ³¢åŠ¨ç‡
    
    # ç›´æ¥ä½¿ç”¨"æ”¶ç›˜"åˆ—è®¡ç®—æ—¥æ”¶ç›Šç‡ï¼ˆä¸è¿›è¡Œä»»ä½•åˆ—åæ˜ å°„ï¼‰
    daily_returns = df["æ”¶ç›˜"].pct_change().dropna()
    
    # è®¡ç®—å¹´åŒ–æ³¢åŠ¨ç‡
    if len(daily_returns) >= 20:
        volatility = daily_returns.std() * np.sqrt(252)
    else:
        volatility = 0.2  # é»˜è®¤æ³¢åŠ¨ç‡
    
    # é™åˆ¶æ³¢åŠ¨ç‡åœ¨åˆç†èŒƒå›´å†…
    volatility = max(0.05, min(1.0, volatility))
    
    return volatility

# ========== ä»¥ä¸‹æ˜¯å…³é”®ä¿®å¤ ==========
def calculate_market_cap(df: pd.DataFrame, stock_code: str) -> float:
    """è®¡ç®—è‚¡ç¥¨å¸‚å€¼ï¼ˆç›´æ¥ä½¿ç”¨åŸºç¡€ä¿¡æ¯æ–‡ä»¶ä¸­çš„æ•°æ®ï¼‰
    
    Returns:
        float: å¸‚å€¼(äº¿å…ƒ)
    """
    try:
        # 1. ä¼˜å…ˆä½¿ç”¨åŸºç¡€ä¿¡æ¯æ–‡ä»¶ä¸­çš„å¸‚å€¼æ•°æ®
        basic_info_df = load_stock_basic_info()
        if not basic_info_df.empty:
            stock_info = basic_info_df[basic_info_df["code"] == stock_code]
            if not stock_info.empty:
                market_cap = stock_info["market_cap"].values[0]
                if not pd.isna(market_cap) and market_cap > 0:
                    logger.debug(f"ä½¿ç”¨åŸºç¡€ä¿¡æ¯æ–‡ä»¶ä¸­çš„å¸‚å€¼æ•°æ®: {market_cap:.2f}äº¿å…ƒ")
                    return market_cap
        
        # 2. å¦‚æœåŸºç¡€ä¿¡æ¯ä¸­æ²¡æœ‰ï¼Œå°è¯•ä½¿ç”¨å†å²æ•°æ®ä¼°ç®—
        if df is not None and not df.empty and len(df) >= 250:
            if "æˆäº¤é‡" in df.columns and "æ”¶ç›˜" in df.columns:
                avg_volume = df["æˆäº¤é‡"].iloc[-250:].mean()
                avg_price = df["æ”¶ç›˜"].iloc[-250:].mean()
                if avg_volume > 0 and avg_price > 0:
                    # ä¼°ç®—æ—¥å‡æˆäº¤é¢(ä¸‡å…ƒ)
                    daily_turnover = avg_volume * avg_price / 10000
                    # å‡è®¾æ¢æ‰‹ç‡ä¸º2%ï¼Œä¼°ç®—æ€»å¸‚å€¼
                    if daily_turnover > 0:
                        estimated_market_cap = daily_turnover / 0.02  # æ¢æ‰‹ç‡2%
                        logger.debug(f"ä½¿ç”¨å†å²æ•°æ®ä¼°ç®—å¸‚å€¼: {estimated_market_cap:.2f}äº¿å…ƒ")
                        return estimated_market_cap
        
        # 3. å¦‚æœæ— æ³•è·å–å¸‚å€¼ï¼Œè¿”å›é»˜è®¤å€¼
        logger.warning(f"âš ï¸ æ— æ³•è·å–è‚¡ç¥¨ {stock_code} çš„å‡†ç¡®å¸‚å€¼ï¼Œä½¿ç”¨é»˜è®¤å¸‚å€¼ 50äº¿å…ƒ")
        return 50.0
    
    except Exception as e:
        logger.error(f"ä¼°ç®—{stock_code}å¸‚å€¼å¤±è´¥: {str(e)}", exc_info=True)
        return 50.0  # è¿”å›é»˜è®¤å¸‚å€¼
# ========== ä»¥ä¸Šæ˜¯å…³é”®ä¿®å¤ ==========

def is_stock_suitable(stock_code: str, df: pd.DataFrame, data_level: str, data_days: int) -> bool:
    """åˆ¤æ–­ä¸ªè‚¡æ˜¯å¦é€‚åˆç­–ç•¥ï¼ˆæµåŠ¨æ€§ã€æ³¢åŠ¨ç‡ã€å¸‚å€¼ä¸‰é‡è¿‡æ»¤ï¼‰"""
    try:
        # 1. æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
        if data_level == "insufficient" or data_level == "corrupted":
            logger.debug(f"è‚¡ç¥¨ {stock_code} è¢«è¿‡æ»¤ - æ•°æ®é‡ä¸è¶³({data_days}å¤©)")
            return False
            
        # è·å–è‚¡ç¥¨æ‰€å±æ¿å—
        section = get_stock_section(stock_code)
        if section not in MARKET_SECTIONS:
            logger.debug(f"è‚¡ç¥¨ {stock_code} ä¸å±äºä»»ä½•æ¿å—ï¼Œè·³è¿‡")
            return False
            
        # è·å–æ¿å—é…ç½®
        section_config = MARKET_SECTIONS[section]
        
        # 2. å¸‚å€¼è¿‡æ»¤ - ä½¿ç”¨æ¿å—ç‰¹å®šçš„é˜ˆå€¼
        market_cap = calculate_market_cap(df, stock_code)
        if market_cap < section_config["min_market_cap"]:
            logger.debug(f"è‚¡ç¥¨ {stock_code}({section}) è¢«è¿‡æ»¤ - å¸‚å€¼ä¸è¶³({market_cap:.2f}äº¿å…ƒ < {section_config['min_market_cap']}äº¿å…ƒ)")
            return False
        if market_cap > section_config["max_market_cap"]:
            logger.debug(f"è‚¡ç¥¨ {stock_code}({section}) è¢«è¿‡æ»¤ - å¸‚å€¼è¿‡å¤§({market_cap:.2f}äº¿å…ƒ > {section_config['max_market_cap']}äº¿å…ƒ)")
            return False
            
        # 3. æ³¢åŠ¨ç‡è¿‡æ»¤ - ä½¿ç”¨æ¿å—ç‰¹å®šçš„é˜ˆå€¼
        volatility = calculate_annual_volatility(df)
        if volatility < section_config["min_volatility"] or volatility > section_config["max_volatility"]:
            logger.debug(f"è‚¡ç¥¨ {stock_code}({section}) è¢«è¿‡æ»¤ - æ³¢åŠ¨ç‡å¼‚å¸¸({volatility:.2%}ä¸åœ¨{section_config['min_volatility']:.2%}-{section_config['max_volatility']:.2%}èŒƒå›´å†…)")
            return False
            
        # 4. æµåŠ¨æ€§è¿‡æ»¤ - ä½¿ç”¨æ¿å—ç‰¹å®šçš„é˜ˆå€¼
        avg_volume = calculate_avg_volume(df)
        if avg_volume < section_config["min_daily_volume"] / 10000:  # è½¬æ¢ä¸ºä¸‡å…ƒ
            logger.debug(f"è‚¡ç¥¨ {stock_code}({section}) è¢«è¿‡æ»¤ - æµåŠ¨æ€§ä¸è¶³(æ—¥å‡æˆäº¤é¢{avg_volume:.2f}ä¸‡å…ƒ < {section_config['min_daily_volume']/10000:.2f}ä¸‡å…ƒ)")
            return False
            
        logger.debug(f"è‚¡ç¥¨ {stock_code}({section}) é€šè¿‡æ‰€æœ‰è¿‡æ»¤æ¡ä»¶")
        return True
        
    except Exception as e:
        logger.error(f"è‚¡ç¥¨ {stock_code} è¿‡æ»¤æ£€æŸ¥å¤±è´¥: {str(e)}", exc_info=True)
        return False

def calculate_avg_volume(df: pd.DataFrame) -> float:
    """è®¡ç®—æ—¥å‡æˆäº¤é¢ï¼ˆä¸‡å…ƒï¼‰"""
    if df is None or df.empty or "æˆäº¤é‡" not in df.columns or "æ”¶ç›˜" not in df.columns:
        return 0.0
    
    # è®¡ç®—æ—¥å‡æˆäº¤é¢ï¼ˆå…ƒï¼‰
    avg_volume = df["æˆäº¤é‡"].iloc[-20:].mean() * 100 * df["æ”¶ç›˜"].iloc[-20:].mean()
    # è½¬æ¢ä¸ºä¸‡å…ƒ
    return avg_volume / 10000

# ========== ä»¥ä¸‹æ˜¯å…³é”®ä¿®æ”¹ï¼šæ›´å¼¹æ€§çš„è¯„åˆ†æœºåˆ¶ ==========
def calculate_stock_strategy_score(stock_code: str, df: pd.DataFrame) -> float:
    """è®¡ç®—è‚¡ç¥¨ç­–ç•¥è¯„åˆ†ï¼ˆæ›´ç²¾ç»†åŒ–çš„è¯„åˆ†æœºåˆ¶ï¼‰
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        df: é¢„å¤„ç†åçš„è‚¡ç¥¨æ•°æ®
    
    Returns:
        float: è¯„åˆ†(0-100)
    """
    try:
        if df is None or df.empty or len(df) < 40:
            logger.debug(f"è‚¡ç¥¨ {stock_code} æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—ç­–ç•¥è¯„åˆ†")
            return 0.0
        
        # æ£€æŸ¥å¿…è¦åˆ—
        required_columns = ['å¼€ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æ”¶ç›˜', 'æˆäº¤é‡']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            logger.debug(f"è‚¡ç¥¨ {stock_code} æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {', '.join(missing_columns)}ï¼Œæ— æ³•è®¡ç®—ç­–ç•¥è¯„åˆ†")
            return 0.0
        
        # è·å–æœ€æ–°æ•°æ®
        current = df["æ”¶ç›˜"].iloc[-1]
        if pd.isna(current) or current <= 0:
            logger.debug(f"è‚¡ç¥¨ {stock_code} æ— æ•ˆçš„æ”¶ç›˜ä»·: {current}")
            return 0.0
        
        volume = df["æˆäº¤é‡"].iloc[-1] if "æˆäº¤é‡" in df.columns and len(df) >= 1 else 0
        
        # è·å–è‚¡ç¥¨æ‰€å±æ¿å—
        section = get_stock_section(stock_code)
        
        # 1. è¶‹åŠ¿æŒ‡æ ‡è¯„åˆ† (40%)
        trend_score = 0.0
        if len(df) >= 40:
            # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
            df["ma5"] = df["æ”¶ç›˜"].rolling(window=5).mean()
            df["ma10"] = df["æ”¶ç›˜"].rolling(window=10).mean()
            df["ma20"] = df["æ”¶ç›˜"].rolling(window=20).mean()
            df["ma40"] = df["æ”¶ç›˜"].rolling(window=40).mean()
            
            # 1.1 å¤šå¤´æ’åˆ—è¯„åˆ† (20åˆ†) - åŸºäºå‡çº¿é—´è·å’Œè§’åº¦
            ma5 = df["ma5"].iloc[-1] if "ma5" in df.columns else current
            ma10 = df["ma10"].iloc[-1] if "ma10" in df.columns else current
            ma20 = df["ma20"].iloc[-1] if "ma20" in df.columns else current
            ma40 = df["ma40"].iloc[-1] if "ma40" in df.columns else current
            
            # æ£€æŸ¥æ˜¯å¦å¤šå¤´æ’åˆ—
            if not pd.isna(ma5) and not pd.isna(ma10) and not pd.isna(ma20) and not pd.isna(ma40):
                # è®¡ç®—å‡çº¿é—´è·æ¯”ä¾‹
                spacing_ratio_5_10 = (ma5 - ma10) / ma10 if ma10 > 0 else 0
                spacing_ratio_10_20 = (ma10 - ma20) / ma20 if ma20 > 0 else 0
                spacing_ratio_20_40 = (ma20 - ma40) / ma40 if ma40 > 0 else 0
                
                # è®¡ç®—å‡çº¿æ–œç‡
                ma5_slope = (df["ma5"].iloc[-1] - df["ma5"].iloc[-5]) / 5 if len(df) >= 5 and "ma5" in df.columns else 0
                ma10_slope = (df["ma10"].iloc[-1] - df["ma10"].iloc[-5]) / 5 if len(df) >= 5 and "ma10" in df.columns else 0
                ma20_slope = (df["ma20"].iloc[-1] - df["ma20"].iloc[-5]) / 5 if len(df) >= 5 and "ma20" in df.columns else 0
                
                # å¤šå¤´æ’åˆ—å¼ºåº¦è¯„åˆ† (0-20åˆ†)
                spacing_score = min(10, max(0, (spacing_ratio_5_10 + spacing_ratio_10_20 + spacing_ratio_20_40) * 100))
                slope_score = min(10, max(0, (ma5_slope + ma10_slope + ma20_slope) * 100))
                trend_score += spacing_score + slope_score
        
        # 1.2 ä»·æ ¼ä½ç½®è¯„åˆ† (10åˆ†) - åŸºäºåœ¨20æ—¥å‡çº¿ä¸Šæ–¹çš„å¤©æ•°å’Œåç¦»ç‡
        if "ma20" in df.columns and len(df) >= 20:
            ma20 = df["ma20"].iloc[-1]
            if not pd.isna(ma20) and ma20 > 0:
                # è®¡ç®—ä»·æ ¼åç¦»ç‡
                deviation = (current - ma20) / ma20
                
                # è®¡ç®—è¿ç»­åœ¨å‡çº¿ä¸Šæ–¹çš„å¤©æ•°
                above_ma_days = 0
                for i in range(1, min(20, len(df))):
                    if df["æ”¶ç›˜"].iloc[-i] > df["ma20"].iloc[-i]:
                        above_ma_days += 1
                    else:
                        break
                
                # ä»·æ ¼ä½ç½®è¯„åˆ† (0-10åˆ†)
                deviation_score = max(0, min(5, 5 - abs(deviation) * 50))  # ç†æƒ³åç¦»ç‡åœ¨0-2%
                days_score = min(5, above_ma_days * 0.5)  # æ¯å¤šä¸€å¤©åŠ 0.5åˆ†ï¼Œæœ€å¤š5åˆ†
                trend_score += deviation_score + days_score
        
        # 1.3 è¶‹åŠ¿å¼ºåº¦è¯„åˆ† (10åˆ†) - åŸºäº20æ—¥æ¶¨å¹…å’Œè¶‹åŠ¿ç¨³å®šæ€§
        if len(df) >= 20:
            price_change_20 = (current - df["æ”¶ç›˜"].iloc[-20]) / df["æ”¶ç›˜"].iloc[-20] * 100
            
            # è®¡ç®—è¶‹åŠ¿ç¨³å®šæ€§ (ä»·æ ¼åœ¨20æ—¥å‡çº¿ä¹‹ä¸Šçš„æ¯”ä¾‹)
            above_ma_ratio = 0
            if "ma20" in df.columns:
                above_ma_ratio = sum(1 for i in range(20) if df["æ”¶ç›˜"].iloc[-i-1] > df["ma20"].iloc[-i-1]) / 20
            
            # è¶‹åŠ¿å¼ºåº¦è¯„åˆ† (0-10åˆ†)
            change_score = min(7, max(0, price_change_20 * 0.2))  # æ¯1%æ¶¨å¹…å¾—0.2åˆ†ï¼Œæœ€é«˜7åˆ†
            stability_score = min(3, above_ma_ratio * 3)  # ç¨³å®šæ€§æœ€é«˜3åˆ†
            trend_score += change_score + stability_score
        
        # 2. åŠ¨é‡æŒ‡æ ‡è¯„åˆ† (20%)
        momentum_score = 0.0
        # è®¡ç®—MACD
        if "æ”¶ç›˜" in df.columns:
            df["ema12"] = df["æ”¶ç›˜"].ewm(span=12, adjust=False).mean()
            df["ema26"] = df["æ”¶ç›˜"].ewm(span=26, adjust=False).mean()
            df["macd"] = df["ema12"] - df["ema26"]
            df["signal"] = df["macd"].ewm(span=9, adjust=False).mean()
            df["hist"] = df["macd"] - df["signal"]
        
        # 2.1 MACDè¯„åˆ† (10åˆ†) - åŸºäºæŸ±çŠ¶ä½“å¢é•¿å’Œæ­£å€¼å¤§å°
        if "hist" in df.columns and len(df) >= 2:
            macd_hist = df["hist"].iloc[-1]
            macd_hist_prev = df["hist"].iloc[-2]
            
            # MACDæŸ±çŠ¶ä½“å¢é•¿è¯„åˆ†
            if not pd.isna(macd_hist) and not pd.isna(macd_hist_prev):
                growth_rate = (macd_hist - macd_hist_prev) / abs(macd_hist_prev) if macd_hist_prev != 0 else 1
                
                # å¢é•¿ç‡è¯„åˆ† (0-5åˆ†)
                growth_score = min(5, max(0, growth_rate * 10))
                
                # æ­£å€¼å¤§å°è¯„åˆ† (0-5åˆ†)
                value_score = min(5, max(0, macd_hist * 10))
                
                momentum_score += growth_score + value_score
        
        # 2.2 RSIè¯„åˆ† (10åˆ†) - åŸºäºä¸ç†æƒ³åŒºåŸŸçš„è·ç¦»
        if "æ”¶ç›˜" in df.columns:
            delta = df["æ”¶ç›˜"].diff()
            gain = delta.where(delta > 0, 0)
            loss = -delta.where(delta < 0, 0)
            avg_gain = gain.rolling(window=14).mean()
            avg_loss = loss.rolling(window=14).mean()
            rs = avg_gain / avg_loss.replace(0, np.nan)  # é¿å…é™¤é›¶é”™è¯¯
            df["rsi"] = 100 - (100 / (1 + rs))
        
        if "rsi" in df.columns:
            rsi = df["rsi"].iloc[-1]
            if not pd.isna(rsi):
                # RSIè¯„åˆ† (0-10åˆ†)ï¼Œç†æƒ³åŒºåŸŸ50-70
                if 50 <= rsi <= 70:
                    # åœ¨ç†æƒ³åŒºåŸŸå†…ï¼Œè¶Šæ¥è¿‘60åˆ†è¶Šé«˜
                    distance = abs(rsi - 60)
                    rsi_score = max(0, 10 - distance * 0.2)
                else:
                    # åœ¨ç†æƒ³åŒºåŸŸå¤–ï¼Œæ ¹æ®è·ç¦»æ‰£åˆ†
                    distance = min(abs(rsi - 50), abs(rsi - 70))
                    rsi_score = max(0, 5 - distance * 0.1)
                
                momentum_score += rsi_score
        
        # 3. é‡èƒ½æŒ‡æ ‡è¯„åˆ† (20%)
        volume_score = 0.0
        if "æˆäº¤é‡" in df.columns:
            df["volume_ma5"] = df["æˆäº¤é‡"].rolling(window=5).mean()
        
        volume_ma5 = df["volume_ma5"].iloc[-1] if "volume_ma5" in df.columns and len(df) >= 1 else 0
        if volume_ma5 > 0 and volume > 0:
            volume_ratio = volume / volume_ma5
            
            # 3.1 é‡èƒ½æ”¾å¤§è¯„åˆ† (10åˆ†) - åŸºäºæ”¾å¤§æ¯”ä¾‹
            volume_score += min(10, volume_ratio * 5)  # æ”¾å¤§100%å¾—æ»¡åˆ†
            
            # 3.2 é‡ä»·é…åˆè¯„åˆ† (10åˆ†) - åŸºäºä»·æ ¼å˜åŒ–ä¸é‡èƒ½å˜åŒ–çš„ç›¸å…³æ€§
            if len(df) >= 2:
                price_change = (current - df["æ”¶ç›˜"].iloc[-2]) / df["æ”¶ç›˜"].iloc[-2]
                volume_change = (volume - volume_ma5) / volume_ma5
                
                # è®¡ç®—è¿‘5å¤©ä»·æ ¼å˜åŒ–ä¸é‡èƒ½å˜åŒ–çš„ç›¸å…³æ€§
                price_changes = []
                volume_changes = []
                for i in range(1, min(5, len(df))):
                    price_changes.append((df["æ”¶ç›˜"].iloc[-i] - df["æ”¶ç›˜"].iloc[-i-1]) / df["æ”¶ç›˜"].iloc[-i-1])
                    volume_changes.append((df["æˆäº¤é‡"].iloc[-i] - df["æˆäº¤é‡"].iloc[-i-1]) / df["æˆäº¤é‡"].iloc[-i-1])
                
                # è®¡ç®—ç›¸å…³ç³»æ•°
                if len(price_changes) > 1:
                    mean_price = sum(price_changes) / len(price_changes)
                    mean_volume = sum(volume_changes) / len(volume_changes)
                    
                    numerator = sum((p - mean_price) * (v - mean_volume) for p, v in zip(price_changes, volume_changes))
                    denominator = (sum((p - mean_price)**2 for p in price_changes) * sum((v - mean_volume)**2 for v in volume_changes)) ** 0.5
                    
                    if denominator != 0:
                        correlation = numerator / denominator
                        volume_score += max(0, min(10, correlation * 10))
        
        # 4. æ³¢åŠ¨ç‡æŒ‡æ ‡è¯„åˆ† (20%)
        volatility_score = 0.0
        # è®¡ç®—æ³¢åŠ¨ç‡ï¼ˆ20æ—¥å¹´åŒ–æ³¢åŠ¨ç‡ï¼‰
        if "æ”¶ç›˜" in df.columns:
            df["pct_change"] = df["æ”¶ç›˜"].pct_change() * 100
        
        if "pct_change" in df.columns:
            df["volatility"] = df["pct_change"].rolling(window=20).std() * np.sqrt(252)
        
        if "volatility" in df.columns and len(df) >= 20:
            volatility = df["volatility"].iloc[-1]
            
            if not pd.isna(volatility):
                # 4.1 æ³¢åŠ¨ç‡æ°´å¹³è¯„åˆ† (10åˆ†) - åŸºäºä¸ç†æƒ³èŒƒå›´çš„è·ç¦»
                section_config = MARKET_SECTIONS.get(section, MARKET_SECTIONS["æ²ªå¸‚ä¸»æ¿"])
                min_vol = section_config["min_volatility"]
                max_vol = section_config["max_volatility"]
                
                if min_vol <= volatility <= max_vol:
                    # åœ¨ç†æƒ³èŒƒå›´å†…ï¼Œè¶Šæ¥è¿‘ä¸­é—´å€¼åˆ†è¶Šé«˜
                    mid_vol = (min_vol + max_vol) / 2
                    distance = abs(volatility - mid_vol)
                    vol_score = max(0, 10 - distance * 20)
                else:
                    # åœ¨ç†æƒ³èŒƒå›´å¤–ï¼Œæ ¹æ®è·ç¦»æ‰£åˆ†
                    distance = min(abs(volatility - min_vol), abs(volatility - max_vol))
                    vol_score = max(0, 5 - distance * 10)
                
                volatility_score += vol_score
                
                # 4.2 æ³¢åŠ¨ç‡ç¨³å®šæ€§è¯„åˆ† (10åˆ†) - åŸºäºæ³¢åŠ¨ç‡å˜åŒ–ç‡
                if len(df) >= 21:
                    prev_volatility = df["volatility"].iloc[-21]
                    if not pd.isna(prev_volatility) and prev_volatility > 0:
                        volatility_change = (volatility - prev_volatility) / prev_volatility
                        
                        # å˜åŒ–ç‡è¶Šå°ï¼Œè¯„åˆ†è¶Šé«˜
                        stability_score = max(0, 10 - abs(volatility_change) * 100)
                        volatility_score += stability_score
        
        # ç»¼åˆè¯„åˆ†
        total_score = trend_score + momentum_score + volume_score + volatility_score
        total_score = max(0, min(100, total_score))  # é™åˆ¶åœ¨0-100èŒƒå›´å†…
        
        logger.debug(f"è‚¡ç¥¨ {stock_code}({section}) ç­–ç•¥è¯„åˆ†: {total_score:.2f} "
                     f"(è¶‹åŠ¿={trend_score:.1f}, åŠ¨é‡={momentum_score:.1f}, "
                     f"é‡èƒ½={volume_score:.1f}, æ³¢åŠ¨ç‡={volatility_score:.1f})")
        
        return total_score
    
    except Exception as e:
        logger.error(f"è®¡ç®—è‚¡ç¥¨ {stock_code} ç­–ç•¥è¯„åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        return 0.0
# ========== ä»¥ä¸Šæ˜¯å…³é”®ä¿®æ”¹ï¼šæ›´å¼¹æ€§çš„è¯„åˆ†æœºåˆ¶ ==========

# ========== ä»¥ä¸‹æ˜¯å…³é”®ä¿®æ”¹ï¼šä¸ºæ¯ä¸ªæ¿å—ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š ==========
def generate_section_report(section: str, stocks: List[Dict]) -> str:
    """ç”Ÿæˆå•ä¸ªæ¿å—çš„è¯¦ç»†æŠ¥å‘Š
    
    Args:
        section: æ¿å—åç§°
        stocks: è¯¥æ¿å—çš„è‚¡ç¥¨åˆ—è¡¨
    
    Returns:
        str: æ¿å—è¯¦ç»†æŠ¥å‘Š
    """
    report_lines = []
    
    # æ·»åŠ æ ‡é¢˜
    beijing_time = get_beijing_time()
    report_lines.append(f"ğŸ“Š {section}æ¿å—è¶‹åŠ¿ç­–ç•¥æŠ¥å‘Š ({beijing_time.strftime('%Y-%m-%d %H:%M')})")
    report_lines.append("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    
    # æ·»åŠ æ¿å—ç­›é€‰æ¡ä»¶
    section_config = MARKET_SECTIONS.get(section, MARKET_SECTIONS["æ²ªå¸‚ä¸»æ¿"])
    report_lines.append(f"ğŸ” ç­›é€‰æ¡ä»¶:")
    report_lines.append(f"  â€¢ å¸‚å€¼èŒƒå›´: {section_config['min_market_cap']}-{section_config['max_market_cap']}äº¿å…ƒ")
    report_lines.append(f"  â€¢ æ—¥å‡æˆäº¤é¢: >{section_config['min_daily_volume']/10000:.2f}ä¸‡å…ƒ")
    report_lines.append(f"  â€¢ å¹´åŒ–æ³¢åŠ¨ç‡: {section_config['min_volatility']*100:.1f}%-{section_config['max_volatility']*100:.1f}%")
    report_lines.append("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨
    if not stocks:
        report_lines.append(f"âš ï¸ æœªç­›é€‰å‡ºç¬¦åˆæ¡ä»¶çš„{section}è‚¡ç¥¨")
        report_lines.append("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        report_lines.append("ğŸ’¡ æ“ä½œå»ºè®®: å½“å‰å¸‚åœºç¯å¢ƒä¸‹ï¼Œè¯¥æ¿å—æš‚æ— ç¬¦åˆç­–ç•¥æ ‡å‡†çš„æ ‡çš„")
        report_lines.append("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        report_lines.append("ğŸ“Š æ•°æ®æ¥æº: fish-etf (https://github.com/karmyshunde-sudo/fish-etf)")
        return "\n".join(report_lines)
    
    # æ·»åŠ ç­›é€‰å‡ºçš„è‚¡ç¥¨è¯¦æƒ…
    report_lines.append(f"âœ… ç­›é€‰å‡º {len(stocks)} åªä¼˜è´¨è‚¡ç¥¨ (æŒ‰è¯„åˆ†æ’åº):")
    
    for i, stock in enumerate(stocks):
        stock_code = stock["code"]
        stock_name = stock["name"]
        score = stock["score"]
        df = stock["df"]
        
        # è·å–æœ€æ–°æ•°æ®
        current = df["æ”¶ç›˜"].iloc[-1]
        volume = df["æˆäº¤é‡"].iloc[-1] if "æˆäº¤é‡" in df.columns and len(df) >= 1 else 0
        
        # è®¡ç®—20æ—¥å‡çº¿
        ma20 = df["æ”¶ç›˜"].rolling(window=20).mean().iloc[-1] if len(df) >= 20 else current
        
        # è®¡ç®—ä»·æ ¼åç¦»ç‡
        deviation = (current - ma20) / ma20 if ma20 > 0 else 0
        
        # è·å–è¶‹åŠ¿æŒ‡æ ‡
        trend_score = min(40, score * 0.4)  # ä»æ€»åˆ†ä¸­æ¨ç®—
        momentum_score = min(20, score * 0.2)
        volume_score = min(20, score * 0.2)
        volatility_score = min(20, score * 0.2)
        
        # æ·»åŠ è‚¡ç¥¨è¯¦æƒ…
        report_lines.append(f"{'='*30}")
        report_lines.append(f"{i+1}. {stock_name}({stock_code}) - {score:.1f}åˆ†")
        report_lines.append(f"ğŸ“ˆ è¶‹åŠ¿: {trend_score:.1f}/40 | åŠ¨é‡: {momentum_score:.1f}/20")
        report_lines.append(f"ğŸ“Š é‡èƒ½: {volume_score:.1f}/20 | æ³¢åŠ¨: {volatility_score:.1f}/20")
        report_lines.append(f"ğŸ’° ä»·æ ¼: {current:.4f} | 20æ—¥å‡çº¿: {ma20:.4f} | åç¦»ç‡: {deviation:.2%}")
        report_lines.append(f"ğŸ”„ é‡èƒ½: {volume:,.0f}æ‰‹ | 5æ—¥å‡é‡: {calculate_avg_volume(df):,.2f}ä¸‡å…ƒ")
    
    report_lines.append("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    report_lines.append("ğŸ’¡ æ“ä½œæŒ‡å—:")
    report_lines.append("1. è¯„åˆ†è¶Šé«˜ï¼Œè¶‹åŠ¿è¶Šå¼ºï¼Œå¯è€ƒè™‘é€‚å½“å¢åŠ ä»“ä½")
    report_lines.append("2. æ¯åªä¸ªè‚¡ä»“ä½â‰¤15%ï¼Œåˆ†æ•£æŠ•èµ„5-8åª")
    report_lines.append("3. æŒç»­å…³æ³¨è¶‹åŠ¿å˜åŒ–ï¼ŒåŠæ—¶è°ƒæ•´æŒä»“")
    report_lines.append("4. ç§‘åˆ›æ¿/åˆ›ä¸šæ¿æ³¢åŠ¨è¾ƒå¤§ï¼Œæ³¨æ„æ§åˆ¶é£é™©")
    report_lines.append("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    report_lines.append("ğŸ“Š æ•°æ®æ¥æº: fish-etf (https://github.com/karmyshunde-sudo/fish-etf)")
    
    return "\n".join(report_lines)
# ========== ä»¥ä¸Šæ˜¯å…³é”®ä¿®æ”¹ï¼šä¸ºæ¯ä¸ªæ¿å—ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š ==========

# ========== ä»¥ä¸‹æ˜¯å…³é”®ä¿®æ”¹ ==========
# ç¼“å­˜å­—å…¸
FILTER_CACHE = {}
SCORE_CACHE = {}
CACHE_EXPIRY = timedelta(hours=1)  # ç¼“å­˜æœ‰æ•ˆæœŸ
def get_cached_filter_result(stock_code: str, last_update: datetime) -> Optional[bool]:
    """è·å–ç¼“å­˜çš„ç­›é€‰ç»“æœ"""
    if stock_code in FILTER_CACHE:
        cached_result, cache_time = FILTER_CACHE[stock_code]
        if datetime.now() - cache_time < CACHE_EXPIRY:
            return cached_result
    return None

def cache_filter_result(stock_code: str, result: bool):
    """ç¼“å­˜ç­›é€‰ç»“æœ"""
    FILTER_CACHE[stock_code] = (result, datetime.now())

def get_cached_score(stock_code: str, last_update: datetime) -> Optional[float]:
    """è·å–ç¼“å­˜çš„è¯„åˆ†ç»“æœ"""
    if stock_code in SCORE_CACHE:
        cached_score, cache_time = SCORE_CACHE[stock_code]
        if datetime.now() - cache_time < CACHE_EXPIRY:
            return cached_score
    return None

def cache_score(stock_code: str, score: float):
    """ç¼“å­˜è¯„åˆ†ç»“æœ"""
    SCORE_CACHE[stock_code] = (score, datetime.now())
# ========== ä»¥ä¸Šæ˜¯å…³é”®ä¿®æ”¹ ==========

def get_top_stocks_for_strategy() -> Dict[str, List[Dict]]:
    """æŒ‰æ¿å—è·å–é€‚åˆç­–ç•¥çš„è‚¡ç¥¨ï¼ˆä½¿ç”¨æœ¬åœ°å·²ä¿å­˜æ•°æ®ï¼‰"""
    try:
        logger.info("===== å¼€å§‹æ‰§è¡Œä¸ªè‚¡è¶‹åŠ¿ç­–ç•¥(TickTen) =====")
        
        # 1. è·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
        basic_info_df = load_stock_basic_info()
        if basic_info_df.empty:
            logger.error("è·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
            return {}
        
        logger.info(f"å·²åŠ è½½è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ï¼Œå…± {len(basic_info_df)} æ¡è®°å½•")
        
        # 2. æŒ‰æ¿å—åˆ†ç»„å¤„ç†
        section_stocks = {section: [] for section in MARKET_SECTIONS.keys()}
        
        # 3. åˆå§‹åŒ–å„æ¿å—è®¡æ•°å™¨ï¼ˆæ·»åŠ è¯¦ç»†è¿‡æ»¤åŸå› ç»Ÿè®¡ï¼‰
        section_counts = {section: {
            "total": 0, 
            "data_ok": 0, 
            "market_cap_filtered": 0,
            "volatility_filtered": 0,
            "liquidity_filtered": 0,
            "data_filtered": 0,
            "suitable": 0,
            "scored": 0
        } for section in MARKET_SECTIONS.keys()}
        
        # 4. å¤„ç†æ¯åªè‚¡ç¥¨
        stock_list = basic_info_df.to_dict('records')
        logger.info(f"å¼€å§‹å¤„ç† {len(stock_list)} åªè‚¡ç¥¨...")
        
        # ç¡®ä¿æ‰€æœ‰è‚¡ç¥¨ä»£ç æ˜¯å­—ç¬¦ä¸²æ ¼å¼ï¼ˆ6ä½ï¼Œå‰é¢è¡¥é›¶ï¼‰
        for stock in stock_list:
            stock["code"] = str(stock["code"]).zfill(6)
        
        logger.info(f"ä»Šå¤©å®é™…å¤„ç† {len(stock_list)} åªè‚¡ç¥¨ï¼ˆå®Œæ•´å¤„ç†ï¼‰")
        
        def process_stock(stock):
            # ç¡®ä¿è‚¡ç¥¨ä»£ç æ˜¯å­—ç¬¦ä¸²ï¼Œå¹¶ä¸”æ˜¯6ä½ï¼ˆå‰é¢è¡¥é›¶ï¼‰
            stock_code = str(stock["code"]).zfill(6)
            stock_name = stock["name"]
            section = stock["section"]
            
            # æ£€æŸ¥æ¿å—æ˜¯å¦æœ‰æ•ˆ
            if section not in MARKET_SECTIONS:
                return None
            
            # æ›´æ–°æ¿å—è®¡æ•°å™¨
            section_counts[section]["total"] += 1
            
            # 1. å°è¯•ä»ç¼“å­˜è·å–ç»“æœ
            last_update = get_last_update_time(basic_info_df, stock_code)
            cached_result = get_cached_filter_result(stock_code, last_update)
            if cached_result is not None:
                logger.debug(f"è‚¡ç¥¨ {stock_code} ä½¿ç”¨ç¼“å­˜ç­›é€‰ç»“æœ: {cached_result}")
                if not cached_result:
                    return None
                
                cached_score = get_cached_score(stock_code, last_update)
                if cached_score is not None and cached_score > 0:
                    # ä»æœ¬åœ°åŠ è½½æ•°æ®
                    df = get_stock_daily_data(stock_code)
                    if not df.empty:
                        return {
                            "code": stock_code,
                            "name": stock_name,
                            "score": cached_score,
                            "df": df,
                            "section": section
                        }
            
            # 2. è·å–æ—¥çº¿æ•°æ®ï¼ˆä»æœ¬åœ°åŠ è½½ï¼‰
            df = get_stock_daily_data(stock_code)
            
            # 3. æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
            data_level, data_days = check_data_integrity(df)
            logger.debug(f"è‚¡ç¥¨ {stock_code} æ•°æ®å®Œæ•´æ€§: {data_level} ({data_days}å¤©)")
            
            # 4. æ ¹æ®æ•°æ®å®Œæ•´æ€§åº”ç”¨ä¸åŒç­–ç•¥
            if data_level == "insufficient" or data_level == "corrupted":
                section_counts[section]["data_filtered"] += 1
                logger.debug(f"è‚¡ç¥¨ {stock_code} è¢«è¿‡æ»¤ - æ•°æ®é‡ä¸è¶³({data_days}å¤©)")
                cache_filter_result(stock_code, False)
                return None
            
            # æ£€æŸ¥å¸‚å€¼æ•°æ®æ˜¯å¦å¯é 
            market_cap = calculate_market_cap(df, stock_code)
            if market_cap <= 0:
                logger.warning(f"âš ï¸ è‚¡ç¥¨ {stock_code} å¸‚å€¼æ•°æ®ä¸å¯é ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                market_cap = 50.0  # ä½¿ç”¨é»˜è®¤å¸‚å€¼
            
            # æ£€æŸ¥æ˜¯å¦é€‚åˆç­–ç•¥
            if not is_stock_suitable(stock_code, df, data_level, data_days):
                # è®°å½•å…·ä½“è¿‡æ»¤åŸå› 
                if market_cap < MARKET_SECTIONS[section]["min_market_cap"]:
                    section_counts[section]["market_cap_filtered"] += 1
                    logger.debug(f"è‚¡ç¥¨ {stock_code} è¢«è¿‡æ»¤ - å¸‚å€¼ä¸è¶³")
                elif calculate_annual_volatility(df) < MARKET_SECTIONS[section]["min_volatility"] or \
                     calculate_annual_volatility(df) > MARKET_SECTIONS[section]["max_volatility"]:
                    section_counts[section]["volatility_filtered"] += 1
                    logger.debug(f"è‚¡ç¥¨ {stock_code} è¢«è¿‡æ»¤ - æ³¢åŠ¨ç‡å¼‚å¸¸")
                elif calculate_avg_volume(df) < MARKET_SECTIONS[section]["min_daily_volume"] / 10000:
                    section_counts[section]["liquidity_filtered"] += 1
                    logger.debug(f"è‚¡ç¥¨ {stock_code} è¢«è¿‡æ»¤ - æµåŠ¨æ€§ä¸è¶³")
                else:
                    logger.debug(f"è‚¡ç¥¨ {stock_code} è¢«è¿‡æ»¤ - æœªçŸ¥åŸå› ")
                
                cache_filter_result(stock_code, False)
                return None
            
            section_counts[section]["suitable"] += 1
            
            # 5. è®¡ç®—ç­–ç•¥å¾—åˆ†
            score = calculate_stock_strategy_score(stock_code, df)
            
            if score > 0:
                # 6. ç¼“å­˜ç»“æœ
                cache_filter_result(stock_code, True)
                cache_score(stock_code, score)
                
                # 7. æ›´æ–°æ¿å—è®¡æ•°å™¨
                section_counts[section]["scored"] += 1
                
                return {
                    "code": stock_code,
                    "name": stock_name,
                    "score": score,
                    "df": df,
                    "section": section
                }
            
            # 7. ç¼“å­˜ç­›é€‰å¤±è´¥ç»“æœ
            cache_filter_result(stock_code, False)
            return None
        
        # 6. å¹¶è¡Œå¤„ç†è‚¡ç¥¨ï¼ˆä¼˜åŒ–å¹¶å‘å‚æ•°ï¼‰
        results = []
        # é™ä½å¹¶å‘æ•°ï¼Œç¡®ä¿ä¸ä¼šè§¦å‘AkShareé™åˆ¶
        with ThreadPoolExecutor(max_workers=5) as executor:
            # å¢åŠ æ¯æ‰¹å¤„ç†çš„è‚¡ç¥¨æ•°é‡
            for i in range(0, len(stock_list), 15):
                batch = stock_list[i:i+15]
                batch_results = list(executor.map(process_stock, batch))
                results.extend(batch_results)
                # å‡å°‘ç­‰å¾…æ—¶é—´
                time.sleep(0.8)
        
        # 7. æ”¶é›†ç»“æœ
        for result in results:
            if result is not None:
                section = result["section"]
                section_stocks[section].append(result)
        
        # 8. è®°å½•å„æ¿å—ç­›é€‰ç»“æœï¼ˆåŒ…å«è¯¦ç»†è¿‡æ»¤åŸå› ï¼‰
        for section, counts in section_counts.items():
            if counts["total"] > 0:
                logger.info(f"ã€ç­›é€‰è¯¦ç»†ç»Ÿè®¡ã€‘æ¿å— {section}:")
                logger.info(f"  - æ€»è‚¡ç¥¨æ•°é‡: {counts['total']}")
                logger.info(f"  - æ•°æ®é‡ä¸è¶³: {counts['data_filtered']} ({counts['data_filtered']/counts['total']*100:.1f}%)")
                logger.info(f"  - å¸‚å€¼è¿‡æ»¤: {counts['market_cap_filtered']} ({counts['market_cap_filtered']/counts['total']*100:.1f}%)")
                logger.info(f"  - æ³¢åŠ¨ç‡è¿‡æ»¤: {counts['volatility_filtered']} ({counts['volatility_filtered']/counts['total']*100:.1f}%)")
                logger.info(f"  - æµåŠ¨æ€§è¿‡æ»¤: {counts['liquidity_filtered']} ({counts['liquidity_filtered']/counts['total']*100:.1f}%)")
                logger.info(f"  - é€šè¿‡ä¸‰é‡è¿‡æ»¤: {counts['suitable']} ({counts['suitable']/counts['total']*100:.1f}%)")
                logger.info(f"  - è¯„åˆ†>0: {counts['scored']} ({counts['scored']/counts['total']*100:.1f}%)")
        
        # 9. å¯¹æ¯ä¸ªæ¿å—çš„è‚¡ç¥¨æŒ‰å¾—åˆ†æ’åºï¼Œå¹¶å–å‰Nåª
        top_stocks_by_section = {}
        for section, stocks in section_stocks.items():
            if stocks:
                stocks.sort(key=lambda x: x["score"], reverse=True)
                top_stocks = stocks[:MAX_STOCKS_PER_SECTION]
                top_stocks_by_section[section] = top_stocks
                logger.info(f"ã€æœ€ç»ˆç»“æœã€‘æ¿å— {section} ç­›é€‰å‡º {len(top_stocks)} åªè‚¡ç¥¨")
                # è®°å½•ç­›é€‰å‡ºçš„è‚¡ç¥¨è¯¦æƒ…
                for i, stock in enumerate(top_stocks):
                    logger.info(f"  {i+1}. {stock['name']}({stock['code']}) - è¯„åˆ†: {stock['score']:.2f}")
            else:
                logger.info(f"ã€æœ€ç»ˆç»“æœã€‘æ¿å— {section} æ— ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
        
        # 10. æ›´æ–°åŸºç¡€ä¿¡æ¯ä¸­çš„å¸‚å€¼å’Œè¯„åˆ†
        updated_records = []
        for section, stocks in top_stocks_by_section.items():
            for stock in stocks:
                stock_code = str(stock["code"]).zfill(6)
                stock_name = stock["name"]
                section = stock["section"]
                market_cap = calculate_market_cap(stock["df"], stock_code)
                score = stock["score"]
                
                # æ›´æ–°åŸºç¡€ä¿¡æ¯
                updated_records.append({
                    "code": stock_code,
                    "name": stock_name,
                    "section": section,
                    "market_cap": market_cap,
                    "score": score,
                    "last_update": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                })
        
        # 11. ä¿å­˜æ›´æ–°åçš„åŸºç¡€ä¿¡æ¯
        if updated_records:
            # åˆ›å»ºä¸´æ—¶DataFrameç”¨äºæ›´æ–°
            update_df = pd.DataFrame(updated_records)
            
            # ä»…æ›´æ–°å¸‚å€¼å’Œè¯„åˆ†ï¼Œä¸æ”¹å˜åŸºç¡€ä¿¡æ¯ç»“æ„
            for _, record in update_df.iterrows():
                mask = basic_info_df["code"] == record["code"]
                if mask.any():
                    # æ›´æ–°ç°æœ‰è®°å½•çš„å¸‚å€¼å’Œè¯„åˆ†
                    basic_info_df.loc[mask, "market_cap"] = record["market_cap"]
                    basic_info_df.loc[mask, "score"] = record["score"]
                    basic_info_df.loc[mask, "last_update"] = record["last_update"]
            
            # 12. ä¿å­˜æ›´æ–°
            basic_info_df.to_csv(BASIC_INFO_FILE, index=False)
            logger.info(f"è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å·²æ›´æ–°ï¼Œå…± {len(basic_info_df)} æ¡è®°å½•")
            
            # ä½¿ç”¨ git_utils.py ä¸­å·²æœ‰çš„å·¥å…·å‡½æ•°
            try:
                logger.info("æ­£åœ¨æäº¤æ›´æ–°åçš„è‚¡ç¥¨åŸºç¡€ä¿¡æ¯åˆ°GitHubä»“åº“...")
                commit_message = "è‡ªåŠ¨æ›´æ–°è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ [ç­–ç•¥æ‰§è¡Œ]"
                if commit_and_push_file(BASIC_INFO_FILE, commit_message):
                    logger.info("æ›´æ–°åçš„è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å·²æˆåŠŸæäº¤å¹¶æ¨é€åˆ°GitHubä»“åº“")
                else:
                    logger.warning("æäº¤æ›´æ–°åçš„è‚¡ç¥¨åŸºç¡€ä¿¡æ¯åˆ°GitHubä»“åº“å¤±è´¥ï¼Œä½†ç»§ç»­æ‰§è¡Œç­–ç•¥")
            except Exception as e:
                logger.warning(f"æäº¤æ›´æ–°åçš„è‚¡ç¥¨åŸºç¡€ä¿¡æ¯åˆ°GitHubä»“åº“å¤±è´¥: {str(e)}")
                logger.warning(traceback.format_exc())
        
        return top_stocks_by_section
    
    except Exception as e:
        logger.error(f"è·å–ä¼˜è´¨è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {str(e)}", exc_info=True)
        logger.error(traceback.format_exc())
        return {}

# ========== ä»¥ä¸‹æ˜¯å…³é”®ä¿®æ”¹ï¼šç§»é™¤æ—§çš„ç”Ÿæˆç­–ç•¥æ€»ç»“å‡½æ•°ï¼Œæ”¹ä¸ºç”Ÿæˆæ¯ä¸ªæ¿å—çš„æŠ¥å‘Š ==========
def main():
    """ä¸»å‡½æ•°"""
    try:
        logger.info("===== å¼€å§‹æ‰§è¡Œä¸ªè‚¡è¶‹åŠ¿ç­–ç•¥(TickTen) =====")
        
        # 1. è·å–é€‚åˆç­–ç•¥çš„è‚¡ç¥¨
        top_stocks_by_section = get_top_stocks_for_strategy()
        
        # 2. ä¸ºæ¯ä¸ªæ¿å—ç”Ÿæˆè¯¦ç»†æŠ¥å‘Šå¹¶æ¨é€
        total_stocks = 0
        for section, stocks in top_stocks_by_section.items():
            if stocks:
                total_stocks += len(stocks)
                # ç”Ÿæˆæ¿å—æŠ¥å‘Š
                section_report = generate_section_report(section, stocks)
                # æ¨é€æ¿å—æŠ¥å‘Š
                logger.info(f"æ¨é€ {section} æ¿å—ç­–ç•¥æŠ¥å‘Š")
                send_wechat_message(section_report, message_type="stock_tickten")
                # é€‚å½“å»¶æ—¶ï¼Œé¿å…æ¶ˆæ¯æ¨é€è¿‡äºé¢‘ç¹
                time.sleep(2)
        
        # 3. ç”Ÿæˆå¹¶æ¨é€æ•´ä½“æ€»ç»“
        beijing_time = get_beijing_time()
        summary_lines = []
        summary_lines.append(f"ğŸ“Š ä¸ªè‚¡è¶‹åŠ¿ç­–ç•¥æ‰§è¡Œæ€»ç»“ ({beijing_time.strftime('%Y-%m-%d %H:%M')})")
        summary_lines.append("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        summary_lines.append(f"âœ… å…±ç­›é€‰å‡º {total_stocks} åªä¼˜è´¨è‚¡ç¥¨ï¼ˆæŒ‰æ¿å—åˆ†å¸ƒï¼‰:")
        
        for section, stocks in top_stocks_by_section.items():
            if stocks:
                summary_lines.append(f"  â€¢ {section}: {len(stocks)} åª")
        
        summary_lines.append("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        summary_lines.append("ğŸ’¡ æ“ä½œæŒ‡å—:")
        summary_lines.append("1. è¯„åˆ†è¶Šé«˜ï¼Œè¶‹åŠ¿è¶Šå¼ºï¼Œå¯è€ƒè™‘é€‚å½“å¢åŠ ä»“ä½")
        summary_lines.append("2. æ¯åªä¸ªè‚¡ä»“ä½â‰¤15%ï¼Œåˆ†æ•£æŠ•èµ„5-8åª")
        summary_lines.append("3. æŒç»­å…³æ³¨è¶‹åŠ¿å˜åŒ–ï¼ŒåŠæ—¶è°ƒæ•´æŒä»“")
        summary_lines.append("4. ç§‘åˆ›æ¿/åˆ›ä¸šæ¿æ³¢åŠ¨è¾ƒå¤§ï¼Œæ³¨æ„æ§åˆ¶é£é™©")
        summary_lines.append("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        summary_lines.append("ğŸ“Š æ•°æ®æ¥æº: fish-etf (https://github.com/karmyshunde-sudo/fish-etf)")
        
        summary_message = "\n".join(summary_lines)
        logger.info("æ¨é€æ•´ä½“ç­–ç•¥æ‰§è¡Œæ€»ç»“")
        send_wechat_message(summary_message, message_type="stock_tickten")
        
        logger.info("ä¸ªè‚¡ç­–ç•¥æŠ¥å‘Šå·²æˆåŠŸå‘é€è‡³ä¼ä¸šå¾®ä¿¡")
        logger.info("===== ä¸ªè‚¡è¶‹åŠ¿ç­–ç•¥(TickTen)æ‰§è¡Œå®Œæˆ =====")
    
    except Exception as e:
        error_msg = f"ä¸ªè‚¡è¶‹åŠ¿ç­–ç•¥æ‰§è¡Œå¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        logger.error(traceback.format_exc())
        send_wechat_message(error_msg, message_type="error")

if __name__ == "__main__":
    main()
