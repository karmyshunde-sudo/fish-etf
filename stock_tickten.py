#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸ªè‚¡è¶‹åŠ¿è·Ÿè¸ªç­–ç•¥ï¼ˆTickTenç­–ç•¥ï¼‰
åŸºäºakshareå®æ—¶çˆ¬å–ä¸ªè‚¡æ•°æ®ï¼Œåº”ç”¨æµåŠ¨æ€§ã€æ³¢åŠ¨ç‡ã€å¸‚å€¼ä¸‰é‡è¿‡æ»¤ï¼Œç­›é€‰ä¼˜è´¨ä¸ªè‚¡
æŒ‰æ¿å—åˆ†ç±»æ¨é€ï¼Œæ¯ä¸ªæ¿å—æœ€å¤š10åªï¼Œå…±40åª
"""

import os
import logging
import pandas as pd
import numpy as np
import time
import akshare as ak
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, Any
# ========== ä»¥ä¸‹æ˜¯å…³é”®ä¿®æ”¹ ==========
from concurrent.futures import ThreadPoolExecutor
# ========== ä»¥ä¸Šæ˜¯å…³é”®ä¿®æ”¹ ==========
from config import Config
from utils.date_utils import (
    get_current_times,
    get_beijing_time,
    get_utc_time
)
from wechat_push.push import send_wechat_message

# åˆå§‹åŒ–æ—¥å¿—
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
handler = logging.StreamHandler()
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)

# ========== ä»¥ä¸‹æ˜¯å…³é”®ä¿®æ”¹ ==========
# å®šä¹‰è‚¡ç¥¨åŸºç¡€ä¿¡æ¯æ–‡ä»¶è·¯å¾„
BASIC_INFO_FILE = "data/all_stocks.csv"

# å¸‚å€¼è¿‡æ»¤é˜ˆå€¼ï¼ˆç”¨äºåŸºç¡€è¿‡æ»¤ï¼‰
MIN_MARKET_CAP_FOR_BASIC_FILTER = 50  # äº¿å…ƒ

# æ•°æ®æ›´æ–°é—´éš”ï¼ˆå¤©ï¼‰
DATA_UPDATE_INTERVAL = 1
# ========== ä»¥ä¸Šæ˜¯å…³é”®ä¿®æ”¹ ==========

# è‚¡ç¥¨æ¿å—é…ç½®
MARKET_SECTIONS = {
    "æ²ªå¸‚ä¸»æ¿": {
        "prefix": ["60"],
        "min_daily_volume": 5000 * 10000,  # æ—¥å‡æˆäº¤é¢é˜ˆå€¼(å…ƒ)
        "max_volatility": 0.40,  # æœ€å¤§æ³¢åŠ¨ç‡
        "min_market_cap": 50,  # æœ€å°å¸‚å€¼(äº¿å…ƒ)
        "max_market_cap": 2000  # æœ€å¤§å¸‚å€¼(äº¿å…ƒ)
    },
    "æ·±å¸‚ä¸»æ¿": {
        "prefix": ["00"],
        "min_daily_volume": 5000 * 10000,
        "max_volatility": 0.40,
        "min_market_cap": 50,
        "min_market_cap": 50,
        "max_market_cap": 2000
    },
    "åˆ›ä¸šæ¿": {
        "prefix": ["30"],
        "min_daily_volume": 5000 * 10000,
        "max_volatility": 0.40,
        "min_market_cap": 50,
        "max_market_cap": 2000
    },
    "ç§‘åˆ›æ¿": {
        "prefix": ["688"],
        "min_daily_volume": 5000 * 10000,
        "max_volatility": 0.40,
        "min_market_cap": 50,
        "max_market_cap": 2000
    }
}

# å…¶ä»–å‚æ•°
MIN_DATA_DAYS = 30  # æœ€å°æ•°æ®å¤©æ•°ï¼ˆç”¨äºè®¡ç®—æŒ‡æ ‡ï¼‰
MAX_STOCKS_TO_ANALYZE = 300  # å‡å°‘æ¯æ¬¡åˆ†æçš„æœ€å¤§è‚¡ç¥¨æ•°é‡ï¼ˆé¿å…è¯·æ±‚è¿‡å¤šï¼‰
MAX_STOCKS_PER_SECTION = 8  # æ¯ä¸ªæ¿å—æœ€å¤šæŠ¥å‘Šçš„è‚¡ç¥¨æ•°é‡
CRITICAL_VALUE_DAYS = 40  # ä¸´ç•Œå€¼è®¡ç®—å¤©æ•°

# ========== ä»¥ä¸‹æ˜¯å…³é”®ä¿®æ”¹ ==========
def load_stock_basic_info() -> pd.DataFrame:
    """åŠ è½½è‚¡ç¥¨åŸºç¡€ä¿¡æ¯"""
    try:
        if os.path.exists(BASIC_INFO_FILE):
            df = pd.read_csv(BASIC_INFO_FILE)
            logger.info(f"æˆåŠŸåŠ è½½è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ï¼Œå…± {len(df)} æ¡è®°å½•")
            return df
        else:
            logger.info("è‚¡ç¥¨åŸºç¡€ä¿¡æ¯æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶")
            return pd.DataFrame()
    except Exception as e:
        logger.error(f"åŠ è½½è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å¤±è´¥: {str(e)}")
        return pd.DataFrame()

def save_stock_basic_info(df: pd.DataFrame) -> bool:
    """ä¿å­˜è‚¡ç¥¨åŸºç¡€ä¿¡æ¯"""
    try:
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(BASIC_INFO_FILE), exist_ok=True)
        
        # ä¿å­˜æ–‡ä»¶
        df.to_csv(BASIC_INFO_FILE, index=False)
        logger.info(f"è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å·²ä¿å­˜ï¼Œå…± {len(df)} æ¡è®°å½•")
        return True
    except Exception as e:
        logger.error(f"ä¿å­˜è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å¤±è´¥: {str(e)}")
        return False

def get_last_update_time(df: pd.DataFrame, stock_code: str) -> Optional[datetime]:
    """è·å–è‚¡ç¥¨æœ€åæ›´æ–°æ—¶é—´"""
    if df.empty:
        return None
    
    stock_info = df[df["code"] == stock_code]
    if not stock_info.empty:
        last_update = stock_info["last_update"].values[0]
        try:
            # å°è¯•è§£ææ—¶é—´å­—ç¬¦ä¸²
            return datetime.strptime(last_update, "%Y-%m-%d %H:%M:%S")
        except:
            return None
    return None

def should_update_stock(df: pd.DataFrame, stock_code: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°è‚¡ç¥¨æ•°æ®"""
    last_update = get_last_update_time(df, stock_code)
    if last_update is None:
        return True
    
    # å¦‚æœæœ€åæ›´æ–°æ—¶é—´è¶…è¿‡DATA_UPDATE_INTERVALå¤©ï¼Œåˆ™éœ€è¦æ›´æ–°
    return (datetime.now() - last_update).days >= DATA_UPDATE_INTERVAL

def update_stock_basic_info(basic_info_df: pd.DataFrame, stock_code: str, stock_name: str, 
                           market_cap: float, section: str) -> pd.DataFrame:
    """æ›´æ–°è‚¡ç¥¨åŸºç¡€ä¿¡æ¯"""
    # å‡†å¤‡æ–°è®°å½•
    new_record = {
        "code": stock_code,
        "name": stock_name,
        "market_cap": market_cap,
        "section": section,
        "last_update": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }
    
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
    if not basic_info_df.empty:
        existing = basic_info_df[basic_info_df["code"] == stock_code]
        if not existing.empty:
            # æ›´æ–°ç°æœ‰è®°å½•
            idx = basic_info_df[basic_info_df["code"] == stock_code].index[0]
            for key, value in new_record.items():
                basic_info_df.at[idx, key] = value
            return basic_info_df
    
    # æ·»åŠ æ–°è®°å½•
    new_df = pd.DataFrame([new_record])
    if basic_info_df.empty:
        return new_df
    else:
        return pd.concat([basic_info_df, new_df], ignore_index=True)
# ========== ä»¥ä¸Šæ˜¯å…³é”®ä¿®æ”¹ ==========

def get_stock_section(stock_code: str) -> str:
    """æ ¹æ®è‚¡ç¥¨ä»£ç åˆ¤æ–­æ‰€å±æ¿å—
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç ï¼ˆ6ä½æ•°å­—ï¼‰
    
    Returns:
        str: æ¿å—åç§°
    """
    for section, config in MARKET_SECTIONS.items():
        for prefix in config["prefix"]:
            if stock_code.startswith(prefix):
                return section
    return "å…¶ä»–æ¿å—"

def fetch_stock_list() -> pd.DataFrame:
    """ä»ä»“åº“åŠ è½½è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ï¼Œå¿…è¦æ—¶æ›´æ–°"""
    try:
        logger.info("æ­£åœ¨åŠ è½½è‚¡ç¥¨åŸºç¡€ä¿¡æ¯...")
        
        # 1. å°è¯•åŠ è½½ç°æœ‰åŸºç¡€ä¿¡æ¯
        if os.path.exists(BASIC_INFO_FILE):
            basic_info_df = pd.read_csv(BASIC_INFO_FILE)
            logger.info(f"æˆåŠŸåŠ è½½ç°æœ‰è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ï¼Œå…± {len(basic_info_df)} æ¡è®°å½•")
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆåŸºäºæœ€åæ›´æ–°æ—¶é—´ï¼‰
            if "last_update" in basic_info_df.columns and not basic_info_df.empty:
                last_update_str = basic_info_df["last_update"].max()
                try:
                    last_update = datetime.strptime(last_update_str, "%Y-%m-%d %H:%M:%S")
                    if (datetime.now() - last_update).days < 1:
                        logger.info(f"è‚¡ç¥¨åŸºç¡€ä¿¡æ¯æœªè¿‡æœŸï¼ˆæœ€åæ›´æ–°: {last_update_str}ï¼‰ï¼Œä½¿ç”¨ç°æœ‰æ•°æ®")
                        # ä¿®å¤ï¼šç§»é™¤é‡å¤è®°å½•ï¼Œç¡®ä¿å”¯ä¸€æ€§
                        basic_info_df = basic_info_df.drop_duplicates(subset=['code'], keep='last')
                        logger.info(f"å»é‡åè‚¡ç¥¨åŸºç¡€ä¿¡æ¯æ•°é‡: {len(basic_info_df)} æ¡è®°å½•")
                        return basic_info_df
                except Exception as e:
                    logger.warning(f"è§£ææœ€åæ›´æ–°æ—¶é—´å¤±è´¥: {str(e)}ï¼Œå°†é‡æ–°è·å–æ•°æ®")
        else:
            logger.info("è‚¡ç¥¨åŸºç¡€ä¿¡æ¯æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶")
        
        # 2. è·å–Aè‚¡è‚¡ç¥¨åˆ—è¡¨
        logger.info("æ­£åœ¨ä»AkShareè·å–è‚¡ç¥¨åˆ—è¡¨...")
        stock_list = ak.stock_info_a_code_name()
        if stock_list.empty:
            logger.error("è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥ï¼šè¿”å›ä¸ºç©º")
            # å¦‚æœæ— æ³•è·å–æ–°æ•°æ®ï¼Œå°è¯•è¿”å›ç©ºDataFrame
            return pd.DataFrame(columns=["code", "name", "section", "market_cap", "last_update"])
        
        # è®°å½•åˆå§‹è‚¡ç¥¨æ•°é‡
        initial_count = len(stock_list)
        logger.info(f"æˆåŠŸè·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œå…± {initial_count} åªè‚¡ç¥¨ï¼ˆåˆå§‹æ•°é‡ï¼‰")
        
        # å‰ç½®ç­›é€‰æ¡ä»¶ï¼šè¿‡æ»¤STè‚¡ç¥¨å’Œéä¸»æ¿/ç§‘åˆ›æ¿/åˆ›ä¸šæ¿è‚¡ç¥¨
        stock_list = stock_list[~stock_list["name"].str.contains("ST")]
        stock_list = stock_list[stock_list["code"].str.startswith(("60", "00", "30", "688"))]
        
        # è®°å½•å‰ç½®ç­›é€‰åçš„è‚¡ç¥¨æ•°é‡
        filtered_count = len(stock_list)
        logger.info(f"ã€å‰ç½®ç­›é€‰ã€‘è¿‡æ»¤STè‚¡ç¥¨å’Œéä¸»æ¿/ç§‘åˆ›æ¿/åˆ›ä¸šæ¿è‚¡ç¥¨åï¼Œå‰©ä½™ {filtered_count} åªï¼ˆè¿‡æ»¤äº† {initial_count - filtered_count} åªï¼‰")
        
        # 3. åˆ›å»ºåŸºç¡€ä¿¡æ¯DataFrame
        basic_info_data = []
        for _, row in stock_list.iterrows():
            stock_code = row["code"]
            stock_name = row["name"]
            section = get_stock_section(stock_code)
            
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰è®°å½•
            existing_market_cap = 0
            existing_score = 0
            if os.path.exists(BASIC_INFO_FILE) and "code" in basic_info_df.columns:
                existing = basic_info_df[basic_info_df["code"] == stock_code]
                if not existing.empty:
                    # ä¿ç•™ç°æœ‰å¸‚å€¼å’Œè¯„åˆ†
                    existing_market_cap = existing["market_cap"].values[0]
                    if "score" in existing.columns:
                        existing_score = existing["score"].values[0]
            
            # åŸºç¡€ä¿¡æ¯åªåŒ…å«å¿…è¦å­—æ®µ
            basic_info_data.append({
                "code": stock_code,
                "name": stock_name,
                "section": section,
                "market_cap": existing_market_cap,
                "score": existing_score,
                "last_update": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            })
        
        basic_info_df = pd.DataFrame(basic_info_data)
        
        # 4. ä¿®å¤ï¼šç¡®ä¿è‚¡ç¥¨ä»£ç å”¯ä¸€ï¼Œç§»é™¤é‡å¤è®°å½•
        if "code" in basic_info_df.columns:
            basic_info_df = basic_info_df.drop_duplicates(subset=['code'], keep='last')
            logger.info(f"å»é‡åè‚¡ç¥¨åŸºç¡€ä¿¡æ¯æ•°é‡: {len(basic_info_df)} æ¡è®°å½•")
        
        # 5. ä¿å­˜åŸºç¡€ä¿¡æ¯
        os.makedirs(os.path.dirname(BASIC_INFO_FILE), exist_ok=True)
        basic_info_df.to_csv(BASIC_INFO_FILE, index=False)
        logger.info(f"è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å·²ä¿å­˜è‡³ {BASIC_INFO_FILE}ï¼Œå…± {len(basic_info_df)} æ¡è®°å½•")
        
        return basic_info_df
    
    except Exception as e:
        logger.error(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {str(e)}", exc_info=True)
        # å¦‚æœå¤±è´¥ï¼Œå°è¯•è¿”å›ç°æœ‰æ•°æ®
        if os.path.exists(BASIC_INFO_FILE):
            try:
                basic_info_df = pd.read_csv(BASIC_INFO_FILE)
                # ç¡®ä¿å”¯ä¸€æ€§
                if "code" in basic_info_df.columns:
                    basic_info_df = basic_info_df.drop_duplicates(subset=['code'], keep='last')
                    logger.warning(f"ä½¿ç”¨ç°æœ‰æ•°æ®å¹¶å»é‡ï¼Œå…± {len(basic_info_df)} æ¡è®°å½•")
                return basic_info_df
            except:
                pass
        return pd.DataFrame()

def fetch_stock_data(stock_code: str, days: int = 250) -> pd.DataFrame:
    """ä»AkShareè·å–ä¸ªè‚¡å†å²æ•°æ®
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç ï¼ˆä¸å¸¦å¸‚åœºå‰ç¼€ï¼‰
        days: è·å–æœ€è¿‘å¤šå°‘å¤©çš„æ•°æ®
    
    Returns:
        pd.DataFrame: ä¸ªè‚¡æ—¥çº¿æ•°æ®
    """
    try:
        # ç¡®å®šå¸‚åœºå‰ç¼€
        section = get_stock_section(stock_code)
        if section == "æ²ªå¸‚ä¸»æ¿" or section == "ç§‘åˆ›æ¿":
            market_prefix = "sh"
        else:  # æ·±å¸‚ä¸»æ¿ã€åˆ›ä¸šæ¿
            market_prefix = "sz"
        
        # è®¡ç®—æ—¥æœŸèŒƒå›´
        end_date = datetime.now().strftime("%Y%m%d")
        start_date = (datetime.now() - timedelta(days=days)).strftime("%Y%m%d")
        
        # å°è¯•å¤šç§å¯èƒ½çš„è‚¡ç¥¨ä»£ç æ ¼å¼
        possible_codes = [
            f"{market_prefix}{stock_code}",  # "sh000001"
            f"{stock_code}.{market_prefix.upper()}",  # "000001.SH"
            stock_code,  # "000001"
            f"{stock_code}.{'SZ' if market_prefix == 'sz' else 'SH'}",  # "000001.SZ"
            f"{market_prefix}{stock_code}.XSHG" if market_prefix == "sh" else f"{market_prefix}{stock_code}.XSHE",  # äº¤æ˜“æ‰€æ ¼å¼
        ]
        
        logger.debug(f"å°è¯•è·å–è‚¡ç¥¨ {stock_code} æ•°æ®ï¼Œå¯èƒ½çš„ä»£ç æ ¼å¼: {possible_codes}")
        logger.debug(f"æ—¶é—´èŒƒå›´: {start_date} è‡³ {end_date}")
        
        # å°è¯•ä½¿ç”¨å¤šç§æ¥å£å’Œä»£ç æ ¼å¼è·å–æ•°æ®
        df = None
        successful_code = None
        successful_interface = None
        
        # å…ˆå»ºè®®åˆ‡æ¢ä¸ºstock_zh_a_hist æ¥å£ä½¿ç”¨(è¯¥æ¥å£æ•°æ®è´¨é‡è¾ƒå¥½) [[2]]
        # å…ˆå°è¯•ä½¿ç”¨stock_zh_a_histæ¥å£
        for code in possible_codes:
            for attempt in range(5):  # å¢åŠ é‡è¯•æ¬¡æ•°
                try:
                    logger.debug(f"å°è¯•{attempt+1}/5: ä½¿ç”¨stock_zh_a_histæ¥å£è·å–è‚¡ç¥¨ {code}")
                    df = ak.stock_zh_a_hist(symbol=code, period="daily", 
                                           start_date=start_date, end_date=end_date, 
                                           adjust="qfq")
                    if not df.empty:
                        successful_code = code
                        successful_interface = "stock_zh_a_hist"
                        logger.debug(f"æˆåŠŸé€šè¿‡stock_zh_a_histæ¥å£è·å–è‚¡ç¥¨ {code} æ•°æ®")
                        break
                except Exception as e:
                    logger.debug(f"ä½¿ç”¨stock_zh_a_histæ¥å£è·å–è‚¡ç¥¨ {code} å¤±è´¥: {str(e)}")
                
                # æŒ‡æ•°é€€é¿ç­‰å¾…ï¼Œé¿å…é«˜å¹¶å‘è·å–æ•°æ®å¯¼è‡´IPè¢«æ‹‰é»‘ [[5]]
                time.sleep(0.5 * (2 ** attempt))
            
            if df is not None and not df.empty:
                break
        
        # å¦‚æœstock_zh_a_histæ¥å£å¤±è´¥ï¼Œå°è¯•stock_zh_a_dailyæ¥å£
        if df is None or df.empty:
            for code in possible_codes:
                for attempt in range(3):
                    try:
                        logger.debug(f"å°è¯•{attempt+1}/3: ä½¿ç”¨stock_zh_a_dailyæ¥å£è·å–è‚¡ç¥¨ {code}")
                        df = ak.stock_zh_a_daily(symbol=code, 
                                               start_date=start_date, 
                                               end_date=end_date, 
                                               adjust="qfq")
                        if not df.empty:
                            successful_code = code
                            successful_interface = "stock_zh_a_daily"
                            logger.debug(f"æˆåŠŸé€šè¿‡stock_zh_a_dailyæ¥å£è·å–è‚¡ç¥¨ {code} æ•°æ®")
                            break
                    except Exception as e:
                        logger.debug(f"ä½¿ç”¨stock_zh_a_dailyæ¥å£è·å–è‚¡ç¥¨ {code} å¤±è´¥: {str(e)}")
                    
                    time.sleep(1.0 * (2 ** attempt))
                
                if df is not None and not df.empty:
                    break
        
        # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œè¿”å›ç©ºDataFrame
        if df is None or df.empty:
            logger.warning(f"è·å–è‚¡ç¥¨ {stock_code} æ•°æ®å¤±è´¥ï¼Œæ‰€æœ‰æ¥å£å’Œä»£ç æ ¼å¼å‡æ— æ•ˆ")
            return pd.DataFrame()
        
        logger.info(f"âœ… æˆåŠŸé€šè¿‡ {successful_interface} æ¥å£è·å–è‚¡ç¥¨ {successful_code} æ•°æ®ï¼Œå…± {len(df)} å¤©")
        
        # å¤„ç†å¯èƒ½çš„åˆ—åå·®å¼‚
        if 'date' in df.columns:
            # è‹±æ–‡åˆ—åæ˜ å°„åˆ°æ ‡å‡†åˆ—å
            column_mapping = {
                'date': 'æ—¥æœŸ',
                'open': 'å¼€ç›˜',
                'high': 'æœ€é«˜',
                'low': 'æœ€ä½',
                'close': 'æ”¶ç›˜',
                'volume': 'æˆäº¤é‡',
                'amount': 'æˆäº¤é¢',
                'amplitude': 'æŒ¯å¹…',
                'percent': 'æ¶¨è·Œå¹…',
                'change': 'æ¶¨è·Œé¢',
                'turnover': 'æ¢æ‰‹ç‡'
            }
        else:
            # ä¸­æ–‡åˆ—åæ˜ å°„åˆ°æ ‡å‡†åˆ—å
            column_mapping = {
                'æ—¥æœŸ': 'æ—¥æœŸ',
                'å¼€ç›˜': 'å¼€ç›˜',
                'æœ€é«˜': 'æœ€é«˜',
                'æœ€ä½': 'æœ€ä½',
                'æ”¶ç›˜': 'æ”¶ç›˜',
                'æˆäº¤é‡': 'æˆäº¤é‡',
                'æˆäº¤é¢': 'æˆäº¤é¢',
                'æŒ¯å¹…': 'æŒ¯å¹…',
                'æ¶¨è·Œå¹…': 'æ¶¨è·Œå¹…',
                'æ¶¨è·Œé¢': 'æ¶¨è·Œé¢',
                'æ¢æ‰‹ç‡': 'æ¢æ‰‹ç‡'
            }
        
        # é‡å‘½ååˆ—
        df = df.rename(columns={k: v for k, v in column_mapping.items() if k in df.columns})
        
        # ç¡®ä¿æ—¥æœŸåˆ—å­˜åœ¨
        if 'æ—¥æœŸ' not in df.columns and 'date' in df.columns:
            df = df.rename(columns={'date': 'æ—¥æœŸ'})
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦çš„åˆ—
        required_columns = ["æ—¥æœŸ", "å¼€ç›˜", "æœ€é«˜", "æœ€ä½", "æ”¶ç›˜", "æˆäº¤é‡"]
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            logger.warning(f"è‚¡ç¥¨ {stock_code} æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {', '.join(missing_columns)}")
            return pd.DataFrame()
        
        # ç¡®ä¿æ—¥æœŸåˆ—æ˜¯å­—ç¬¦ä¸²ç±»å‹
        if "æ—¥æœŸ" in df.columns:
            df["æ—¥æœŸ"] = df["æ—¥æœŸ"].astype(str)
            # ç¡®ä¿æ—¥æœŸæ ¼å¼ä¸ºYYYY-MM-DD
            df["æ—¥æœŸ"] = df["æ—¥æœŸ"].str.replace(r'(\d{4})/(\d{1,2})/(\d{1,2})', 
                                              lambda m: f"{m.group(1)}-{int(m.group(2)):02d}-{int(m.group(3)):02d}", 
                                              regex=True)
            df = df.sort_values("æ—¥æœŸ", ascending=True)
        
        # æ£€æŸ¥æ•°æ®é‡
        if len(df) < 10:
            logger.warning(f"è‚¡ç¥¨ {stock_code} æ•°æ®é‡ä¸è¶³({len(df)}å¤©)ï¼Œå¯èƒ½å½±å“åˆ†æç»“æœ")
        
        logger.debug(f"æˆåŠŸè·å–è‚¡ç¥¨ {stock_code} æ•°æ®ï¼Œå…± {len(df)} æ¡è®°å½•")
        return df
    
    except Exception as e:
        logger.debug(f"è·å–è‚¡ç¥¨ {stock_code} æ•°æ®å¤±è´¥: {str(e)}")
        return pd.DataFrame()

def calculate_annual_volatility(df: pd.DataFrame) -> float:
    """è®¡ç®—å¹´åŒ–æ³¢åŠ¨ç‡"""
    if len(df) < 20:
        logger.warning(f"æ•°æ®ä¸è¶³20å¤©ï¼Œæ— æ³•å‡†ç¡®è®¡ç®—æ³¢åŠ¨ç‡")
        return 0.2  # é»˜è®¤æ³¢åŠ¨ç‡
    
    # è®¡ç®—æ—¥æ”¶ç›Šç‡
    # ========== ä»¥ä¸‹æ˜¯å…³é”®ä¿®æ”¹ ==========
    # åŸå§‹ä»£ç : daily_returns = df["æ”¶ç›˜"].pct_change().dropna()
    # ä¿®æ”¹ä¸º: ä½¿ç”¨æ ‡å‡†åˆ—å 'æ”¶ç›˜'
    daily_returns = df["æ”¶ç›˜"].pct_change().dropna()
    # ========== ä»¥ä¸Šæ˜¯å…³é”®ä¿®æ”¹ ==========
    
    # è®¡ç®—å¹´åŒ–æ³¢åŠ¨ç‡
    if len(daily_returns) >= 20:
        volatility = daily_returns.std() * np.sqrt(252)
    else:
        volatility = 0.2  # é»˜è®¤æ³¢åŠ¨ç‡
    
    # é™åˆ¶æ³¢åŠ¨ç‡åœ¨åˆç†èŒƒå›´å†…
    volatility = max(0.05, min(1.0, volatility))
    
    return volatility

def calculate_market_cap(df: pd.DataFrame, stock_code: str) -> float:
    """ç›´æ¥ä»æ¥å£è·å–å¸‚å€¼ï¼ˆæ— éœ€è®¡ç®—ï¼‰"""
    try:
        # 1. ç›´æ¥è·å–å®æ—¶è¡Œæƒ…æ•°æ®
        stock_info = ak.stock_zh_a_spot_em()
        if stock_info.empty:
            logger.warning(f"æ— æ³•è·å–è‚¡ç¥¨ {stock_code} çš„å®æ—¶è¡Œæƒ…æ•°æ®")
            return 0.0
        
        # 2. æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç åŒ¹é…ï¼ˆçº¯6ä½æ•°å­—ï¼‰
        stock_code_std = stock_code.zfill(6)
        
        # 3. å°è¯•åŒ¹é…è‚¡ç¥¨
        matched = stock_info[stock_info["ä»£ç "] == stock_code_std]
        
        # 4. å¦‚æœåŒ¹é…æˆåŠŸï¼Œç›´æ¥è·å–æµé€šå¸‚å€¼
        if not matched.empty:
            if "æµé€šå¸‚å€¼" in matched.columns:
                market_cap = float(matched["æµé€šå¸‚å€¼"].iloc[0])
                if market_cap > 0:
                    # æ­£ç¡®è½¬æ¢ï¼šå…ƒ â†’ äº¿å…ƒï¼ˆé™¤ä»¥100,000,000ï¼‰
                    market_cap_in_billion = market_cap / 100000000
                    logger.debug(f"âœ… ä½¿ç”¨å®æ—¶æ•°æ®è·å–æµé€šå¸‚å€¼: {market_cap_in_billion:.2f}äº¿å…ƒ")
                    return market_cap_in_billion
        
        # 5. å¦‚æœæµé€šå¸‚å€¼ä¸å¯ç”¨ï¼Œå°è¯•æ€»å¸‚å€¼
        if not matched.empty and "æ€»å¸‚å€¼" in matched.columns:
            market_cap = float(matched["æ€»å¸‚å€¼"].iloc[0])
            if market_cap > 0:
                market_cap_in_billion = market_cap / 100000000
                logger.debug(f"âœ… ä½¿ç”¨å®æ—¶æ•°æ®è·å–æ€»å¸‚å€¼: {market_cap_in_billion:.2f}äº¿å…ƒ")
                return market_cap_in_billion
        
        logger.warning(f"âŒ æ— æ³•è·å–è‚¡ç¥¨ {stock_code} çš„æœ‰æ•ˆå¸‚å€¼æ•°æ®")
        return 0.0
    
    except Exception as e:
        logger.error(f"è·å–è‚¡ç¥¨ {stock_code} å¸‚å€¼å¤±è´¥: {str(e)}", exc_info=True)
        return 0.0

def is_stock_suitable(stock_code: str, df: pd.DataFrame) -> bool:
    """åˆ¤æ–­ä¸ªè‚¡æ˜¯å¦é€‚åˆç­–ç•¥ï¼ˆæµåŠ¨æ€§ã€æ³¢åŠ¨ç‡ã€å¸‚å€¼ä¸‰é‡è¿‡æ»¤ï¼‰
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        df: è‚¡ç¥¨æ—¥çº¿æ•°æ®
    
    Returns:
        bool: æ˜¯å¦é€‚åˆç­–ç•¥
    """
    try:
        if df is None or df.empty or len(df) < MIN_DATA_DAYS:
            logger.debug(f"è‚¡ç¥¨ {stock_code} æ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
            return False
        
        # è·å–è‚¡ç¥¨æ‰€å±æ¿å—
        section = get_stock_section(stock_code)
        if section == "å…¶ä»–æ¿å—" or section not in MARKET_SECTIONS:
            logger.debug(f"è‚¡ç¥¨ {stock_code} ä¸å±äºä»»ä½•æ¿å—ï¼Œè·³è¿‡")
            return False
        
        # è·å–æ¿å—é…ç½®
        section_config = MARKET_SECTIONS[section]
        
        # 1. æµåŠ¨æ€§è¿‡æ»¤ï¼ˆæ—¥å‡æˆäº¤>è®¾å®šé˜ˆå€¼ï¼‰
        # ä¿®æ­£ï¼šAè‚¡çš„æˆäº¤é‡å•ä½æ˜¯"æ‰‹"ï¼ˆ1æ‰‹=100è‚¡ï¼‰ï¼Œéœ€è¦ä¹˜ä»¥100
        if 'æˆäº¤é‡' in df.columns and 'æ”¶ç›˜' in df.columns and len(df) >= 20:
            daily_volume = df["æˆäº¤é‡"].iloc[-20:].mean() * 100 * df["æ”¶ç›˜"].iloc[-20:].mean()
            logger.info(f"ã€æµåŠ¨æ€§è¿‡æ»¤ã€‘è‚¡ç¥¨ {stock_code} - {section} - æ—¥å‡æˆäº¤é¢: {daily_volume/10000:.2f}ä¸‡å…ƒ, è¦æ±‚: >{section_config['min_daily_volume']/10000:.2f}ä¸‡å…ƒ")
            
            if daily_volume < section_config["min_daily_volume"]:
                logger.info(f"ã€æµåŠ¨æ€§è¿‡æ»¤ã€‘è‚¡ç¥¨ {stock_code} - {section} - æµåŠ¨æ€§è¿‡æ»¤å¤±è´¥ï¼ˆæ—¥å‡æˆäº¤é¢ä¸è¶³ï¼‰")
                return False
            else:
                logger.info(f"ã€æµåŠ¨æ€§è¿‡æ»¤ã€‘è‚¡ç¥¨ {stock_code} - {section} - é€šè¿‡æµåŠ¨æ€§è¿‡æ»¤")
        else:
            logger.debug(f"è‚¡ç¥¨ {stock_code} ç¼ºå°‘æˆäº¤é‡æˆ–æ”¶ç›˜ä»·æ•°æ®ï¼Œæ— æ³•è¿›è¡ŒæµåŠ¨æ€§è¿‡æ»¤")
            return False
        
        # 2. æ³¢åŠ¨ç‡è¿‡æ»¤ï¼ˆå¹´åŒ–æ³¢åŠ¨ç‡<è®¾å®šé˜ˆå€¼ï¼‰
        annual_volatility = calculate_annual_volatility(df)
        logger.info(f"ã€æ³¢åŠ¨ç‡è¿‡æ»¤ã€‘è‚¡ç¥¨ {stock_code} - {section} - å¹´åŒ–æ³¢åŠ¨ç‡: {annual_volatility:.2%}, è¦æ±‚: <{section_config['max_volatility']:.0%}")
        
        if annual_volatility > section_config["max_volatility"]:
            logger.info(f"ã€æ³¢åŠ¨ç‡è¿‡æ»¤ã€‘è‚¡ç¥¨ {stock_code} - {section} - æ³¢åŠ¨ç‡è¿‡æ»¤å¤±è´¥ï¼ˆæ³¢åŠ¨ç‡è¿‡é«˜ï¼‰")
            return False
        else:
            logger.info(f"ã€æ³¢åŠ¨ç‡è¿‡æ»¤ã€‘è‚¡ç¥¨ {stock_code} - {section} - é€šè¿‡æ³¢åŠ¨ç‡è¿‡æ»¤")
        
        # 3. å¸‚å€¼è¿‡æ»¤ï¼ˆå¸‚å€¼>è®¾å®šé˜ˆå€¼ï¼‰
        market_cap = calculate_market_cap(df, stock_code)
        logger.info(f"ã€å¸‚å€¼è¿‡æ»¤ã€‘è‚¡ç¥¨ {stock_code} - {section} - å¸‚å€¼: {market_cap:.2f}äº¿å…ƒ, è¦æ±‚: >{section_config['min_market_cap']:.2f}äº¿å…ƒ")
        
        if market_cap < section_config["min_market_cap"]:
            logger.info(f"ã€å¸‚å€¼è¿‡æ»¤ã€‘è‚¡ç¥¨ {stock_code} - {section} - å¸‚å€¼è¿‡æ»¤å¤±è´¥ï¼ˆå¸‚å€¼ä¸è¶³ï¼‰")
            return False
        else:
            logger.info(f"ã€å¸‚å€¼è¿‡æ»¤ã€‘è‚¡ç¥¨ {stock_code} - {section} - é€šè¿‡å¸‚å€¼è¿‡æ»¤")
        
        logger.info(f"ã€æœ€ç»ˆç»“æœã€‘è‚¡ç¥¨ {stock_code} - {section} - é€šè¿‡æ‰€æœ‰è¿‡æ»¤æ¡ä»¶")
        return True
    
    except Exception as e:
        logger.error(f"ç­›é€‰è‚¡ç¥¨{stock_code}å¤±è´¥: {str(e)}", exc_info=True)
        return False

def calculate_stock_strategy_score(stock_code: str, df: pd.DataFrame) -> float:
    """è®¡ç®—è‚¡ç¥¨ç­–ç•¥è¯„åˆ†
    
    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        df: é¢„å¤„ç†åçš„è‚¡ç¥¨æ•°æ®
    
    Returns:
        float: è¯„åˆ†(0-100)
    """
    try:
        if df is None or df.empty or len(df) < 40:
            logger.debug(f"è‚¡ç¥¨ {stock_code} æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—ç­–ç•¥è¯„åˆ†")
            return 0.0
        
        # æ£€æŸ¥å¿…è¦åˆ—
        required_columns = ['å¼€ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æ”¶ç›˜', 'æˆäº¤é‡']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            logger.debug(f"è‚¡ç¥¨ {stock_code} æ•°æ®ç¼ºå°‘å¿…è¦åˆ—: {', '.join(missing_columns)}ï¼Œæ— æ³•è®¡ç®—ç­–ç•¥è¯„åˆ†")
            return 0.0
        
        # è·å–æœ€æ–°æ•°æ®
        current = df["æ”¶ç›˜"].iloc[-1]
        if pd.isna(current) or current <= 0:
            logger.debug(f"è‚¡ç¥¨ {stock_code} æ— æ•ˆçš„æ”¶ç›˜ä»·: {current}")
            return 0.0
        
        volume = df["æˆäº¤é‡"].iloc[-1] if "æˆäº¤é‡" in df.columns and len(df) >= 1 else 0
        
        # 1. è¶‹åŠ¿è¯„åˆ† (40%)
        trend_score = 0.0
        if len(df) >= 40:
            # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
            df["ma5"] = df["æ”¶ç›˜"].rolling(window=5).mean()
            df["ma10"] = df["æ”¶ç›˜"].rolling(window=10).mean()
            df["ma20"] = df["æ”¶ç›˜"].rolling(window=20).mean()
            df["ma40"] = df["æ”¶ç›˜"].rolling(window=CRITICAL_VALUE_DAYS).mean()
            
            ma5 = df["ma5"].iloc[-1] if "ma5" in df.columns else current
            ma10 = df["ma10"].iloc[-1] if "ma10" in df.columns else current
            ma20 = df["ma20"].iloc[-1] if "ma20" in df.columns else current
            ma40 = df["ma40"].iloc[-1] if "ma40" in df.columns else current
            
            # æ£€æŸ¥çŸ­æœŸå‡çº¿æ˜¯å¦åœ¨é•¿æœŸå‡çº¿ä¸Šæ–¹ï¼ˆå¤šå¤´æ’åˆ—ï¼‰
            if ma5 > ma10 > ma20 > ma40 and all(not pd.isna(x) for x in [ma5, ma10, ma20, ma40]):
                trend_score += 20  # å¤šå¤´æ’åˆ—ï¼ŒåŠ 20åˆ†
            
            # æ£€æŸ¥ä»·æ ¼æ˜¯å¦åœ¨å‡çº¿ä¸Šæ–¹
            if not pd.isna(ma20) and current > ma20:
                trend_score += 10  # ä»·æ ¼åœ¨20æ—¥å‡çº¿ä¸Šæ–¹ï¼ŒåŠ 10åˆ†
            
            # æ£€æŸ¥è¶‹åŠ¿å¼ºåº¦
            if len(df) >= 20:
                price_change_20 = (current - df["æ”¶ç›˜"].iloc[-20]) / df["æ”¶ç›˜"].iloc[-20] * 100
                if not pd.isna(price_change_20) and price_change_20 > 5:
                    trend_score += 10  # 20æ—¥æ¶¨å¹…å¤§äº5%ï¼ŒåŠ 10åˆ†
        
        # 2. åŠ¨é‡è¯„åˆ† (20%)
        momentum_score = 0.0
        # è®¡ç®—MACD
        if "æ”¶ç›˜" in df.columns:
            df["ema12"] = df["æ”¶ç›˜"].ewm(span=12, adjust=False).mean()
            df["ema26"] = df["æ”¶ç›˜"].ewm(span=26, adjust=False).mean()
            df["macd"] = df["ema12"] - df["ema26"]
            df["signal"] = df["macd"].ewm(span=9, adjust=False).mean()
            df["hist"] = df["macd"] - df["signal"]
        
        if "hist" in df.columns and len(df) >= 2:
            macd_hist = df["hist"].iloc[-1]
            macd_hist_prev = df["hist"].iloc[-2]
            
            # MACDæŸ±çŠ¶ä½“å¢åŠ 
            if not pd.isna(macd_hist) and not pd.isna(macd_hist_prev) and macd_hist > macd_hist_prev and macd_hist > 0:
                momentum_score += 10  # MACDæŸ±çŠ¶ä½“å¢åŠ ä¸”ä¸ºæ­£ï¼ŒåŠ 10åˆ†
            
            # RSIæŒ‡æ ‡
            if "æ”¶ç›˜" in df.columns:
                delta = df["æ”¶ç›˜"].diff()
                gain = delta.where(delta > 0, 0)
                loss = -delta.where(delta < 0, 0)
                avg_gain = gain.rolling(window=14).mean()
                avg_loss = loss.rolling(window=14).mean()
                rs = avg_gain / avg_loss.replace(0, np.nan)  # é¿å…é™¤é›¶é”™è¯¯
                df["rsi"] = 100 - (100 / (1 + rs))
            
            if "rsi" in df.columns:
                rsi = df["rsi"].iloc[-1]
                if not pd.isna(rsi):
                    if 50 < rsi < 70:
                        momentum_score += 10  # RSIåœ¨50-70ä¹‹é—´ï¼ŒåŠ 10åˆ†
                    elif rsi >= 70:
                        momentum_score += 5  # RSIå¤§äº70ï¼ŒåŠ 5åˆ†
        
        # 3. é‡èƒ½è¯„åˆ† (20%)
        volume_score = 0.0
        if "æˆäº¤é‡" in df.columns:
            df["volume_ma5"] = df["æˆäº¤é‡"].rolling(window=5).mean()
        
        volume_ma5 = df["volume_ma5"].iloc[-1] if "volume_ma5" in df.columns and len(df) >= 1 else 0
        if volume_ma5 > 0 and volume > 0:
            volume_ratio = volume / volume_ma5
            
            # é‡èƒ½æ”¾å¤§
            if volume_ratio > 1.5:
                volume_score += 10  # é‡èƒ½æ”¾å¤§50%ä»¥ä¸Šï¼ŒåŠ 10åˆ†
            elif volume_ratio > 1.2:
                volume_score += 5  # é‡èƒ½æ”¾å¤§20%ä»¥ä¸Šï¼ŒåŠ 5åˆ†
            
            # é‡ä»·é…åˆ
            if len(df) >= 2:
                price_change = (current - df["æ”¶ç›˜"].iloc[-2]) / df["æ”¶ç›˜"].iloc[-2] * 100
                if price_change > 0 and volume_ratio > 1.0:
                    volume_score += 10  # ä»·æ ¼ä¸Šæ¶¨ä¸”é‡èƒ½æ”¾å¤§ï¼ŒåŠ 10åˆ†
        
        # 4. æ³¢åŠ¨ç‡è¯„åˆ† (20%)
        volatility_score = 0.0
        # è®¡ç®—æ³¢åŠ¨ç‡ï¼ˆ20æ—¥å¹´åŒ–æ³¢åŠ¨ç‡ï¼‰
        if "æ”¶ç›˜" in df.columns:
            df["pct_change"] = df["æ”¶ç›˜"].pct_change() * 100
        
        if "pct_change" in df.columns:
            df["volatility"] = df["pct_change"].rolling(window=20).std() * np.sqrt(252)
        
        if "volatility" in df.columns and len(df) >= 20:
            volatility = df["volatility"].iloc[-1]
            
            if not pd.isna(volatility):
                # é€‚ä¸­çš„æ³¢åŠ¨ç‡
                if 15 <= volatility <= 30:
                    volatility_score += 10  # æ³¢åŠ¨ç‡åœ¨15%-30%ä¹‹é—´ï¼ŒåŠ 10åˆ†
                elif volatility > 30:
                    volatility_score += 5  # æ³¢åŠ¨ç‡å¤§äº30%ï¼ŒåŠ 5åˆ†
                
                # æ³¢åŠ¨ç‡è¶‹åŠ¿
                if len(df) >= 21:
                    prev_volatility = df["volatility"].iloc[-21]
                    if not pd.isna(prev_volatility) and prev_volatility > 0:
                        volatility_change = (volatility - prev_volatility) / prev_volatility
                        
                        if -0.1 <= volatility_change <= 0.1:
                            volatility_score += 10  # æ³¢åŠ¨ç‡ç¨³å®šï¼ŒåŠ 10åˆ†
        
        # ç»¼åˆè¯„åˆ†
        total_score = trend_score + momentum_score + volume_score + volatility_score
        total_score = max(0, min(100, total_score))  # é™åˆ¶åœ¨0-100èŒƒå›´å†…
        
        logger.debug(f"è‚¡ç¥¨ {stock_code} ç­–ç•¥è¯„åˆ†: {total_score:.2f} "
                     f"(è¶‹åŠ¿={trend_score:.1f}, åŠ¨é‡={momentum_score:.1f}, "
                     f"é‡èƒ½={volume_score:.1f}, æ³¢åŠ¨ç‡={volatility_score:.1f})")
        
        return total_score
    
    except Exception as e:
        logger.error(f"è®¡ç®—è‚¡ç¥¨ {stock_code} ç­–ç•¥è¯„åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        return 0.0

def get_top_stocks_for_strategy() -> Dict[str, List[Dict]]:
    """æŒ‰æ¿å—è·å–é€‚åˆç­–ç•¥çš„è‚¡ç¥¨"""
    try:
        # 1. è·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯
        basic_info_df = fetch_stock_list()
        if basic_info_df.empty:
            logger.error("è·å–è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
            return {}
        
        logger.info(f"å·²åŠ è½½è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ï¼Œå…± {len(basic_info_df)} æ¡è®°å½•")
        
        # 2. æŒ‰æ¿å—åˆ†ç»„å¤„ç†
        section_stocks = {section: [] for section in MARKET_SECTIONS.keys()}
        
        # 3. åˆå§‹åŒ–å„æ¿å—è®¡æ•°å™¨
        section_counts = {section: {"total": 0, "data_ok": 0, "suitable": 0, "scored": 0}
                         for section in MARKET_SECTIONS.keys()}
        
        # 4. å¤„ç†æ¯åªè‚¡ç¥¨
        stock_list = basic_info_df.to_dict('records')
        
        def process_stock(stock):
            stock_code = stock["code"]
            stock_name = stock["name"]
            section = stock["section"]
            
            # æ£€æŸ¥æ¿å—æ˜¯å¦æœ‰æ•ˆ
            if section not in MARKET_SECTIONS:
                return None
            
            # æ›´æ–°æ¿å—è®¡æ•°å™¨
            section_counts[section]["total"] += 1
            
            # è·å–æ—¥çº¿æ•°æ®
            df = fetch_stock_data(stock_code)
            
            # æ£€æŸ¥æ•°æ®é‡
            if df is None or df.empty or len(df) < MIN_DATA_DAYS:
                return None
            
            # æ›´æ–°æ¿å—è®¡æ•°å™¨
            section_counts[section]["data_ok"] += 1
            
            # æ£€æŸ¥æ˜¯å¦é€‚åˆç­–ç•¥
            if is_stock_suitable(stock_code, df):
                # æ›´æ–°æ¿å—è®¡æ•°å™¨
                section_counts[section]["suitable"] += 1
                
                # è®¡ç®—ç­–ç•¥å¾—åˆ†
                score = calculate_stock_strategy_score(stock_code, df)
                
                if score > 0:
                    # æ›´æ–°æ¿å—è®¡æ•°å™¨
                    section_counts[section]["scored"] += 1
                    return {
                        "code": stock_code,
                        "name": stock_name,
                        "score": score,
                        "df": df,
                        "section": section
                    }
            
            return None
        
        # 5. å¹¶è¡Œå¤„ç†è‚¡ç¥¨ï¼ˆé™åˆ¶å¹¶å‘æ•°é‡ï¼Œé¿å…è¢«AkShareé™åˆ¶ï¼‰
        results = []
        with ThreadPoolExecutor(max_workers=5) as executor:
            # åˆ†æ‰¹å¤„ç†ï¼Œé¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
            for i in range(0, len(stock_list), 10):
                batch = stock_list[i:i+10]
                batch_results = list(executor.map(process_stock, batch))
                results.extend(batch_results)
                time.sleep(1.0)  # æ‰¹æ¬¡é—´ç­‰å¾…
        
        # 6. æ”¶é›†ç»“æœ
        for result in results:
            if result is not None:
                section = result["section"]
                section_stocks[section].append(result)
        
        # 7. è®°å½•å„æ¿å—ç­›é€‰ç»“æœ
        for section, counts in section_counts.items():
            if counts["total"] > 0:
                logger.info(f"ã€ç­›é€‰ç»Ÿè®¡ã€‘æ¿å— {section}:")
                logger.info(f"  - æ€»è‚¡ç¥¨æ•°é‡: {counts['total']}")
                logger.info(f"  - æ•°æ®é‡è¶³å¤Ÿ: {counts['data_ok']} ({counts['data_ok']/counts['total']*100:.1f}%)")
                logger.info(f"  - é€šè¿‡ä¸‰é‡è¿‡æ»¤: {counts['suitable']} ({counts['suitable']/counts['total']*100:.1f}%)")
                logger.info(f"  - è¯„åˆ†>0: {counts['scored']} ({counts['scored']/counts['total']*100:.1f}%)")
        
        # 8. å¯¹æ¯ä¸ªæ¿å—çš„è‚¡ç¥¨æŒ‰å¾—åˆ†æ’åºï¼Œå¹¶å–å‰Nåª
        top_stocks_by_section = {}
        for section, stocks in section_stocks.items():
            if stocks:
                stocks.sort(key=lambda x: x["score"], reverse=True)
                top_stocks = stocks[:MAX_STOCKS_PER_SECTION]
                top_stocks_by_section[section] = top_stocks
                logger.info(f"ã€æœ€ç»ˆç»“æœã€‘æ¿å— {section} ç­›é€‰å‡º {len(top_stocks)} åªè‚¡ç¥¨")
        
        # 9. æ›´æ–°åŸºç¡€ä¿¡æ¯ä¸­çš„å¸‚å€¼å’Œè¯„åˆ†
        updated_records = []
        for section, stocks in top_stocks_by_section.items():
            for stock in stocks:
                stock_code = stock["code"]
                stock_name = stock["name"]
                section = stock["section"]
                market_cap = calculate_market_cap(stock["df"], stock_code)
                score = stock["score"]
                
                # æ›´æ–°è®°å½•
                updated_records.append({
                    "code": stock_code,
                    "name": stock_name,
                    "section": section,
                    "market_cap": market_cap,
                    "score": score,
                    "last_update": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                })
        
        # 10. ä¿å­˜æ›´æ–°åçš„åŸºç¡€ä¿¡æ¯
        if updated_records:
            updated_df = pd.DataFrame(updated_records)
            # åˆå¹¶åˆ°åŸºç¡€ä¿¡æ¯
            for _, record in updated_df.iterrows():
                mask = basic_info_df["code"] == record["code"]
                if mask.any():
                    # æ›´æ–°ç°æœ‰è®°å½•
                    basic_info_df.loc[mask, "market_cap"] = record["market_cap"]
                    basic_info_df.loc[mask, "score"] = record["score"]
                    basic_info_df.loc[mask, "last_update"] = record["last_update"]
                else:
                    # æ·»åŠ æ–°è®°å½•
                    basic_info_df = pd.concat([basic_info_df, pd.DataFrame([record])], ignore_index=True)
            
            # ä¿å­˜æ›´æ–°
            basic_info_df.to_csv(BASIC_INFO_FILE, index=False)
            logger.info(f"è‚¡ç¥¨åŸºç¡€ä¿¡æ¯å·²æ›´æ–°ï¼Œå…± {len(basic_info_df)} æ¡è®°å½•")
        
        return top_stocks_by_section
    
    except Exception as e:
        logger.error(f"è·å–ä¼˜è´¨è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {str(e)}", exc_info=True)
        return {}

def generate_stock_signal_message(stock: Dict, df: pd.DataFrame, 
                                close_price: float, critical_value: float, 
                                deviation: float) -> str:
    """ç”Ÿæˆè‚¡ç¥¨ä¿¡å·è¯¦ç»†æ¶ˆæ¯
    
    Args:
        stock: è‚¡ç¥¨ä¿¡æ¯
        df: è‚¡ç¥¨æ•°æ®
        close_price: å½“å‰æ”¶ç›˜ä»·
        critical_value: ä¸´ç•Œå€¼
        deviation: åç¦»åº¦
    
    Returns:
        str: ä¿¡å·è¯¦ç»†æ¶ˆæ¯
    """
    stock_code = stock["code"]
    stock_name = stock["name"]
    
    # è·å–æœ€æ–°æ•°æ®
    latest_data = df.iloc[-1]
    
    # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…è¦åˆ—
    required_columns = ['å¼€ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æ”¶ç›˜', 'æˆäº¤é‡']
    missing_columns = [col for col in required_columns if col not in df.columns]
    
    if missing_columns:
        return f"{stock_name}({stock_code}) æ•°æ®ä¸å®Œæ•´ï¼Œæ— æ³•ç”Ÿæˆä¿¡å·"
    
    # è®¡ç®—æŒ‡æ ‡
    ma5 = latest_data["æ”¶ç›˜"] if len(df) < 5 else df["æ”¶ç›˜"].rolling(5).mean().iloc[-1]
    ma10 = latest_data["æ”¶ç›˜"] if len(df) < 10 else df["æ”¶ç›˜"].rolling(10).mean().iloc[-1]
    ma20 = latest_data["æ”¶ç›˜"] if len(df) < 20 else df["æ”¶ç›˜"].rolling(20).mean().iloc[-1]
    volume = latest_data["æˆäº¤é‡"]
    volume_ma5 = volume if len(df) < 5 else df["æˆäº¤é‡"].rolling(5).mean().iloc[-1]
    
    # é‡èƒ½åˆ†æ
    volume_ratio = volume / volume_ma5 if volume_ma5 > 0 else 1.0
    volume_analysis = "é‡èƒ½æ”¾å¤§" if volume_ratio > 1.2 else "é‡èƒ½å¹³ç¨³" if volume_ratio > 0.8 else "é‡èƒ½èç¼©"
    
    # è¶‹åŠ¿åˆ†æ
    trend_analysis = "å¤šå¤´æ’åˆ—" if ma5 > ma10 > ma20 else "ç©ºå¤´æ’åˆ—" if ma5 < ma10 < ma20 else "éœ‡è¡èµ°åŠ¿"
    
    # ç”Ÿæˆæ¶ˆæ¯
    message = []
    message.append(f"{stock_name}({stock_code})")
    message.append(f"ğŸ“Š ä»·æ ¼: {close_price:.4f} | ä¸´ç•Œå€¼: {critical_value:.4f} | åç¦»åº¦: {deviation:.2%}")
    message.append(f"ğŸ“ˆ è¶‹åŠ¿: {trend_analysis} | {volume_analysis}")
    message.append(f"â° é‡èƒ½: {volume:,.0f}æ‰‹ | 5æ—¥å‡é‡: {volume_ma5:,.0f}æ‰‹ | æ¯”ä¾‹: {volume_ratio:.2f}")
    
    return "\n".join(message)

def generate_strategy_summary(top_stocks_by_section: Dict[str, List[Dict]]) -> str:
    """ç”Ÿæˆç­–ç•¥æ€»ç»“æ¶ˆæ¯
    
    Args:
        top_stocks_by_section: æŒ‰æ¿å—ç»„ç»‡çš„è‚¡ç¥¨ä¿¡æ¯
    
    Returns:
        str: ç­–ç•¥æ€»ç»“æ¶ˆæ¯
    """
    summary_lines = []
    
    # æ·»åŠ æ ‡é¢˜
    beijing_time = get_beijing_time()
    summary_lines.append(f"ğŸ“Š ä¸ªè‚¡è¶‹åŠ¿ç­–ç•¥æŠ¥å‘Š ({beijing_time.strftime('%Y-%m-%d %H:%M')})")
    summary_lines.append("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    
    # æ·»åŠ å„æ¿å—ç»“æœ
    total_stocks = 0
    for section, stocks in top_stocks_by_section.items():
        if stocks:
            summary_lines.append(f"ğŸ“Œ {section}æ¿å— ({len(stocks)}åª):")
            for stock in stocks:
                stock_code = stock["code"]
                stock_name = stock["name"]
                score = stock["score"]
                summary_lines.append(f"   â€¢ {stock_name}({stock_code}) {score:.1f}åˆ†")
            total_stocks += len(stocks)
    
    summary_lines.append(f"ğŸ“Š æ€»è®¡: {total_stocks}åªè‚¡ç¥¨ï¼ˆæ¯æ¿å—æœ€å¤š{MAX_STOCKS_PER_SECTION}åªï¼‰")
    summary_lines.append("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    
    # æ·»åŠ æ“ä½œæŒ‡å—
    summary_lines.append("ğŸ’¡ æ“ä½œæŒ‡å—:")
    summary_lines.append("1. YESä¿¡å·: å¯æŒä»“æˆ–å»ºä»“ï¼Œä¸¥æ ¼æ­¢æŸ")
    summary_lines.append("2. NOä¿¡å·: å‡ä»“æˆ–è§‚æœ›ï¼Œé¿å…ç›²ç›®æŠ„åº•")
    summary_lines.append("3. éœ‡è¡å¸‚: é«˜æŠ›ä½å¸ï¼Œæ§åˆ¶æ€»ä»“ä½â‰¤40%")
    summary_lines.append("4. å•ä¸€ä¸ªè‚¡ä»“ä½â‰¤15%ï¼Œåˆ†æ•£æŠ•èµ„5-8åª")
    summary_lines.append("5. ç§‘åˆ›æ¿/åˆ›ä¸šæ¿: ä»“ä½å’Œæ­¢æŸå¹…åº¦é€‚å½“æ”¾å®½")
    summary_lines.append("â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    summary_lines.append("ğŸ“Š æ•°æ®æ¥æº: fish-etf (https://github.com/karmyshunde-sudo/fish-etf )")
    
    summary_message = "\n".join(summary_lines)
    return summary_message

def main():
    """ä¸»å‡½æ•°"""
    try:
        logger.info("===== å¼€å§‹æ‰§è¡Œä¸ªè‚¡è¶‹åŠ¿ç­–ç•¥(TickTen) =====")
        
        # 1. è·å–é€‚åˆç­–ç•¥çš„è‚¡ç¥¨
        top_stocks_by_section = get_top_stocks_for_strategy()
        
        # 2. ç”Ÿæˆç­–ç•¥æ€»ç»“æ¶ˆæ¯
        summary_message = generate_strategy_summary(top_stocks_by_section)
        
        # 3. æ¨é€å…¨å¸‚åœºç­–ç•¥æ€»ç»“æ¶ˆæ¯
        logger.info("æ¨é€å…¨å¸‚åœºç­–ç•¥æ€»ç»“æ¶ˆæ¯")
        send_wechat_message(summary_message, message_type="stock_tickten")
        
        logger.info("ä¸ªè‚¡ç­–ç•¥æŠ¥å‘Šå·²æˆåŠŸå‘é€è‡³ä¼ä¸šå¾®ä¿¡")
        logger.info("===== ä¸ªè‚¡è¶‹åŠ¿ç­–ç•¥(TickTen)æ‰§è¡Œå®Œæˆ =====")
    
    except Exception as e:
        error_msg = f"ä¸ªè‚¡è¶‹åŠ¿ç­–ç•¥æ‰§è¡Œå¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        send_wechat_message(error_msg, message_type="error")

if __name__ == "__main__":
    main()
