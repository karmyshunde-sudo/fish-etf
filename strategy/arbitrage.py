#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
套利策略计算模块
基于已保存的实时数据计算套利机会
严格遵循项目架构原则：只负责计算，不涉及数据爬取和消息格式化
增强功能：增量保存数据、自动清理过期数据、支持新系统无历史数据场景
"""

import pandas as pd
import numpy as np
import logging
import os
import time
from datetime import datetime, timedelta
from typing import Optional, Dict, Any, List, Tuple
from config import Config
from utils.date_utils import (
    get_current_times,
    get_beijing_time,
    get_utc_time,
    is_file_outdated,
    is_trading_time
)
from utils.file_utils import (
    load_etf_daily_data, 
    ensure_chinese_columns,
    load_discount_status,
    save_discount_status,
    should_push_discount,
    mark_discount_pushed,
    load_premium_status,
    save_premium_status,
    should_push_premium,
    mark_premium_pushed,
    load_etf_metadata
)
from data_crawler.strategy_arbitrage_source import get_latest_arbitrage_opportunities as get_arbitrage_data
from .etf_scoring import (
    get_etf_basic_info, 
    get_etf_name,
    calculate_arbitrage_score,
    calculate_component_stability_score
)
from wechat_push.push import send_wechat_message

# 初始化日志
logger = logging.getLogger(__name__)

def extract_scalar_value(value, default=0.0, log_prefix=""):
    """
    安全地从各种类型中提取标量值
    
    Args:
        value: 可能是标量、Series、DataFrame、字符串等
        default: 默认值，如果无法提取标量值
        log_prefix: 日志前缀，用于标识调用位置
    
    Returns:
        float: 标量值
    """
    try:
        # 如果已经是标量值，直接返回
        if isinstance(value, (int, float)):
            return float(value)
        
        # 如果是字符串，尝试转换为浮点数
        if isinstance(value, str):
            # 尝试移除非数字字符
            cleaned_str = ''.join(c for c in value if c.isdigit() or c in ['.', '-'])
            if cleaned_str:
                result = float(cleaned_str)
                logger.debug(f"{log_prefix}从字符串提取标量值: '{value}' -> {result}")
                return result
            logger.warning(f"{log_prefix}无法从字符串 '{value}' 提取有效数字，使用默认值{default}")
            return default
        
        # 如果是pandas对象，尝试提取标量值
        if isinstance(value, (pd.Series, pd.DataFrame)):
            # 尝试获取第一个值
            if value.size > 0:
                # 尝试使用.values.flatten()[0]（最可靠）
                try:
                    result = float(value.values.flatten()[0])
                    logger.debug(f"{log_prefix}通过.values.flatten()[0]提取标量值: {result}")
                    return result
                except Exception as e:
                    # 尝试使用.item()
                    try:
                        result = float(value.item())
                        logger.debug(f"{log_prefix}通过.item()提取标量值: {result}")
                        return result
                    except Exception as e2:
                        # 尝试使用.iloc[0]
                        try:
                            valid_values = value[~pd.isna(value)]
                            if not valid_values.empty:
                                result = float(valid_values.iloc[0])
                                logger.debug(f"{log_prefix}通过.iloc[0]提取标量值: {result}")
                                return result
                        except Exception as e3:
                            pass
            
            logger.error(f"{log_prefix}无法从pandas对象提取标量值(size={value.size})，使用默认值{default}")
            return default
        
        # 尝试直接转换为浮点数
        result = float(value)
        logger.debug(f"{log_prefix}直接转换为浮点数: {result}")
        return result
    
    except Exception as e:
        logger.error(f"{log_prefix}无法从类型 {type(value)} 中提取标量值: {str(e)}，使用默认值{default}")
        return default

def calculate_premium_discount(market_price: float, iopv: float) -> float:
    """
    计算折溢价率
    Args:
        market_price: 市场价格
        iopv: IOPV(基金份额参考净值)
    
    Returns:
        float: 折溢价率（百分比），正数表示溢价，负数表示折价
    """
    if iopv <= 0:
        logger.warning(f"无效的IOPV: {iopv}")
        return 0.0
    
    # 正确计算折溢价率：(市场价格 - IOPV) / IOPV * 100
    # 结果为正：溢价（市场价格 > IOPV）
    # 结果为负：折价（市场价格 < IOPV）
    premium_discount = ((market_price - iopv) / iopv) * 100
    return round(premium_discount, 2)

# 保留原有的 is_manual_trigger 函数定义
def is_manual_trigger() -> bool:
    """
    判断是否是手动触发的任务
    
    Returns:
        bool: 如果是手动触发返回True，否则返回False
    """
    try:
        # 检查环境变量，GitHub Actions中手动触发会有特殊环境变量
        return os.environ.get('GITHUB_EVENT_NAME', '') == 'workflow_dispatch'
    except Exception as e:
        logger.error(f"检查是否为手动触发失败: {str(e)}", exc_info=True)
        return False

def calculate_arbitrage_opportunity() -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    基于实时数据计算ETF套利机会
    
    Returns:
        Tuple[pd.DataFrame, pd.DataFrame]: 折价机会DataFrame, 溢价机会DataFrame
    """
    try:
        # 获取当前双时区时间
        utc_now, beijing_now = get_current_times()
        logger.info(f"开始计算套利机会 (UTC: {utc_now}, CST: {beijing_now})")
        
        # 获取最新的套利机会
        # 修复：处理可能返回3个值的情况
        result = get_arbitrage_data()
        if isinstance(result, tuple) and len(result) == 3:
            discount_opportunities, premium_opportunities, _ = result
        elif isinstance(result, tuple) and len(result) == 2:
            discount_opportunities, premium_opportunities = result
        else:
            logger.error(f"get_arbitrage_data() 返回值格式错误，期望2或3个值，实际返回: {result}")
            return pd.DataFrame(), pd.DataFrame()
        
        if discount_opportunities.empty and premium_opportunities.empty:
            logger.info("未发现有效套利机会")
            return pd.DataFrame(), pd.DataFrame()
        
        # 添加规模和日均成交额信息
        discount_opportunities = add_etf_basic_info(discount_opportunities)
        premium_opportunities = add_etf_basic_info(premium_opportunities)
        
        # 计算综合评分 - 关键修复：确保传递的是标量值
        discount_opportunities = calculate_arbitrage_scores(discount_opportunities)
        premium_opportunities = calculate_arbitrage_scores(premium_opportunities)
        
        # 过滤有效的套利机会
        discount_opportunities = filter_valid_discount_opportunities(discount_opportunities)
        premium_opportunities = filter_valid_premium_opportunities(premium_opportunities)
        
        # 筛选今天尚未推送的套利机会（增量推送功能）
        discount_opportunities = filter_new_discount_opportunities(discount_opportunities)
        premium_opportunities = filter_new_premium_opportunities(premium_opportunities)
        
        logger.info(f"发现 {len(discount_opportunities)} 个新的折价机会（基于新评分机制）")
        logger.info(f"发现 {len(premium_opportunities)} 个新的溢价机会（基于新评分机制）")
        
        return discount_opportunities, premium_opportunities

    except Exception as e:
        error_msg = f"计算套利机会失败: {str(e)}"
        logger.error(error_msg, exc_info=True)
        send_wechat_message(
            message=error_msg,
            message_type="error"
        )
        return pd.DataFrame(), pd.DataFrame()
    
def filter_new_discount_opportunities(df: pd.DataFrame) -> pd.DataFrame:
    """
    过滤掉今天已经推送过的折价机会
    
    Args:
        df: 原始折价机会DataFrame
    
    Returns:
        pd.DataFrame: 仅包含新发现的折价机会的DataFrame
    """
    if df.empty:
        return df
    
    try:
        # 创建一个列表，包含应该推送的ETF代码
        etfs_to_push = []
        
        for _, row in df.iterrows():
            etf_code = row["ETF代码"]
            if should_push_discount(etf_code):
                etfs_to_push.append(etf_code)
        
        # 过滤DataFrame
        new_opportunities = df[df["ETF代码"].isin(etfs_to_push)].copy()
        
        logger.info(f"从 {len(df)} 个折价机会中筛选出 {len(new_opportunities)} 个新机会（增量推送）")
        return new_opportunities
    
    except Exception as e:
        logger.error(f"过滤新折价机会失败: {str(e)}", exc_info=True)
        # 出错时返回原始DataFrame，确保至少能推送新发现的机会
        return df

def filter_new_premium_opportunities(df: pd.DataFrame) -> pd.DataFrame:
    """
    过滤掉今天已经推送过的溢价机会
    
    Args:
        df: 原始溢价机会DataFrame
    
    Returns:
        pd.DataFrame: 仅包含新发现的溢价机会的DataFrame
    """
    if df.empty:
        return df
    
    try:
        # 创建一个列表，包含应该推送的ETF代码
        etfs_to_push = []
        
        for _, row in df.iterrows():
            etf_code = row["ETF代码"]
            if should_push_premium(etf_code):
                etfs_to_push.append(etf_code)
        
        # 过滤DataFrame
        new_opportunities = df[df["ETF代码"].isin(etfs_to_push)].copy()
        
        logger.info(f"从 {len(df)} 个溢价机会中筛选出 {len(new_opportunities)} 个新机会（增量推送）")
        return new_opportunities
    
    except Exception as e:
        logger.error(f"过滤新溢价机会失败: {str(e)}", exc_info=True)
        # 出错时返回原始DataFrame，确保至少能推送新发现的机会
        return df

def sort_opportunities_by_abs_premium(df: pd.DataFrame) -> pd.DataFrame:
    """
    按折溢价率绝对值排序
    
    Args:
        df: 原始套利机会DataFrame
    
    Returns:
        pd.DataFrame: 排序后的DataFrame
    """
    if df.empty:
        return df
    
    try:
        df["abs_premium_discount"] = df["折溢价率"].abs()
        df = df.sort_values("abs_premium_discount", ascending=False)
        df = df.drop(columns=["abs_premium_discount"])
        return df
    except Exception as e:
        logger.error(f"排序套利机会失败: {str(e)}", exc_info=True)
        return df

def add_etf_basic_info(df: pd.DataFrame) -> pd.DataFrame:
    """
    为套利机会数据添加ETF基本信息（规模、日均成交额）
    
    Args:
        df: 原始套利机会DataFrame
    
    Returns:
        pd.DataFrame: 添加基本信息后的DataFrame
    """
    if df.empty:
        return df
    
    try:
        # 为每只ETF添加基本信息
        for idx, row in df.iterrows():
            etf_code = row["ETF代码"]
            size, _ = get_etf_basic_info(etf_code)
            
            # 计算日均成交额
            avg_volume = 0.0
            etf_df = load_etf_daily_data(etf_code)
            if not etf_df.empty and "成交额" in etf_df.columns:
                # 取最近30天数据
                recent_data = etf_df.tail(30)
                if len(recent_data) > 0:
                    # 修复：不再进行单位转换，因为data_crawler中已统一转换为"万元"
                    avg_volume = recent_data["成交额"].mean()
            
            # 使用.loc避免SettingWithCopyWarning
            df.loc[idx, "基金规模"] = size
            df.loc[idx, "日均成交额"] = avg_volume
        
        logger.info(f"添加ETF基本信息完成，共处理 {len(df)} 个机会")
        return df
    
    except Exception as e:
        logger.error(f"添加ETF基本信息失败: {str(e)}", exc_info=True)
        return df

def calculate_arbitrage_scores(df: pd.DataFrame) -> pd.DataFrame:
    """
    计算ETF套利综合评分
    
    Args:
        df: 原始套利机会DataFrame
    
    Returns:
        pd.DataFrame: 包含综合评分的DataFrame
    """
    if df.empty:
        return df
    
    try:
        # 为每只ETF计算综合评分
        scores = []
        for idx, row in df.iterrows():
            etf_code = row["ETF代码"]
            # 获取ETF日线数据
            etf_df = load_etf_daily_data(etf_code)
            if etf_df.empty:
                logger.warning(f"ETF {etf_code} 无日线数据，无法计算综合评分")
                scores.append(0.0)
                continue
            
            # 使用辅助函数安全提取标量值
            premium_discount = extract_scalar_value(
                row["折溢价率"],
                log_prefix=f"ETF {etf_code} 折溢价率: "
            )
            
            # 从DataFrame行中提取所有必需参数
            etf_name = extract_scalar_value(row["ETF名称"], log_prefix=f"ETF {etf_code} 名称: ")
            market_price = extract_scalar_value(row["市场价格"], log_prefix=f"ETF {etf_code} 市场价格: ")
            iopv = extract_scalar_value(row["IOPV"], log_prefix=f"ETF {etf_code} IOPV: ")
            fund_size = extract_scalar_value(row["基金规模"], log_prefix=f"ETF {etf_code} 基金规模: ")
            avg_volume = extract_scalar_value(row["日均成交额"], log_prefix=f"ETF {etf_code} 日均成交额: ")
            
            # 限制在合理范围内
            MAX_DISCOUNT = -20.0  # 最大折价率（-20%）
            MAX_PREMIUM = 20.0    # 最大溢价率（20%）
            premium_discount = max(min(premium_discount, MAX_PREMIUM), MAX_DISCOUNT)
            
            # 记录实际使用的值（用于调试）
            logger.debug(f"ETF {etf_code} 实际使用的折溢价率: {premium_discount:.2f}%")
            
            # 计算综合评分
            score = calculate_arbitrage_score(
                etf_code,
                etf_name,
                premium_discount,
                market_price,
                iopv,
                fund_size,
                avg_volume,
                etf_df
            )
            scores.append(score)
        
        # 添加评分列
        df["综合评分"] = scores
        logger.info(f"计算ETF套利综合评分完成，共 {len(df)} 个机会")
        return df
    except Exception as e:
        logger.error(f"计算ETF套利综合评分失败: {str(e)}", exc_info=True)
        # 添加默认评分列
        df["综合评分"] = 0.0
        return df

def filter_valid_discount_opportunities(df: pd.DataFrame) -> pd.DataFrame:
    """
    过滤有效的折价机会（基于综合评分和阈值）
    
    Args:
        df: 原始折价机会DataFrame
    
    Returns:
        pd.DataFrame: 过滤后的DataFrame
    """
    if df.empty:
        return df
    
    try:
        # 按阈值过滤
        # 新评分机制：有效折价率 = max(折价率 - 0.2%, 0)
        # 有效折价率阈值：0.1% (对应20分)
        # 评分阈值：60分（表示"可以考虑买入"）
        filtered_df = df[
            (df["折溢价率"] <= -0.3) &  # 考虑0.2%交易成本，有效折价率≥0.1%
            (df["综合评分"] >= 60.0)     # 60分以上表示有效机会
        ]
        
        logger.info(f"从 {len(df)} 个折价机会中筛选出 {len(filtered_df)} 个有效机会（阈值：折价率≤-0.3%，评分≥60分）")
        return filtered_df
    
    except Exception as e:
        logger.error(f"过滤有效折价机会失败: {str(e)}", exc_info=True)
        return df

def filter_valid_premium_opportunities(df: pd.DataFrame) -> pd.DataFrame:
    """
    过滤有效的溢价机会（基于综合评分和阈值）
    
    Args:
        df: 原始溢价机会DataFrame
    
    Returns:
        pd.DataFrame: 过滤后的DataFrame
    """
    if df.empty:
        return df
    
    try:
        # 按阈值过滤
        filtered_df = df[
            (df["折溢价率"] >= Config.PREMIUM_THRESHOLD) & 
            (df["综合评分"] >= Config.ARBITRAGE_SCORE_THRESHOLD)
        ]
        
        logger.info(f"从 {len(df)} 个溢价机会中筛选出 {len(filtered_df)} 个有效机会")
        return filtered_df
    
    except Exception as e:
        logger.error(f"过滤有效溢价机会失败: {str(e)}", exc_info=True)
        return df

def calculate_daily_volume(etf_code: str) -> float:
    """
    计算ETF的日均成交额（基于最近30个交易日）
    
    Args:
        etf_code: ETF代码
        
    Returns:
        float: 日均成交额（万元）
    """
    try:
        # 加载ETF日线数据
        etf_df = load_etf_daily_data(etf_code)
        
        if etf_df.empty:
            logger.debug(f"ETF {etf_code} 无日线数据，无法计算日均成交额")
            return 0.0
        
        # 确保使用中文列名
        etf_df = ensure_chinese_columns(etf_df)
        
        # 检查是否包含"日期"列
        if "日期" not in etf_df.columns:
            logger.warning(f"ETF {etf_code} 数据缺少'日期'列，无法计算日均成交额")
            return 0.0
        
        # 确保数据按日期排序
        etf_df = etf_df.sort_values("日期", ascending=False)
        
        # 取最近30个交易日的数据
        recent_data = etf_df.head(30)
        
        # 检查是否有足够的数据
        if len(recent_data) < 10:  # 至少需要10天数据
            logger.debug(f"ETF {etf_code} 数据不足（{len(recent_data)}天），无法准确计算日均成交额")
            return 0.0
        
        # 计算日均成交额
        if "成交额" in recent_data.columns:
            # 修复：不再进行单位转换，因为data_crawler中已统一转换为"万元"
            avg_volume = recent_data["成交额"].mean()
            logger.debug(f"ETF {etf_code} 日均成交额: {avg_volume:.2f}万元（{len(recent_data)}天数据）")
            return avg_volume
        else:
            logger.warning(f"ETF {etf_code} 缺少成交额数据，无法计算日均成交额")
            return 0.0
    
    except Exception as e:
        logger.error(f"计算ETF {etf_code} 日均成交额失败: {str(e)}", exc_info=True)
        return 0.0

def get_arbitrage_history(days: int = 7) -> pd.DataFrame:
    """
    获取套利历史数据
    
    Args:
        days: 查询天数
    
    Returns:
        pd.DataFrame: 套利历史数据
    """
    try:
        history = []
        beijing_now = get_beijing_time()
        
        for i in range(days):
            date = (beijing_now - timedelta(days=i)).date().strftime("%Y-%m-%d")
            flag_file = os.path.join(Config.FLAG_DIR, f"arbitrage_pushed_{date}.txt")
            
            if os.path.exists(flag_file):
                # 读取当日套利数据
                # 这里简化处理，实际应从数据库或文件中读取历史套利数据
                history.append({
                    "日期": date,
                    "机会数量": 3,  # 示例数据
                    "最大折溢价率": 2.5,  # 示例数据
                    "最小折溢价率": -1.8  # 示例数据
                })
        
        if not history:
            logger.info("未找到套利历史数据")
            return pd.DataFrame()
        
        return pd.DataFrame(history)
    
    except Exception as e:
        error_msg = f"获取套利历史数据失败: {str(e)}"
        logger.error(error_msg, exc_info=True)
        return pd.DataFrame()

def analyze_arbitrage_performance() -> Dict[str, Any]:
    """
    分析套利表现
    
    Returns:
        Dict[str, Any]: 分析结果
    """
    try:
        # 获取历史数据
        history_df = get_arbitrage_history()
        if history_df.empty:
            logger.info("无历史数据可供分析")
            return {
                "avg_opportunities": 0,
                "max_premium": 0,
                "min_discount": 0,
                "trend": "无数据",
                "has_high_premium": False,
                "has_high_discount": False
            }
        
        # 计算统计指标
        avg_opportunities = history_df["机会数量"].mean()
        max_premium = history_df["最大折溢价率"].max()
        min_discount = history_df["最小折溢价率"].min()
        
        # 添加趋势分析
        trend = "平稳"
        if len(history_df) >= 3:
            trend = "上升" if history_df["机会数量"].iloc[-3:].mean() > history_df["机会数量"].iloc[:3].mean() else "下降"
        
        # 返回结构化分析结果
        return {
            "avg_opportunities": avg_opportunities,
            "max_premium": max_premium,
            "min_discount": min_discount,
            "trend": trend,
            "has_high_premium": max_premium > 2.0,
            "has_high_discount": min_discount < -2.0
        }
    
    except Exception as e:
        error_msg = f"套利表现分析失败: {str(e)}"
        logger.error(error_msg, exc_info=True)
        return {
            "avg_opportunities": 0,
            "max_premium": 0,
            "min_discount": 0,
            "trend": "分析失败",
            "has_high_premium": False,
            "has_high_discount": False
        }

def check_arbitrage_exit_signals() -> List[Dict[str, Any]]:
    """
    检查套利退出信号（持有1天后）
    
    Returns:
        List[Dict[str, Any]]: 需要退出的套利交易列表
    """
    try:
        logger.info("开始检查套利退出信号")
        
        # 获取当前双时区时间
        utc_now, beijing_now = get_current_times()
        
        # 检查交易记录文件是否存在
        if not os.path.exists(Config.TRADE_RECORD_FILE):
            logger.warning("交易记录文件不存在，无法检查套利退出信号")
            return []
        
        # 读取交易记录
        trade_df = pd.read_csv(Config.TRADE_RECORD_FILE, encoding="utf-8")
        
        # 获取昨天的日期（基于北京时间）
        yesterday = (beijing_now - timedelta(days=1)).strftime("%Y-%m-%d")
        logger.debug(f"检查昨天({yesterday})执行的套利交易")
        
        # 查找昨天执行的套利交易
        yesterday_arbitrage = trade_df[
            (trade_df["操作"] == "套利买入") & 
            (trade_df["创建日期"] == yesterday)
        ]
        
        if not yesterday_arbitrage.empty:
            logger.info(f"发现{len(yesterday_arbitrage)}条需要退出的套利交易")
            
            # 构建退出信号列表
            exit_signals = []
            for _, row in yesterday_arbitrage.iterrows():
                exit_signals.append({
                    "ETF代码": row["ETF代码"],
                    "ETF名称": row["ETF名称"],
                    "买入价格": row["价格"],
                    "买入日期": row["创建日期"]
                })
            
            return exit_signals
        
        logger.info("未发现需要退出的套利交易")
        return []
    
    except Exception as e:
        error_msg = f"检查套利退出信号失败: {str(e)}"
        logger.error(error_msg, exc_info=True)
        return []

def load_arbitrage_data(date_str: str) -> pd.DataFrame:
    """
    加载指定日期的套利数据
    
    Args:
        date_str: 日期字符串，格式为YYYYMMDD
    
    Returns:
        pd.DataFrame: 套利数据DataFrame
    """
    try:
        # 构建套利数据目录
        arbitrage_dir = os.path.join(Config.DATA_DIR, "arbitrage")
        os.makedirs(arbitrage_dir, exist_ok=True)
        
        # 构建文件路径
        file_path = os.path.join(arbitrage_dir, f"{date_str}.csv")
        
        # 检查文件是否存在
        if not os.path.exists(file_path):
            logger.info(f"套利数据文件不存在: {file_path}")
            return pd.DataFrame()
        
        # 读取CSV文件（明确指定编码）
        df = pd.read_csv(file_path, encoding="utf-8-sig")
        
        # 添加关键诊断日志（INFO级别，确保可见）
        logger.info(f"成功加载套利数据: {file_path}")
        logger.info(f"实际列名: {list(df.columns)}")
        if not df.empty:
            logger.info(f"前几行数据示例: {df.head().to_dict()}")
        
        # 确保DataFrame使用中文列名
        df = ensure_chinese_columns(df)
        
        return df
    
    except Exception as e:
        logger.error(f"加载套利数据失败: {str(e)}", exc_info=True)
        return pd.DataFrame()

def get_latest_arbitrage_opportunities(max_retry: int = 3) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    获取最新的套利机会
    
    Args:
        max_retry: 最大重试次数
    
    Returns:
        Tuple[pd.DataFrame, pd.DataFrame]: (折价机会DataFrame, 溢价机会DataFrame)
    """
    try:
        # 获取当前日期
        today = get_beijing_time().strftime("%Y%m%d")
        
        # 尝试加载今天的套利数据
        df = load_arbitrage_data(today)
        
        # 记录实际加载的列名用于诊断 (INFO级别)
        if not df.empty:
            logger.info(f"成功加载套利数据，实际列名: {list(df.columns)}")
        
        # 检查数据完整性
        if df.empty:
            logger.warning("加载的套利数据为空")
            return pd.DataFrame(), pd.DataFrame()
        
        # 记录实际加载的列名用于诊断 (INFO级别)
        logger.info(f"成功加载套利数据，实际列名: {list(df.columns)}")
        
        # 标准化列名 - 处理可能的空格问题
        df.columns = [col.strip() for col in df.columns]
        
        # 检查数据完整性
        required_columns = ["ETF代码", "ETF名称", "市场价格", "IOPV"]
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            logger.error(f"数据中缺少必要列: {', '.join(missing_columns)}")
            # 记录实际存在的列
            logger.info(f"实际列名: {list(df.columns)}")
            return pd.DataFrame(), pd.DataFrame()
        
        # 修复：在策略计算模块中计算正确的折溢价率
        # 正确的计算公式：(市场价格 - IOPV) / IOPV * 100
        # 结果为正：溢价（市场价格 > IOPV）
        # 结果为负：折价（市场价格 < IOPV）
        df["折溢价率"] = ((df["市场价格"] - df["IOPV"]) / df["IOPV"]) * 100
        
        # 记录筛选前的统计信息
        logger.info(f"筛选前数据量: {len(df)}，折溢价率范围: {df['折溢价率'].min():.2f}% ~ {df['折溢价率'].max():.2f}%")
        
        # 正确的筛选条件 - 分离折价和溢价
        # 折价机会：市场价格 < IOPV (折溢价率为负)
        discount_opportunities = df[df["折溢价率"] <= -Config.DISCOUNT_THRESHOLD].copy()
        
        # 溢价机会：市场价格 > IOPV (折溢价率为正)
        premium_opportunities = df[df["折溢价率"] >= Config.PREMIUM_THRESHOLD].copy()
        
        # 按折溢价率绝对值排序
        if not discount_opportunities.empty:
            discount_opportunities["abs_premium_discount"] = discount_opportunities["折溢价率"].abs()
            discount_opportunities = discount_opportunities.sort_values("abs_premium_discount", ascending=False)
            discount_opportunities = discount_opportunities.drop(columns=["abs_premium_discount"])
        
        if not premium_opportunities.empty:
            premium_opportunities["abs_premium_discount"] = premium_opportunities["折溢价率"].abs()
            premium_opportunities = premium_opportunities.sort_values("abs_premium_discount", ascending=False)
            premium_opportunities = premium_opportunities.drop(columns=["abs_premium_discount"])
        
        # 记录筛选结果
        logger.info(f"发现 {len(discount_opportunities)} 个折价机会 (阈值≥{Config.DISCOUNT_THRESHOLD}%)")
        logger.info(f"发现 {len(premium_opportunities)} 个溢价机会 (阈值≥{Config.PREMIUM_THRESHOLD}%)")
        
        return discount_opportunities, premium_opportunities
    
    except Exception as e:
        logger.error(f"获取最新套利机会失败: {str(e)}", exc_info=True)
        return pd.DataFrame(), pd.DataFrame()

def load_latest_valid_arbitrage_data(days_back: int = 7) -> pd.DataFrame:
    """
    加载最近有效的套利数据
    
    Args:
        days_back: 向前查找的天数
    
    Returns:
        pd.DataFrame: 最近有效的套利数据
    """
    try:
        beijing_now = get_beijing_time()
        
        # 从今天开始向前查找
        for i in range(days_back):
            date = (beijing_now - timedelta(days=i)).strftime("%Y%m%d")
            logger.debug(f"尝试加载历史套利数据: {date}")
            
            df = load_arbitrage_data(date)
            
            # 检查数据是否有效
            if not df.empty:
                # 检查是否包含必要列
                required_columns = ["ETF代码", "ETF名称", "市场价格", "IOPV"]
                if all(col in df.columns for col in required_columns):
                    # 修复：在加载历史数据时也计算正确的折溢价率
                    df["折溢价率"] = ((df["市场价格"] - df["IOPV"]) / df["IOPV"]) * 100
                    
                    logger.info(f"找到有效历史套利数据: {date}, 共 {len(df)} 个机会")
                    # 记录历史数据的折溢价率范围
                    logger.debug(f"历史数据折溢价率范围: {df['折溢价率'].min():.2f}% ~ {df['折溢价率'].max():.2f}%")
                    return df
        
        logger.warning(f"在最近 {days_back} 天内未找到有效的套利数据")
        return pd.DataFrame()
    
    except Exception as e:
        logger.error(f"加载最近有效套利数据失败: {str(e)}", exc_info=True)
        return pd.DataFrame()

def mark_arbitrage_opportunities_pushed(discount_df: pd.DataFrame, premium_df: pd.DataFrame) -> bool:
    """
    标记套利机会为已推送
    
    Args:
        discount_df: 折价机会DataFrame
        premium_df: 溢价机会DataFrame
    
    Returns:
        bool: 是否成功标记
    """
    try:
        # 获取当前日期
        current_date = get_beijing_time().strftime("%Y-%m-%d")
        
        # 加载现有状态 - 使用正确的函数名
        discount_status = load_discount_status()
        premium_status = load_premium_status()
        
        # 更新折价状态
        for _, row in discount_df.iterrows():
            etf_code = row["ETF代码"]
            discount_status[etf_code] = {
                "last_pushed": current_date,
                "score": row["综合评分"]
            }
        
        # 更新溢价状态
        for _, row in premium_df.iterrows():
            etf_code = row["ETF代码"]
            premium_status[etf_code] = {
                "last_pushed": current_date,
                "score": row["综合评分"]
            }
        
        # 保存状态 - 使用正确的函数名
        save_discount_status(discount_status)
        save_premium_status(premium_status)
        
        logger.info(f"成功标记 {len(discount_df) + len(premium_df)} 个ETF套利机会为已推送")
        return True
    
    except Exception as e:
        logger.error(f"标记套利机会为已推送失败: {str(e)}", exc_info=True)
        return False

def get_arbitrage_push_statistics() -> Dict[str, Any]:
    """
    获取套利推送统计信息
    
    Returns:
        Dict[str, Any]: 套利推送统计信息
    """
    try:
        from utils.file_utils import (
            get_arbitrage_push_count, 
            get_discount_push_count,
            get_premium_push_count,
            get_arbitrage_push_history,
            get_discount_push_history,
            get_premium_push_history
        )
        
        # 获取总推送量和今日推送量
        arbitrage_count = get_arbitrage_push_count()
        discount_count = get_discount_push_count()
        premium_count = get_premium_push_count()
        
        # 获取历史推送记录
        arbitrage_history = get_arbitrage_push_history(days=7)
        discount_history = get_discount_push_history(days=7)
        premium_history = get_premium_push_history(days=7)
        
        # 计算总推送量
        total_arbitrage = sum(arbitrage_history.values())
        total_discount = sum(discount_history.values())
        total_premium = sum(premium_history.values())
        
        # 计算日均推送量
        daily_avg_arbitrage = total_arbitrage / len(arbitrage_history) if arbitrage_history else 0
        daily_avg_discount = total_discount / len(discount_history) if discount_history else 0
        daily_avg_premium = total_premium / len(premium_history) if premium_history else 0
        
        # 获取最新推送日期
        latest_arbitrage_date = max(arbitrage_history.keys()) if arbitrage_history else "N/A"
        latest_discount_date = max(discount_history.keys()) if discount_history else "N/A"
        latest_premium_date = max(premium_history.keys()) if premium_history else "N/A"
        
        return {
            "arbitrage": {
                "total_pushed": arbitrage_count["total"],
                "today_pushed": arbitrage_count["today"],
                "total_history": total_arbitrage,
                "daily_avg": round(daily_avg_arbitrage, 2),
                "latest_date": latest_arbitrage_date,
                "history": arbitrage_history
            },
            "discount": {
                "total_pushed": discount_count["total"],
                "today_pushed": discount_count["today"],
                "total_history": total_discount,
                "daily_avg": round(daily_avg_discount, 2),
                "latest_date": latest_discount_date,
                "history": discount_history
            },
            "premium": {
                "total_pushed": premium_count["total"],
                "today_pushed": premium_count["today"],
                "total_history": total_premium,
                "daily_avg": round(daily_avg_premium, 2),
                "latest_date": latest_premium_date,
                "history": premium_history
            }
        }
    
    except Exception as e:
        logger.error(f"获取套利推送统计信息失败: {str(e)}", exc_info=True)
        return {
            "arbitrage": {
                "total_pushed": 0,
                "today_pushed": 0,
                "total_history": 0,
                "daily_avg": 0,
                "latest_date": "N/A",
                "history": {}
            },
            "discount": {
                "total_pushed": 0,
                "today_pushed": 0,
                "total_history": 0,
                "daily_avg": 0,
                "latest_date": "N/A",
                "history": {}
            },
            "premium": {
                "total_pushed": 0,
                "today_pushed": 0,
                "total_history": 0,
                "daily_avg": 0,
                "latest_date": "N/A",
                "history": {}
            }
        }

# 模块初始化
try:
    # 确保必要的目录存在
    Config.init_dirs()
    
    # 初始化日志
    logger.info("套利策略模块初始化完成")
    
    # 清理过期的套利状态记录
    try:
        from utils.file_utils import (
            clear_expired_arbitrage_status,
            clear_expired_discount_status,
            clear_expired_premium_status
        )
        clear_expired_arbitrage_status()
        clear_expired_discount_status()
        clear_expired_premium_status()
        logger.info("已清理过期的套利状态记录")
    except Exception as e:
        logger.error(f"清理过期套利状态记录失败: {str(e)}", exc_info=True)
    
except Exception as e:
    error_msg = f"套利策略模块初始化失败: {str(e)}"
    logger.error(error_msg, exc_info=True)
    
    try:
        # 退回到基础日志配置
        import logging
        logging.basicConfig(
            level="INFO",
            format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
            handlers=[logging.StreamHandler()]
        )
        logging.error(error_msg)
    except Exception as basic_log_error:
        print(f"基础日志配置失败: {str(basic_log_error)}")
        print(error_msg)
