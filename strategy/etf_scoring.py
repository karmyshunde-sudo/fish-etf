#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ETFè¯„åˆ†ç³»ç»Ÿ
åŸºäºå¤šç»´åº¦æŒ‡æ ‡å¯¹ETFè¿›è¡Œç»¼åˆè¯„åˆ†
ç‰¹åˆ«ä¼˜åŒ–äº†æ¶ˆæ¯æ¨é€æ ¼å¼ï¼Œç¡®ä¿ä½¿ç”¨ç»Ÿä¸€çš„æ¶ˆæ¯æ¨¡æ¿
"""
import pandas as pd
import numpy as np
import logging
import os
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple, Union
from config import Config
from utils.date_utils import (
    get_current_times,
    get_beijing_time,
    get_utc_time,
    is_file_outdated
)
from utils.file_utils import load_etf_daily_data, load_etf_metadata
from data_crawler.etf_list_manager import load_all_etf_list, get_etf_name
from wechat_push.push import send_wechat_message

# åˆå§‹åŒ–æ—¥å¿—
logger = logging.getLogger(__name__)

# å¸¸é‡å®šä¹‰
DATE_COL = "æ—¥æœŸ" if "æ—¥æœŸ" in Config.STANDARD_COLUMNS else "date"
CLOSE_COL = "æ”¶ç›˜" if "æ”¶ç›˜" in Config.STANDARD_COLUMNS else "close"
AMOUNT_COL = "æˆäº¤é¢" if "æˆäº¤é¢" in Config.STANDARD_COLUMNS else "amount"
ETF_CODE_COL = "ETFä»£ç "
FUND_SIZE_COL = "åŸºé‡‘è§„æ¨¡"
LISTING_DATE_COL = "ä¸Šå¸‚æ—¥æœŸ"  # ç»Ÿä¸€ä½¿ç”¨"ä¸Šå¸‚æ—¥æœŸ"

def extract_scalar_value(value, default=0.0, log_prefix=""):
    """
    å®‰å…¨åœ°ä»å„ç§ç±»å‹ä¸­æå–æ ‡é‡å€¼
    
    Args:
        value: å¯èƒ½æ˜¯æ ‡é‡ã€Seriesã€DataFrameã€å­—ç¬¦ä¸²ç­‰
        default: é»˜è®¤å€¼ï¼Œå¦‚æœæ— æ³•æå–æ ‡é‡å€¼
        log_prefix: æ—¥å¿—å‰ç¼€ï¼Œç”¨äºæ ‡è¯†è°ƒç”¨ä½ç½®
    
    Returns:
        float: æ ‡é‡å€¼
    """
    try:
        # å¦‚æœå·²ç»æ˜¯æ ‡é‡å€¼ï¼Œç›´æ¥è¿”å›
        if isinstance(value, (int, float)):
            return float(value)
        
        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è½¬æ¢ä¸ºæµ®ç‚¹æ•°
        if isinstance(value, str):
            # å°è¯•ç§»é™¤éæ•°å­—å­—ç¬¦
            cleaned_str = ''.join(c for c in value if c.isdigit() or c in ['.', '-'])
            if cleaned_str:
                result = float(cleaned_str)
                logger.debug(f"{log_prefix}ä»å­—ç¬¦ä¸²æå–æ ‡é‡å€¼: '{value}' -> {result}")
                return result
            logger.warning(f"{log_prefix}æ— æ³•ä»å­—ç¬¦ä¸² '{value}' æå–æœ‰æ•ˆæ•°å­—ï¼Œä½¿ç”¨é»˜è®¤å€¼{default}")
            return default
        
        # å¦‚æœæ˜¯pandaså¯¹è±¡ï¼Œå°è¯•æå–æ ‡é‡å€¼
        if isinstance(value, (pd.Series, pd.DataFrame)):
            # å°è¯•è·å–ç¬¬ä¸€ä¸ªå€¼
            if value.size > 0:
                # å°è¯•ä½¿ç”¨.values.flatten()[0]ï¼ˆæœ€å¯é ï¼‰
                try:
                    result = float(value.values.flatten()[0])
                    logger.debug(f"{log_prefix}é€šè¿‡.values.flatten()[0]æå–æ ‡é‡å€¼: {result}")
                    return result
                except Exception as e:
                    # å°è¯•ä½¿ç”¨.item()
                    try:
                        result = float(value.item())
                        logger.debug(f"{log_prefix}é€šè¿‡.item()æå–æ ‡é‡å€¼: {result}")
                        return result
                    except Exception as e2:
                        # å°è¯•ä½¿ç”¨.iloc[0]
                        try:
                            valid_values = value[~pd.isna(value)]
                            if not valid_values.empty:
                                result = float(valid_values.iloc[0])
                                logger.debug(f"{log_prefix}é€šè¿‡.iloc[0]æå–æ ‡é‡å€¼: {result}")
                                return result
                        except Exception as e3:
                            pass
            
            logger.error(f"{log_prefix}æ— æ³•ä»pandaså¯¹è±¡æå–æ ‡é‡å€¼(size={value.size})ï¼Œä½¿ç”¨é»˜è®¤å€¼{default}")
            return default
        
        # å°è¯•ç›´æ¥è½¬æ¢ä¸ºæµ®ç‚¹æ•°
        result = float(value)
        logger.debug(f"{log_prefix}ç›´æ¥è½¬æ¢ä¸ºæµ®ç‚¹æ•°: {result}")
        return result
    
    except Exception as e:
        logger.error(f"{log_prefix}æ— æ³•ä»ç±»å‹ {type(value)} ä¸­æå–æ ‡é‡å€¼: {str(e)}ï¼Œä½¿ç”¨é»˜è®¤å€¼{default}")
        return default

def calculate_arbitrage_score(
    etf_code: str,
    etf_name: str,
    premium_discount: float,
    market_price: float,
    iopv: float,
    fund_size: float,
    avg_volume: float,
    historical_data: Optional[pd.DataFrame] = None
) -> float:
    """
    é’ˆå¯¹å°èµ„é‡‘ï¼ˆ2ä¸‡ï¼‰ä¼˜åŒ–çš„ETFæ¡æ¼è¯„åˆ†ç³»ç»Ÿï¼ˆ0-100åˆ†ï¼‰
    
    è¯„åˆ†æœºåˆ¶ï¼š
    1. åŸºç¡€ç­›é€‰ï¼ˆä¸æ»¡è¶³åˆ™ç›´æ¥0åˆ†ï¼‰ï¼š
       - ETFè§„æ¨¡ â‰¥ 5äº¿å…ƒï¼ˆé¿å…è¿·ä½ ETFé£é™©ï¼‰
       - æ—¥å‡æˆäº¤é¢ â‰¥ 100ä¸‡å…ƒï¼ˆå°èµ„é‡‘è¶³å¤ŸæµåŠ¨æ€§ï¼‰
    
    2. æœ‰æ•ˆæŠ˜ä»·ç‡è®¡ç®—ï¼š
       - æœ‰æ•ˆæŠ˜ä»·ç‡ = max(æŠ˜ä»·ç‡ - 0.35%, 0)
       - è€ƒè™‘å°èµ„é‡‘å®é™…äº¤æ˜“æˆæœ¬æ›´é«˜ï¼ˆä½£é‡‘+å°èŠ±ç¨+æ»‘ç‚¹ï¼‰
    
    3. è¯„åˆ†å…¬å¼ï¼š
       - å¾—åˆ† = min(100, æœ‰æ•ˆæŠ˜ä»·ç‡ Ã— 400)
       - 0.25%æœ‰æ•ˆæŠ˜ä»· = 100åˆ†ï¼ˆç†æƒ³æ¡æ¼æœºä¼šï¼‰
       - 0.1%æœ‰æ•ˆæŠ˜ä»· = 40åˆ†ï¼ˆä¸€èˆ¬æœºä¼šï¼‰
    
    4. é™„åŠ æ¡ä»¶ï¼ˆå¯é€‰ï¼Œæ ¹æ®é£é™©åå¥½ï¼‰ï¼š
       - è¿ç»­2å¤©æŠ˜ä»·ï¼šé¢å¤–+10åˆ†
       - æŠ˜ä»·å¹…åº¦å¤§äºè¡Œä¸šå¹³å‡ï¼šé¢å¤–+5åˆ†
    """
    try:
        # 1. åŸºç¡€ç­›é€‰
        if fund_size < 5.0:  # 5äº¿å…ƒè§„æ¨¡ä¸‹é™
            logger.debug(f"ETF {etf_code} è§„æ¨¡ {fund_size:.2f}äº¿å…ƒ < 5äº¿å…ƒï¼Œä¸æ»¡è¶³è§„æ¨¡è¦æ±‚")
            return 0.0
            
        if avg_volume < 100:  # 100ä¸‡å…ƒæ—¥å‡æˆäº¤é¢ï¼ˆé€‚åˆå°èµ„é‡‘ï¼‰
            logger.debug(f"ETF {etf_code} æ—¥å‡æˆäº¤é¢ {avg_volume:.2f}ä¸‡å…ƒ < 100ä¸‡å…ƒï¼Œä¸æ»¡è¶³æµåŠ¨æ€§è¦æ±‚")
            return 0.0
            
        # 2. æœ‰æ•ˆæŠ˜ä»·ç‡è®¡ç®—ï¼ˆå°èµ„é‡‘äº¤æ˜“æˆæœ¬æ›´é«˜ï¼‰
        TRANSACTION_COST = 0.35  # å°èµ„é‡‘å®é™…äº¤æ˜“æˆæœ¬çº¦0.35%
        effective_discount = 0.0
        
        # ä»…è®¡ç®—æŠ˜ä»·æƒ…å†µï¼ˆæº¢ä»·å¯¹æ¡æ¼æ— ä»·å€¼ï¼‰
        if premium_discount < 0:
            effective_discount = max(-premium_discount - TRANSACTION_COST, 0)
        
        # 3. è¯„åˆ†å…¬å¼
        score = min(100, effective_discount * 400)  # æ›´æ•æ„Ÿçš„è¯„åˆ†å°ºåº¦
        
        # 4. é™„åŠ æ¡ä»¶ï¼ˆå¦‚æœæä¾›äº†å†å²æ•°æ®ï¼‰
        if historical_data is not None and not historical_data.empty:
            # æ£€æŸ¥æ˜¯å¦è¿ç»­2å¤©æŠ˜ä»·
            if len(historical_data) >= 2:
                prev_premium = historical_data["æŠ˜æº¢ä»·ç‡"].iloc[-2]
                if prev_premium < 0 and premium_discount < 0:
                    score = min(100, score + 10)  # è¿ç»­æŠ˜ä»·åŠ åˆ†
            
            # æ£€æŸ¥æŠ˜ä»·å¹…åº¦æ˜¯å¦å¤§äºè¡Œä¸šå¹³å‡ï¼ˆç®€åŒ–å®ç°ï¼‰
            industry_avg = -0.15  # å‡è®¾è¡Œä¸šå¹³å‡æŠ˜ä»·ç‡ä¸º-0.15%
            if premium_discount < industry_avg:
                score = min(100, score + 5)
        
        # è®°å½•è¯„åˆ†è¯¦æƒ…
        logger.debug(f"ETF {etf_code} æ¡æ¼è¯„åˆ†è¯¦æƒ…: "
                     f"æŠ˜æº¢ä»·ç‡={premium_discount:.2f}%, "
                     f"æœ‰æ•ˆæŠ˜ä»·ç‡={effective_discount:.2f}%, "
                     f"è§„æ¨¡={fund_size:.2f}äº¿å…ƒ, "
                     f"æ—¥å‡æˆäº¤é¢={avg_volume:.2f}ä¸‡å…ƒ, "
                     f"æœ€ç»ˆè¯„åˆ†={score:.2f}")
        
        return score
    
    except Exception as e:
        logger.error(f"è®¡ç®—ETF {etf_code} æ¡æ¼è¯„åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        return 0.0

def calculate_component_stability_score(etf_code: str, df: pd.DataFrame) -> float:
    """
    è®¡ç®—æˆåˆ†è‚¡ç¨³å®šæ€§è¯„åˆ†
    
    Args:
        etf_code: ETFä»£ç 
        df: ETFæ—¥çº¿æ•°æ®
    
    Returns:
        float: æˆåˆ†è‚¡ç¨³å®šæ€§è¯„åˆ† (0-100)
    """
    try:
        if df is None or df.empty:
            logger.warning(f"ETF {etf_code} æ— æ—¥çº¿æ•°æ®ï¼Œæ— æ³•è®¡ç®—æˆåˆ†è‚¡ç¨³å®šæ€§è¯„åˆ†")
            return 70.0  # é»˜è®¤ä¸­ç­‰åé«˜è¯„åˆ†
        
        # åˆ›å»ºDataFrameçš„å‰¯æœ¬ï¼Œé¿å…SettingWithCopyWarning
        df = df.copy(deep=True)
        
        # è®¡ç®—æ³¢åŠ¨ç‡
        volatility = calculate_volatility(df)
        
        # æ³¢åŠ¨ç‡è¯„åˆ†ï¼ˆè¶Šä½è¶Šå¥½ï¼‰ï¼šæ³¢åŠ¨ç‡â‰¤0.1=100åˆ†ï¼Œ0.3=50åˆ†ï¼Œâ‰¥0.5=0åˆ†
        component_score = max(0, 100 - (volatility * 200))
        
        # è€ƒè™‘ETFè§„æ¨¡ï¼ˆè§„æ¨¡è¶Šå¤§ï¼Œæˆåˆ†è‚¡ç¨³å®šæ€§é€šå¸¸è¶Šé«˜ï¼‰
        size, _ = get_etf_basic_info(etf_code)
        size_score = min(max(size * 0.5, 0), 100)
        
        # ç»¼åˆè¯„åˆ†ï¼ˆæ³¢åŠ¨ç‡å 70%ï¼Œè§„æ¨¡å 30%ï¼‰
        total_score = component_score * 0.7 + size_score * 0.3
        
        logger.debug(f"ETF {etf_code} æˆåˆ†è‚¡ç¨³å®šæ€§è¯„åˆ†: {total_score:.2f} (æ³¢åŠ¨ç‡: {volatility:.4f}, è§„æ¨¡: {size}äº¿å…ƒ)")
        return total_score
    
    except Exception as e:
        logger.error(f"è®¡ç®—ETF {etf_code} æˆåˆ†è‚¡ç¨³å®šæ€§è¯„åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        return 70.0  # é»˜è®¤ä¸­ç­‰åé«˜è¯„åˆ†

def calculate_volatility(df: pd.DataFrame) -> float:
    """
    è®¡ç®—ETFä»·æ ¼æ³¢åŠ¨ç‡
    
    Args:
        df: ETFæ—¥çº¿æ•°æ®
    
    Returns:
        float: æ³¢åŠ¨ç‡
    """
    try:
        # ç¡®ä¿ä½¿ç”¨ä¸­æ–‡åˆ—å
        try:
            from utils.file_utils import ensure_chinese_columns
            df = ensure_chinese_columns(df)
        except ImportError:
            # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨å†…ç½®çš„åˆ—åæ˜ å°„
            logger.warning("æ— æ³•å¯¼å…¥ensure_chinese_columnsï¼Œå°è¯•ä½¿ç”¨å†…ç½®åˆ—åæ˜ å°„")
            # è¿™é‡Œå¯ä»¥æ·»åŠ å†…ç½®çš„åˆ—åæ˜ å°„é€»è¾‘
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…è¦åˆ—
        if "æ”¶ç›˜" not in df.columns and "close" not in df.columns:
            logger.error("ETFæ—¥çº¿æ•°æ®ç¼ºå°‘ä»·æ ¼åˆ—ï¼Œæ— æ³•è®¡ç®—æ³¢åŠ¨ç‡")
            return 0.5  # è¿”å›é»˜è®¤æ³¢åŠ¨ç‡
        
        # é€‰æ‹©åˆé€‚çš„ä»·æ ¼åˆ—
        price_col = "æ”¶ç›˜" if "æ”¶ç›˜" in df.columns else "close"
        logger.info(f"æ‰¾åˆ°ä»·æ ¼åˆ—: {price_col} (å¯ç”¨ä»·æ ¼åˆ—: {list(df.columns)})")
        
        # ç¡®ä¿ä»·æ ¼åˆ—æ˜¯æ•°å€¼ç±»å‹
        if not pd.api.types.is_numeric_dtype(df[price_col]):
            try:
                df[price_col] = pd.to_numeric(df[price_col], errors='coerce')
                df = df.dropna(subset=[price_col])
            except:
                logger.error(f"ä»·æ ¼åˆ— {price_col} æ— æ³•è½¬æ¢ä¸ºæ•°å€¼ç±»å‹")
                return 0.5
        
        # è®¡ç®—æ”¶ç›Šç‡
        df["daily_return"] = df[price_col].pct_change().dropna()
        
        # ç¡®ä¿æ”¶ç›Šç‡åˆ—æ˜¯æ•°å€¼ç±»å‹
        if not pd.api.types.is_numeric_dtype(df["daily_return"]):
            try:
                df["daily_return"] = pd.to_numeric(df["daily_return"], errors='coerce')
                df = df.dropna(subset=["daily_return"])
            except:
                logger.error("æ”¶ç›Šç‡åˆ—æ— æ³•è½¬æ¢ä¸ºæ•°å€¼ç±»å‹")
                return 0.5
        
        # è®¡ç®—æ³¢åŠ¨ç‡ï¼ˆå¹´åŒ–æ³¢åŠ¨ç‡ï¼‰
        if len(df["daily_return"]) < 2:
            logger.warning("æ”¶ç›Šç‡æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—æ³¢åŠ¨ç‡")
            return 0.5
        
        volatility = df["daily_return"].std() * np.sqrt(252)  # å¹´åŒ–æ³¢åŠ¨ç‡
        return volatility
    
    except Exception as e:
        logger.error(f"è®¡ç®—ETFæ³¢åŠ¨ç‡å¤±è´¥: {str(e)}", exc_info=True)
        return 0.5  # é»˜è®¤æ³¢åŠ¨ç‡

def calculate_etf_score(etf_code: str, df: pd.DataFrame) -> float:
    """
    è®¡ç®—ETFç»¼åˆè¯„åˆ†ï¼ˆ0-100åˆ†ï¼‰
    
    Args:
        etf_code: ETFä»£ç 
        df: ETFæ—¥çº¿æ•°æ®
    
    Returns:
        float: ETFç»¼åˆè¯„åˆ†
    """
    try:
        # è·å–å½“å‰åŒæ—¶åŒºæ—¶é—´
        _, beijing_now = get_current_times()
        
        # åˆ›å»ºDataFrameçš„å‰¯æœ¬ï¼Œé¿å…SettingWithCopyWarning
        if df is None or df.empty:
            logger.warning(f"ETF {etf_code} æ— æ—¥çº¿æ•°æ®ï¼Œè¯„åˆ†è®¾ä¸º0")
            return 0.0
        
        # åˆ›å»ºå®‰å…¨å‰¯æœ¬
        df = df.copy(deep=True)
        
        # ç¡®ä¿æ•°æ®æŒ‰æ—¥æœŸæ’åº
        if DATE_COL in df.columns:
            df = df.sort_values(DATE_COL)
        
        # æ£€æŸ¥ETFæ˜¯å¦ä¸ºæ–°ä¸Šå¸‚
        size, listing_date = get_etf_basic_info(etf_code)
        is_new_etf = False
        days_since_listing = 0
        
        if listing_date:
            try:
                # å¤„ç†ä¸åŒæ ¼å¼çš„æ—¥æœŸå­—ç¬¦ä¸²
                if isinstance(listing_date, str):
                    # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
                    date_formats = ["%Y-%m-%d", "%Y/%m/%d", "%Y%m%d"]
                    listing_date_obj = None
                    for fmt in date_formats:
                        try:
                            listing_date_obj = datetime.strptime(listing_date, fmt)
                            break
                        except:
                            continue
                    if listing_date_obj:
                        days_since_listing = (beijing_now - listing_date_obj).days
                        is_new_etf = days_since_listing < 90  # ä¸Šå¸‚90å¤©å†…è§†ä¸ºæ–°ETF
                elif isinstance(listing_date, datetime):
                    days_since_listing = (beijing_now - listing_date).days
                    is_new_etf = days_since_listing < 90
            except Exception as e:
                logger.error(f"ETF {etf_code} ä¸Šå¸‚æ—¥æœŸè§£æé”™è¯¯: {str(e)}")
        
        # æ£€æŸ¥æ•°æ®é‡
        min_required_data = 30  # é»˜è®¤éœ€è¦30å¤©æ•°æ®
        if len(df) < min_required_data:
            if len(df) < 10:
                logger.warning(f"ETF {etf_code} æ•°æ®é‡ä¸¥é‡ä¸è¶³({len(df)}å¤©)ï¼Œè¯„åˆ†è®¾ä¸º0")
                return 0.0
            else:
                logger.info(f"ETF {etf_code} æ•°æ®é‡ä¸è¶³({len(df)}å¤©)ï¼Œä½¿ç”¨ç°æœ‰æ•°æ®è®¡ç®—è¯„åˆ†")
                min_required_data = len(df)
        
        # å–æœ€è¿‘min_required_dataå¤©æ•°æ®
        recent_data = df.tail(min_required_data)
        
        # 1. æµåŠ¨æ€§å¾—åˆ†ï¼ˆæ—¥å‡æˆäº¤é¢ï¼‰
        liquidity_score = calculate_liquidity_score(recent_data)
        
        # 2. é£é™©æ§åˆ¶å¾—åˆ†
        risk_score = calculate_risk_score(recent_data)
        
        # 3. æ”¶ç›Šèƒ½åŠ›å¾—åˆ†
        return_score = calculate_return_score(recent_data)
        
        # 4. æƒ…ç»ªæŒ‡æ ‡å¾—åˆ†ï¼ˆæˆäº¤é‡å˜åŒ–ç‡ï¼‰
        sentiment_score = calculate_sentiment_score(recent_data)
        
        # 5. åŸºæœ¬é¢å¾—åˆ†ï¼ˆè§„æ¨¡ã€ä¸Šå¸‚æ—¶é—´ç­‰ï¼‰
        fundamental_score = calculate_fundamental_score(etf_code)
        
        # éªŒè¯æ‰€æœ‰å¾—åˆ†æ˜¯å¦åœ¨æœ‰æ•ˆèŒƒå›´å†… [0, 100]
        scores = {
            "liquidity": max(0, min(100, liquidity_score)),
            "risk": max(0, min(100, risk_score)),
            "return": max(0, min(100, return_score)),
            "sentiment": max(0, min(100, sentiment_score)),
            "fundamental": max(0, min(100, fundamental_score))
        }
        
        # è·å–æƒé‡
        weights = Config.SCORE_WEIGHTS.copy()
        
        # ç¡®ä¿æƒé‡å­—å…¸åŒ…å«æ‰€æœ‰å¿…è¦çš„é”®
        required_keys = ['liquidity', 'risk', 'return', 'sentiment', 'fundamental']
        for key in required_keys:
            if key not in weights:
                logger.warning(f"æƒé‡å­—å…¸ç¼ºå°‘å¿…è¦é”®: {key}, ä½¿ç”¨é»˜è®¤å€¼0.2")
                weights[key] = 0.2
        
        # ç¡®ä¿æƒé‡å’Œä¸º1
        total_weight = sum(weights.values())
        if abs(total_weight - 1.0) > 0.001:
            logger.warning(f"æƒé‡å’Œä¸ä¸º1 ({total_weight}), æ­£åœ¨å½’ä¸€åŒ–")
            for key in weights:
                weights[key] /= total_weight
        
        # è®¡ç®—ç»¼åˆè¯„åˆ†
        total_score = (
            scores["liquidity"] * weights['liquidity'] +
            scores["risk"] * weights['risk'] +
            scores["return"] * weights['return'] +
            scores["sentiment"] * weights['sentiment'] +
            scores["fundamental"] * weights['fundamental']
        )
        
        # åŒé‡éªŒè¯ï¼šç¡®ä¿æœ€ç»ˆè¯„åˆ†åœ¨0-100èŒƒå›´å†…
        total_score = max(0, min(100, total_score))
        
        # å¯¹æ–°ä¸Šå¸‚ETFåº”ç”¨æƒ©ç½šå› å­
        if is_new_etf and days_since_listing < 15:
            penalty_factor = 0.8 - (days_since_listing * 0.02)
            total_score = max(0, total_score * penalty_factor)
            logger.info(f"ETF {etf_code} ä¸ºæ–°ä¸Šå¸‚ETFï¼Œåº”ç”¨æƒ©ç½šå› å­ï¼Œæœ€ç»ˆè¯„åˆ†: {total_score:.2f}")
        
        logger.debug(f"ETF {etf_code} è¯„åˆ†è¯¦æƒ…: "
                     f"æµåŠ¨æ€§={scores['liquidity']:.2f}({weights['liquidity']*100:.0f}%), "
                     f"é£é™©={scores['risk']:.2f}({weights['risk']*100:.0f}%), "
                     f"æ”¶ç›Š={scores['return']:.2f}({weights['return']*100:.0f}%), "
                     f"æƒ…ç»ª={scores['sentiment']:.2f}({weights['sentiment']*100:.0f}%), "
                     f"åŸºæœ¬é¢={scores['fundamental']:.2f}({weights['fundamental']*100:.0f}%), "
                     f"ç»¼åˆ={total_score:.2f}")
        
        return round(total_score, 2)
    
    except Exception as e:
        error_msg = f"è®¡ç®—ETF {etf_code} è¯„åˆ†å¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        # å‘é€é”™è¯¯é€šçŸ¥
        send_wechat_message(
            message=error_msg,
            message_type="error"
        )
        return 0.0

def calculate_liquidity_score(df: pd.DataFrame) -> float:
    """
    è®¡ç®—æµåŠ¨æ€§å¾—åˆ†ï¼ˆæ—¥å‡æˆäº¤é¢ï¼‰
    
    Args:
        df: ETFæ—¥çº¿æ•°æ®
    
    Returns:
        float: æµåŠ¨æ€§å¾—åˆ†
    """
    try:
        if df is None or df.empty:
            logger.warning("ä¼ å…¥çš„DataFrameä¸ºç©ºï¼ŒæµåŠ¨æ€§å¾—åˆ†è®¾ä¸º0")
            return 0.0
        
        # åˆ›å»ºDataFrameçš„å‰¯æœ¬ï¼Œé¿å…SettingWithCopyWarning
        df = df.copy(deep=True)
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æˆäº¤é¢åˆ—
        if AMOUNT_COL not in df.columns:
            logger.warning(f"ETFæ—¥çº¿æ•°æ®ç¼ºå°‘{AMOUNT_COL}åˆ—ï¼Œæ— æ³•è®¡ç®—æµåŠ¨æ€§å¾—åˆ†")
            return 50.0
        
        # ç¡®ä¿æˆäº¤é¢åˆ—æ˜¯æ•°å€¼ç±»å‹
        if not pd.api.types.is_numeric_dtype(df[AMOUNT_COL]):
            try:
                df[AMOUNT_COL] = pd.to_numeric(df[AMOUNT_COL], errors="coerce").fillna(0)
            except Exception as e:
                logger.error(f"æˆäº¤é¢åˆ—è½¬æ¢å¤±è´¥: {str(e)}")
                return 50.0
        
        # è®¡ç®—æ—¥å‡æˆäº¤é¢ï¼ˆå•ä½ï¼šä¸‡å…ƒï¼‰
        avg_volume = df[AMOUNT_COL].mean() / 10000
        
        # æµåŠ¨æ€§è¯„åˆ†ï¼ˆå¯¹æ•°å°ºåº¦ï¼Œæ›´ç¬¦åˆå®é™…æ„Ÿå—ï¼‰
        # 1000ä¸‡å…ƒ=50åˆ†ï¼Œ5000ä¸‡å…ƒ=75åˆ†ï¼Œ10000ä¸‡å…ƒ=90åˆ†
        if avg_volume <= 1000:
            score = 30 + (avg_volume / 1000) * 20
        elif avg_volume <= 5000:
            score = 50 + ((avg_volume - 1000) / 4000) * 25
        elif avg_volume <= 10000:
            score = 75 + ((avg_volume - 5000) / 5000) * 15
        else:
            score = 90 + min((avg_volume - 10000) / 10000, 10)
        
        logger.debug(f"ETFæµåŠ¨æ€§è¯„åˆ†: {score:.2f} (æ—¥å‡æˆäº¤é¢: {avg_volume:.2f}ä¸‡å…ƒ)")
        return score
    
    except Exception as e:
        logger.error(f"è®¡ç®—æµåŠ¨æ€§å¾—åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        return 50.0

def calculate_risk_score(df: pd.DataFrame) -> float:
    """
    è®¡ç®—é£é™©è¯„åˆ†ï¼ˆ0-100åˆ†ï¼Œåˆ†æ•°è¶Šé«˜é£é™©è¶Šå¤§ï¼‰
    
    Args:
        df: ETFæ—¥çº¿æ•°æ®
    
    Returns:
        float: é£é™©è¯„åˆ†ï¼ˆ0-100åˆ†ï¼‰
    """
    try:
        # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®
        if len(df) < 30:
            logger.warning("ETFæ—¥çº¿æ•°æ®ä¸è¶³30å¤©ï¼Œæ— æ³•å‡†ç¡®è®¡ç®—é£é™©è¯„åˆ†")
            return 50.0  # è¿”å›ä¸­æ€§è¯„åˆ†
        
        # ç¡®ä¿ä½¿ç”¨ä¸­æ–‡åˆ—å
        try:
            from utils.file_utils import ensure_chinese_columns
            df = ensure_chinese_columns(df)
        except ImportError:
            # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨å†…ç½®çš„åˆ—åæ˜ å°„
            logger.warning("æ— æ³•å¯¼å…¥ensure_chinese_columnsï¼Œå°è¯•ä½¿ç”¨å†…ç½®åˆ—åæ˜ å°„")
            # è¿™é‡Œå¯ä»¥æ·»åŠ å†…ç½®çš„åˆ—åæ˜ å°„é€»è¾‘
            pass
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…è¦åˆ—
        if "æ”¶ç›˜" not in df.columns and "close" not in df.columns:
            logger.error("ETFæ—¥çº¿æ•°æ®ç¼ºå°‘ä»·æ ¼åˆ—ï¼Œæ— æ³•è®¡ç®—é£é™©è¯„åˆ†")
            return 50.0
        
        # é€‰æ‹©åˆé€‚çš„ä»·æ ¼åˆ—
        price_col = "æ”¶ç›˜" if "æ”¶ç›˜" in df.columns else "close"
        logger.info(f"æ‰¾åˆ°ä»·æ ¼åˆ—: {price_col} (å¯ç”¨ä»·æ ¼åˆ—: {list(df.columns)})")
        
        # ç¡®ä¿ä»·æ ¼åˆ—æ˜¯æ•°å€¼ç±»å‹
        if not pd.api.types.is_numeric_dtype(df[price_col]):
            try:
                df[price_col] = pd.to_numeric(df[price_col], errors='coerce')
                df = df.dropna(subset=[price_col])
            except:
                logger.error(f"ä»·æ ¼åˆ— {price_col} æ— æ³•è½¬æ¢ä¸ºæ•°å€¼ç±»å‹")
                return 50.0
        
        # è®¡ç®—æ”¶ç›Šç‡
        df["daily_return"] = df[price_col].pct_change().dropna()
        
        # ç¡®ä¿æ”¶ç›Šç‡åˆ—æ˜¯æ•°å€¼ç±»å‹
        if not pd.api.types.is_numeric_dtype(df["daily_return"]):
            try:
                df["daily_return"] = pd.to_numeric(df["daily_return"], errors='coerce')
                df = df.dropna(subset=["daily_return"])
            except:
                logger.error("æ”¶ç›Šç‡åˆ—æ— æ³•è½¬æ¢ä¸ºæ•°å€¼ç±»å‹")
                return 50.0
        
        # è®¡ç®—æ³¢åŠ¨ç‡ï¼ˆå¹´åŒ–æ³¢åŠ¨ç‡ï¼‰
        if len(df["daily_return"]) < 2:
            logger.warning("æ”¶ç›Šç‡æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—æ³¢åŠ¨ç‡")
            return 50.0
        
        volatility = df["daily_return"].std() * np.sqrt(252)  # å¹´åŒ–æ³¢åŠ¨ç‡
        
        # è®¡ç®—æŠ˜æº¢ä»·ç‡ç¨³å®šæ€§
        premium_discount_std = 0.5  # é»˜è®¤å€¼
        if "æŠ˜æº¢ä»·ç‡" in df.columns:
            # ç¡®ä¿æŠ˜æº¢ä»·ç‡åˆ—æ˜¯æ•°å€¼ç±»å‹
            if not pd.api.types.is_numeric_dtype(df["æŠ˜æº¢ä»·ç‡"]):
                try:
                    # ä½¿ç”¨è¾…åŠ©å‡½æ•°å®‰å…¨æå–æ ‡é‡å€¼
                    df["æŠ˜æº¢ä»·ç‡"] = df["æŠ˜æº¢ä»·ç‡"].apply(
                        lambda x: extract_scalar_value(x, log_prefix="æŠ˜æº¢ä»·ç‡: ")
                    )
                    df = df.dropna(subset=["æŠ˜æº¢ä»·ç‡"])
                except:
                    logger.warning("æŠ˜æº¢ä»·ç‡åˆ—æ— æ³•è½¬æ¢ä¸ºæ•°å€¼ç±»å‹")
            
            if not df["æŠ˜æº¢ä»·ç‡"].empty:
                premium_discount_std = df["æŠ˜æº¢ä»·ç‡"].std()
        
        # ç»¼åˆé£é™©æŒ‡æ ‡ï¼ˆæ ‡å‡†åŒ–åˆ°0-1ï¼‰
        risk_factor = (volatility * 0.6 + premium_discount_std * 0.4)
        
        # å°†é£é™©æŒ‡æ ‡è½¬æ¢ä¸º0-100åˆ†çš„è¯„åˆ†ï¼ˆåˆ†æ•°è¶Šé«˜é£é™©è¶Šå¤§ï¼‰
        # ä½¿ç”¨Så‹æ›²çº¿ï¼Œä½¿æç«¯å€¼å˜åŒ–æ›´å¹³æ»‘
        risk_score = 100 / (1 + np.exp(-5 * (risk_factor - 0.2)))
        
        # ç¡®ä¿è¯„åˆ†åœ¨0-100èŒƒå›´å†…
        risk_score = max(0, min(100, risk_score))
        
        logger.debug(f"ETFé£é™©è¯„åˆ†è®¡ç®—: æ³¢åŠ¨ç‡={volatility:.4f}, æŠ˜æº¢ä»·æ ‡å‡†å·®={premium_discount_std:.4f}, é£é™©è¯„åˆ†={risk_score:.2f}")
        return risk_score
    
    except Exception as e:
        logger.error(f"è®¡ç®—é£é™©è¯„åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        return 50.0  # å‡ºé”™æ—¶è¿”å›ä¸­æ€§è¯„åˆ†

def calculate_return_score(df: pd.DataFrame) -> float:
    """
    è®¡ç®—æ”¶ç›Šè¯„åˆ†ï¼ˆ0-100åˆ†ï¼Œåˆ†æ•°è¶Šé«˜è¡¨ç¤ºæ½œåœ¨æ”¶ç›Šè¶Šå¤§ï¼‰
    
    Args:
        df: ETFæ—¥çº¿æ•°æ®
    
    Returns:
        float: æ”¶ç›Šè¯„åˆ†ï¼ˆ0-100åˆ†ï¼‰
    """
    try:
        # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®
        if len(df) < 30:
            logger.warning("ETFæ—¥çº¿æ•°æ®ä¸è¶³30å¤©ï¼Œæ— æ³•å‡†ç¡®è®¡ç®—æ”¶ç›Šè¯„åˆ†")
            return 50.0  # è¿”å›ä¸­æ€§è¯„åˆ†
        
        # ç¡®ä¿ä½¿ç”¨ä¸­æ–‡åˆ—å
        try:
            from utils.file_utils import ensure_chinese_columns
            df = ensure_chinese_columns(df)
        except ImportError:
            # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨å†…ç½®çš„åˆ—åæ˜ å°„
            logger.warning("æ— æ³•å¯¼å…¥ensure_chinese_columnsï¼Œå°è¯•ä½¿ç”¨å†…ç½®åˆ—åæ˜ å°„")
            # è¿™é‡Œå¯ä»¥æ·»åŠ å†…ç½®çš„åˆ—åæ˜ å°„é€»è¾‘
            pass
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…è¦åˆ—
        if "æ”¶ç›˜" not in df.columns and "close" not in df.columns:
            logger.error("ETFæ—¥çº¿æ•°æ®ç¼ºå°‘ä»·æ ¼åˆ—ï¼Œæ— æ³•è®¡ç®—æ”¶ç›Šè¯„åˆ†")
            return 50.0
        
        # é€‰æ‹©åˆé€‚çš„ä»·æ ¼åˆ—
        price_col = "æ”¶ç›˜" if "æ”¶ç›˜" in df.columns else "close"
        logger.info(f"æ‰¾åˆ°ä»·æ ¼åˆ—: {price_col} (å¯ç”¨ä»·æ ¼åˆ—: {list(df.columns)})")
        
        # ç¡®ä¿ä»·æ ¼åˆ—æ˜¯æ•°å€¼ç±»å‹
        if not pd.api.types.is_numeric_dtype(df[price_col]):
            try:
                df[price_col] = pd.to_numeric(df[price_col], errors='coerce')
                df = df.dropna(subset=[price_col])
            except:
                logger.error(f"ä»·æ ¼åˆ— {price_col} æ— æ³•è½¬æ¢ä¸ºæ•°å€¼ç±»å‹")
                return 50.0
        
        # è®¡ç®—æ”¶ç›Šç‡
        df["daily_return"] = df[price_col].pct_change().dropna()
        
        # ç¡®ä¿æ”¶ç›Šç‡åˆ—æ˜¯æ•°å€¼ç±»å‹
        if not pd.api.types.is_numeric_dtype(df["daily_return"]):
            try:
                df["daily_return"] = pd.to_numeric(df["daily_return"], errors='coerce')
                df = df.dropna(subset=["daily_return"])
            except:
                logger.error("æ”¶ç›Šç‡åˆ—æ— æ³•è½¬æ¢ä¸ºæ•°å€¼ç±»å‹")
                return 50.0
        
        # è®¡ç®—å¹´åŒ–æ”¶ç›Šç‡
        if len(df) < 2:
            return 50.0
        
        total_return = (df[price_col].iloc[-1] / df[price_col].iloc[0]) - 1
        annualized_return = total_return * (252 / len(df))
        
        # è®¡ç®—å¤æ™®æ¯”ç‡ï¼ˆæ— é£é™©åˆ©ç‡è®¾ä¸º0.02ï¼‰
        risk_free_rate = 0.02
        excess_return = annualized_return - risk_free_rate
        volatility = df["daily_return"].std() * np.sqrt(252)
        
        if volatility > 0:
            sharpe_ratio = excess_return / volatility
        else:
            sharpe_ratio = excess_return
        
        # å°†å¤æ™®æ¯”ç‡è½¬æ¢ä¸º0-100åˆ†çš„è¯„åˆ†
        # å¤æ™®æ¯”ç‡â‰¤0=0åˆ†ï¼Œ0.5=50åˆ†ï¼Œ1.0=100åˆ†
        if sharpe_ratio <= 0:
            return_score = 0
        elif sharpe_ratio <= 0.5:
            return_score = sharpe_ratio * 100
        elif sharpe_ratio <= 1.0:
            return_score = 50 + (sharpe_ratio - 0.5) * 100
        else:
            return_score = 100 + min(sharpe_ratio - 1.0, 1.0) * 50
        
        # ç¡®ä¿è¯„åˆ†åœ¨0-100èŒƒå›´å†…
        return_score = max(0, min(100, return_score))
        
        logger.debug(f"ETFæ”¶ç›Šè¯„åˆ†è®¡ç®—: å¹´åŒ–æ”¶ç›Šç‡={annualized_return:.4f}, æ³¢åŠ¨ç‡={volatility:.4f}, å¤æ™®æ¯”ç‡={sharpe_ratio:.4f}, æ”¶ç›Šè¯„åˆ†={return_score:.2f}")
        return return_score
    
    except Exception as e:
        logger.error(f"è®¡ç®—æ”¶ç›Šè¯„åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        return 50.0  # å‡ºé”™æ—¶è¿”å›ä¸­æ€§è¯„åˆ†

def calculate_sentiment_score(df: pd.DataFrame) -> float:
    """
    è®¡ç®—æƒ…ç»ªæŒ‡æ ‡å¾—åˆ†ï¼ˆ0-100åˆ†ï¼Œåˆ†æ•°è¶Šé«˜è¡¨ç¤ºæƒ…ç»ªè¶Šç§¯æï¼‰
    
    Args:
        df: ETFæ—¥çº¿æ•°æ®
    
    Returns:
        float: æƒ…ç»ªæŒ‡æ ‡å¾—åˆ†
    """
    try:
        if df is None or df.empty:
            logger.warning("ä¼ å…¥çš„DataFrameä¸ºç©ºï¼Œæƒ…ç»ªå¾—åˆ†è®¾ä¸º50")
            return 50.0
        
        # åˆ›å»ºDataFrameçš„å‰¯æœ¬ï¼Œé¿å…SettingWithCopyWarning
        df = df.copy(deep=True)
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…è¦åˆ—
        if AMOUNT_COL not in df.columns or CLOSE_COL not in df.columns:
            logger.warning("ETFæ—¥çº¿æ•°æ®ç¼ºå°‘å¿…è¦åˆ—ï¼Œæ— æ³•è®¡ç®—æƒ…ç»ªå¾—åˆ†")
            return 50.0
        
        # ç¡®ä¿æˆäº¤é¢å’Œæ”¶ç›˜ä»·æ˜¯æ•°å€¼ç±»å‹
        if not pd.api.types.is_numeric_dtype(df[AMOUNT_COL]):
            try:
                df[AMOUNT_COL] = pd.to_numeric(df[AMOUNT_COL], errors="coerce").fillna(0)
            except:
                logger.error(f"æˆäº¤é¢åˆ— {AMOUNT_COL} æ— æ³•è½¬æ¢ä¸ºæ•°å€¼ç±»å‹")
                return 50.0
        
        if not pd.api.types.is_numeric_dtype(df[CLOSE_COL]):
            try:
                df[CLOSE_COL] = pd.to_numeric(df[CLOSE_COL], errors="coerce").fillna(0)
            except:
                logger.error(f"æ”¶ç›˜ä»·åˆ— {CLOSE_COL} æ— æ³•è½¬æ¢ä¸ºæ•°å€¼ç±»å‹")
                return 50.0
        
        # è®¡ç®—æœ€è¿‘5å¤©çš„å¹³å‡æˆäº¤é¢
        recent_avg_volume = df[AMOUNT_COL].tail(5).mean()
        
        # è®¡ç®—å‰5-10å¤©çš„å¹³å‡æˆäº¤é¢
        prev_avg_volume = df[AMOUNT_COL].tail(10).head(5).mean() if len(df) >= 10 else df[AMOUNT_COL].mean()
        
        # è®¡ç®—æˆäº¤é¢å˜åŒ–ç‡
        volume_change = (recent_avg_volume - prev_avg_volume) / max(prev_avg_volume, 1)
        
        # è®¡ç®—æœ€è¿‘5å¤©çš„ä»·æ ¼å˜åŒ–
        recent_price_change = (df[CLOSE_COL].iloc[-1] / df[CLOSE_COL].iloc[-5]) - 1 if len(df) >= 5 else 0
        
        # ç»¼åˆæƒ…ç»ªæŒ‡æ ‡
        sentiment_score = 50 + (volume_change * 25) + (recent_price_change * 25)
        
        # ç¡®ä¿è¯„åˆ†åœ¨0-100èŒƒå›´å†…
        sentiment_score = max(0, min(100, sentiment_score))
        
        logger.debug(f"ETFæƒ…ç»ªè¯„åˆ†: {sentiment_score:.2f} (æˆäº¤é¢å˜åŒ–ç‡: {volume_change:.2f}, ä»·æ ¼å˜åŒ–: {recent_price_change:.2f})")
        return sentiment_score
    
    except Exception as e:
        logger.error(f"è®¡ç®—æƒ…ç»ªå¾—åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        return 50.0

def calculate_fundamental_score(etf_code: str) -> float:
    """
    è®¡ç®—åŸºæœ¬é¢å¾—åˆ†ï¼ˆè§„æ¨¡ã€ä¸Šå¸‚æ—¶é—´ç­‰ï¼‰
    
    Args:
        etf_code: ETFä»£ç 
    
    Returns:
        float: åŸºæœ¬é¢å¾—åˆ†
    """
    try:
        size, listing_date = get_etf_basic_info(etf_code)
        
        # è§„æ¨¡å¾—åˆ†ï¼ˆ10äº¿=60åˆ†ï¼Œ100äº¿=100åˆ†ï¼‰
        size_score = min(max(size * 0.4 + 50, 0), 100)
        
        # ä¸Šå¸‚æ—¶é—´å¾—åˆ†ï¼ˆ1å¹´=50åˆ†ï¼Œ5å¹´=100åˆ†ï¼‰
        if not listing_date:
            age_score = 50.0
        else:
            try:
                # å¤„ç†ä¸åŒæ ¼å¼çš„æ—¥æœŸå­—ç¬¦ä¸²
                if isinstance(listing_date, str):
                    # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
                    date_formats = ["%Y-%m-%d", "%Y/%m/%d", "%Y%m%d"]
                    listing_date_obj = None
                    for fmt in date_formats:
                        try:
                            listing_date_obj = datetime.strptime(listing_date, fmt)
                            break
                        except:
                            continue
                    if listing_date_obj:
                        years_since_listing = (datetime.now() - listing_date_obj).days / 365
                        age_score = min(50 + years_since_listing * 10, 100)
                    else:
                        logger.warning(f"ETF {etf_code} ä¸Šå¸‚æ—¥æœŸæ ¼å¼æ— æ³•è§£æ: {listing_date}")
                        age_score = 50.0
                elif isinstance(listing_date, datetime):
                    years_since_listing = (datetime.now() - listing_date).days / 365
                    age_score = min(50 + years_since_listing * 10, 100)
                else:
                    logger.warning(f"ETF {etf_code} ä¸Šå¸‚æ—¥æœŸç±»å‹æœªçŸ¥: {type(listing_date)}")
                    age_score = 50.0
            except Exception as e:
                logger.error(f"ETF {etf_code} ä¸Šå¸‚æ—¥æœŸå¤„ç†é”™è¯¯: {str(e)}")
                age_score = 50.0
        
        # ç»¼åˆåŸºæœ¬é¢è¯„åˆ†ï¼ˆè§„æ¨¡å 70%ï¼Œä¸Šå¸‚æ—¶é—´å 30%ï¼‰
        fundamental_score = size_score * 0.7 + age_score * 0.3
        
        logger.debug(f"ETF {etf_code} åŸºæœ¬é¢è¯„åˆ†: {fundamental_score:.2f} (è§„æ¨¡: {size}äº¿å…ƒ, ä¸Šå¸‚æ—¥æœŸ: {listing_date})")
        return fundamental_score
    
    except Exception as e:
        logger.error(f"è®¡ç®—ETF {etf_code} åŸºæœ¬é¢è¯„åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        return 70.0  # é»˜è®¤ä¸­ç­‰åé«˜è¯„åˆ†

def get_etf_basic_info(etf_code: str) -> Tuple[float, Optional[str]]:
    """
    ä»ETFåˆ—è¡¨ä¸­è·å–ETFåŸºæœ¬ä¿¡æ¯
    
    Args:
        etf_code: ETFä»£ç  (6ä½æ•°å­—)
    
    Returns:
        Tuple[float, Optional[str]]: (åŸºé‡‘è§„æ¨¡(å•ä½:äº¿å…ƒ), ä¸Šå¸‚æ—¥æœŸå­—ç¬¦ä¸²)
    """
    try:
        # ç¡®ä¿ETFä»£ç æ ¼å¼ä¸€è‡´ï¼ˆ6ä½æ•°å­—ï¼‰
        etf_code = str(etf_code).strip().zfill(6)
        
        # æ£€æŸ¥ETFåˆ—è¡¨æ˜¯å¦æœ‰æ•ˆ
        etf_list = load_all_etf_list()
        if etf_list is None or etf_list.empty:
            logger.warning("ETFåˆ—è¡¨ä¸ºç©ºæˆ–æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤å€¼")
            return 0.0, ""
        
        # ç¡®ä¿ETFåˆ—è¡¨åŒ…å«å¿…è¦çš„åˆ—
        required_columns = [ETF_CODE_COL, FUND_SIZE_COL, LISTING_DATE_COL]
        for col in required_columns:
            if col not in etf_list.columns:
                logger.warning(f"ETFåˆ—è¡¨ç¼ºå°‘å¿…è¦åˆ—: {col}")
                return 0.0, ""
        
        # ç¡®ä¿ETFåˆ—è¡¨ä¸­çš„ETFä»£ç ä¹Ÿæ˜¯6ä½æ•°å­—
        etf_list[ETF_CODE_COL] = etf_list[ETF_CODE_COL].astype(str).str.strip().str.zfill(6)
        
        etf_row = etf_list[etf_list[ETF_CODE_COL] == etf_code]
        if not etf_row.empty:
            # å¤„ç†è§„æ¨¡
            size = 0.0
            if FUND_SIZE_COL in etf_row.iloc[0]:
                size = extract_scalar_value(
                    etf_row.iloc[0][FUND_SIZE_COL], 
                    log_prefix=f"ETF {etf_code} è§„æ¨¡: "
                )
            
            # å¤„ç†ä¸Šå¸‚æ—¥æœŸ
            listing_date = ""
            if LISTING_DATE_COL in etf_row.iloc[0]:
                listing_date = str(etf_row.iloc[0][LISTING_DATE_COL])
            
            return size, listing_date
        
        logger.warning(f"ETF {etf_code} æœªåœ¨ETFåˆ—è¡¨ä¸­æ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤å€¼")
        return 0.0, ""
    
    except Exception as e:
        error_msg = f"è·å–ETF {etf_code} åŸºæœ¬ä¿¡æ¯å¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        # å‘é€é”™è¯¯é€šçŸ¥
        send_wechat_message(
            message=error_msg,
            message_type="error"
        )
        return 0.0, ""

def get_top_rated_etfs(top_n=None, min_score=60, min_fund_size=10.0, min_avg_volume=5000.0) -> pd.DataFrame:
    """
    ä»å…¨å¸‚åœºETFä¸­ç­›é€‰é«˜åˆ†ETF
    
    Args:
        top_n: è¿”å›å‰Nåï¼Œä¸ºNoneåˆ™è¿”å›æ‰€æœ‰é«˜äºmin_scoreçš„ETF
        min_score: æœ€ä½è¯„åˆ†é˜ˆå€¼
        min_fund_size: æœ€å°åŸºé‡‘è§„æ¨¡(äº¿å…ƒ)
        min_avg_volume: æœ€å°æ—¥å‡æˆäº¤é¢(ä¸‡å…ƒ)
    
    Returns:
        pd.DataFrame: åŒ…å«ETFä»£ç ã€åç§°ã€è¯„åˆ†ç­‰ä¿¡æ¯çš„DataFrame
    """
    try:
        metadata_df = load_etf_metadata()
        if metadata_df is None or metadata_df.empty:
            logger.warning("å…ƒæ•°æ®ä¸ºç©ºï¼Œæ— æ³•è·å–ETFåˆ—è¡¨")
            return pd.DataFrame()
        
        all_codes = metadata_df["etf_code"].tolist()
        if not all_codes:
            logger.warning("å…ƒæ•°æ®ä¸­æ— ETFä»£ç ")
            return pd.DataFrame()
        
        score_list = []
        logger.info(f"å¼€å§‹è®¡ç®— {len(all_codes)} åªETFçš„ç»¼åˆè¯„åˆ†...")
        
        for etf_code in all_codes:
            try:
                df = load_etf_daily_data(etf_code)
                if df.empty:
                    logger.debug(f"ETF {etf_code} æ— æ—¥çº¿æ•°æ®ï¼Œè·³è¿‡è¯„åˆ†")
                    continue
                
                # ç¡®ä¿ETFä»£ç æ ¼å¼ä¸€è‡´ï¼ˆ6ä½æ•°å­—ï¼‰
                etf_code = str(etf_code).strip().zfill(6)
                
                # è®¡ç®—ETFè¯„åˆ†
                score = calculate_etf_score(etf_code, df)
                if score < min_score:
                    continue
                
                # è·å–ETFåŸºæœ¬ä¿¡æ¯ï¼ˆä»æœ¬åœ°å…ƒæ•°æ®è·å–ï¼‰
                size = 0.0
                listing_date = ""
                if etf_code in metadata_df["etf_code"].values:
                    size = metadata_df[metadata_df["etf_code"] == etf_code]["size"].values[0]
                    listing_date = metadata_df[metadata_df["etf_code"] == etf_code]["listing_date"].values[0]
                
                etf_name = get_etf_name(etf_code)
                
                # è®¡ç®—æ—¥å‡æˆäº¤é¢ï¼ˆå•ä½ï¼šä¸‡å…ƒï¼‰
                avg_volume = 0.0
                if AMOUNT_COL in df.columns:
                    recent_30d = df.tail(30)
                    if len(recent_30d) > 0:
                        avg_volume = recent_30d[AMOUNT_COL].mean() / 10000
                
                # ä»…ä¿ç•™æ»¡è¶³æ¡ä»¶çš„ETF
                if size >= min_fund_size and avg_volume >= min_avg_volume:
                    score_list.append({
                        "ETFä»£ç ": etf_code,
                        "ETFåç§°": etf_name,
                        "è¯„åˆ†": score,
                        "è§„æ¨¡": size,
                        "æ—¥å‡æˆäº¤é¢": avg_volume,
                        "ä¸Šå¸‚æ—¥æœŸ": listing_date
                    })
                    logger.debug(f"ETF {etf_code} è¯„åˆ†: {score}, è§„æ¨¡: {size}äº¿å…ƒ, æ—¥å‡æˆäº¤é¢: {avg_volume}ä¸‡å…ƒ")
            except Exception as e:
                logger.error(f"å¤„ç†ETF {etf_code} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}", exc_info=True)
                continue
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¬¦åˆæ¡ä»¶çš„ETF
        if not score_list:
            warning_msg = (
                f"æ²¡æœ‰ETFè¾¾åˆ°æœ€ä½è¯„åˆ†é˜ˆå€¼ {min_score}ï¼Œ"
                f"æˆ–æœªæ»¡è¶³è§„æ¨¡({min_fund_size}äº¿å…ƒ)å’Œæ—¥å‡æˆäº¤é¢({min_avg_volume}ä¸‡å…ƒ)è¦æ±‚"
            )
            logger.info(warning_msg)
            return pd.DataFrame()
        
        # åˆ›å»ºè¯„åˆ†DataFrame
        score_df = pd.DataFrame(score_list).sort_values("è¯„åˆ†", ascending=False)
        total_etfs = len(score_df)
        
        # è®¡ç®—å‰X%çš„ETFæ•°é‡
        top_percent = Config.SCORE_TOP_PERCENT
        top_count = max(10, int(total_etfs * top_percent / 100))
        
        # è®°å½•ç­›é€‰ç»“æœ
        logger.info(f"è¯„åˆ†å®Œæˆã€‚å…±{total_etfs}åªETFè¯„åˆ†â‰¥{min_score}ï¼Œå–å‰{top_percent}%({top_count}åª)")
        logger.info(f"åº”ç”¨ç­›é€‰å‚æ•°: è§„æ¨¡â‰¥{min_fund_size}äº¿å…ƒ, æ—¥å‡æˆäº¤é¢â‰¥{min_avg_volume}ä¸‡å…ƒ")
        
        # è¿”å›ç»“æœ
        if top_n is not None and top_n > 0:
            return score_df.head(top_n)
        return score_df.head(top_count)
    
    except Exception as e:
        error_msg = f"è·å–é«˜åˆ†ETFåˆ—è¡¨æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
        logger.error(error_msg, exc_info=True)
        # å‘é€é”™è¯¯é€šçŸ¥
        send_wechat_message(
            message=error_msg,
            message_type="error"
        )
        return pd.DataFrame()

def get_etf_score_history(etf_code: str, days: int = 30) -> pd.DataFrame:
    """
    è·å–ETFå†å²è¯„åˆ†æ•°æ®
    
    Args:
        etf_code: ETFä»£ç 
        days: æŸ¥è¯¢å¤©æ•°
    
    Returns:
        pd.DataFrame: è¯„åˆ†å†å²æ•°æ®
    """
    try:
        history = []
        beijing_now = get_beijing_time()
        
        for i in range(days):
            date = (beijing_now - timedelta(days=i)).date().strftime("%Y-%m-%d")
            score_file = os.path.join(Config.SCORE_HISTORY_DIR, f"{etf_code}_{date}.json")
            
            if os.path.exists(score_file):
                try:
                    with open(score_file, 'r') as f:
                        score_data = json.load(f)
                        history.append({
                            "æ—¥æœŸ": date,
                            "è¯„åˆ†": score_data.get("score", 0.0),
                            "æ’å": score_data.get("rank", 0)
                        })
                except Exception as e:
                    logger.error(f"è¯»å–è¯„åˆ†å†å²æ–‡ä»¶ {score_file} å¤±è´¥: {str(e)}")
        
        if not history:
            logger.info(f"æœªæ‰¾åˆ°ETF {etf_code} çš„è¯„åˆ†å†å²æ•°æ®")
            return pd.DataFrame()
        
        return pd.DataFrame(history)
    
    except Exception as e:
        error_msg = f"è·å–ETF {etf_code} è¯„åˆ†å†å²æ•°æ®å¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        # å‘é€é”™è¯¯é€šçŸ¥
        send_wechat_message(
            message=error_msg,
            message_type="error"
        )
        return pd.DataFrame()

def analyze_etf_score_trend(etf_code: str) -> str:
    """
    åˆ†æETFè¯„åˆ†è¶‹åŠ¿
    
    Args:
        etf_code: ETFä»£ç 
    
    Returns:
        str: åˆ†æç»“æœ
    """
    try:
        # è·å–è¯„åˆ†å†å²
        history_df = get_etf_score_history(etf_code)
        if history_df.empty:
            return f"ã€{etf_code} è¯„åˆ†è¶‹åŠ¿ã€‘\nâ€¢ æ— å†å²è¯„åˆ†æ•°æ®"
        
        # è®¡ç®—è¶‹åŠ¿
        latest_score = history_df.iloc[0]["è¯„åˆ†"]
        avg_score = history_df["è¯„åˆ†"].mean()
        trend = "ä¸Šå‡" if latest_score > avg_score else "ä¸‹é™"
        
        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        report = f"ã€{etf_code} è¯„åˆ†è¶‹åŠ¿ã€‘\n"
        report += f"â€¢ å½“å‰è¯„åˆ†: {latest_score:.2f}\n"
        report += f"â€¢ è¿‘æœŸå¹³å‡è¯„åˆ†: {avg_score:.2f}\n"
        report += f"â€¢ è¯„åˆ†è¶‹åŠ¿: {trend}\n"
        
        # æ·»åŠ å»ºè®®
        if trend == "ä¸Šå‡":
            report += "ğŸ’¡ å»ºè®®ï¼šè¯„åˆ†æŒç»­ä¸Šå‡ï¼Œå¯å…³æ³¨è¯¥ETF"
        else:
            report += "ğŸ’¡ å»ºè®®ï¼šè¯„åˆ†æŒç»­ä¸‹é™ï¼Œéœ€è°¨æ…è€ƒè™‘"
        
        return report
    
    except Exception as e:
        error_msg = f"åˆ†æETF {etf_code} è¯„åˆ†è¶‹åŠ¿å¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        # å‘é€é”™è¯¯é€šçŸ¥
        send_wechat_message(
            message=error_msg,
            message_type="error"
        )
        return f"ã€{etf_code} è¯„åˆ†è¶‹åŠ¿ã€‘\nâ€¢ åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—"

# æ¨¡å—åˆå§‹åŒ–
try:
    # ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨
    Config.init_dirs()
    
    # æ£€æŸ¥ETFåˆ—è¡¨æ˜¯å¦è¿‡æœŸ
    if is_file_outdated(Config.ALL_ETFS_PATH, Config.ETF_LIST_UPDATE_INTERVAL):
        warning_msg = "ETFåˆ—è¡¨å·²è¿‡æœŸï¼Œè¯„åˆ†ç³»ç»Ÿå¯èƒ½ä½¿ç”¨æ—§æ•°æ®"
        logger.warning(warning_msg)
        # å‘é€è­¦å‘Šé€šçŸ¥
        send_wechat_message(
            message=warning_msg,
            message_type="error"
        )
    
    # åˆå§‹åŒ–æ—¥å¿—
    logger.info("ETFè¯„åˆ†ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
except Exception as e:
    error_msg = f"ETFè¯„åˆ†ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}"
    logger.error(error_msg, exc_info=True)
    
    try:
        # é€€å›åˆ°åŸºç¡€æ—¥å¿—é…ç½®
        logging.basicConfig(
            level="INFO",
            format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
            handlers=[logging.StreamHandler()]
        )
        logging.error(error_msg)
    except Exception as basic_log_error:
        print(f"åŸºç¡€æ—¥å¿—é…ç½®å¤±è´¥: {str(basic_log_error)}")
        print(error_msg)
    
    # å‘é€é”™è¯¯é€šçŸ¥
    try:
        send_wechat_message(
            message=error_msg,
            message_type="error"
        )
    except Exception as send_error:
        logger.error(f"å‘é€é”™è¯¯é€šçŸ¥å¤±è´¥: {str(send_error)}", exc_info=True)
