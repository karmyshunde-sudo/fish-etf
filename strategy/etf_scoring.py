#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ETFè¯„åˆ†ç³»ç»Ÿ
åŸºäºå¤šç»´åº¦æŒ‡æ ‡å¯¹ETFè¿›è¡Œç»¼åˆè¯„åˆ†
ç‰¹åˆ«ä¼˜åŒ–äº†æ¶ˆæ¯æ¨é€æ ¼å¼ï¼Œç¡®ä¿ä½¿ç”¨ç»Ÿä¸€çš„æ¶ˆæ¯æ¨¡æ¿
"""

import pandas as pd
import numpy as np
import logging
import os
import json
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple, Union
from config import Config
from utils.date_utils import (
    get_current_times,
    get_beijing_time,
    get_utc_time,
    is_file_outdated
)
from utils.file_utils import load_etf_daily_data, load_etf_metadata
from data_crawler.etf_list_manager import load_all_etf_list, get_etf_name
from wechat_push.push import send_wechat_message

# åˆå§‹åŒ–æ—¥å¿—
logger = logging.getLogger(__name__)

# å¸¸é‡å®šä¹‰
DATE_COL = "æ—¥æœŸ" if "æ—¥æœŸ" in Config.STANDARD_COLUMNS else "date"
CLOSE_COL = "æ”¶ç›˜" if "æ”¶ç›˜" in Config.STANDARD_COLUMNS else "close"
AMOUNT_COL = "æˆäº¤é¢" if "æˆäº¤é¢" in Config.STANDARD_COLUMNS else "amount"
ETF_CODE_COL = "ETFä»£ç "
FUND_SIZE_COL = "åŸºé‡‘è§„æ¨¡"
LISTING_DATE_COL = "ä¸Šå¸‚æ—¥æœŸ"  # æ–°å¢ï¼šå®šä¹‰ä¸Šå¸‚æ—¥æœŸåˆ—å

def extract_scalar_value(value, default=0.0, log_prefix=""):
    """
    å®‰å…¨åœ°ä»å„ç§ç±»å‹ä¸­æå–æ ‡é‡å€¼
    
    Args:
        value: å¯èƒ½æ˜¯æ ‡é‡ã€Seriesã€DataFrameã€å­—ç¬¦ä¸²ç­‰
        default: é»˜è®¤å€¼ï¼Œå¦‚æœæ— æ³•æå–æ ‡é‡å€¼
        log_prefix: æ—¥å¿—å‰ç¼€ï¼Œç”¨äºæ ‡è¯†è°ƒç”¨ä½ç½®
    
    Returns:
        float: æ ‡é‡å€¼
    """
    try:
        # å¦‚æœå·²ç»æ˜¯æ ‡é‡å€¼ï¼Œç›´æ¥è¿”å›
        if isinstance(value, (int, float)):
            return float(value)
        
        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è½¬æ¢ä¸ºæµ®ç‚¹æ•°
        if isinstance(value, str):
            # å°è¯•ç§»é™¤éæ•°å­—å­—ç¬¦
            cleaned_str = ''.join(c for c in value if c.isdigit() or c in ['.', '-'])
            if cleaned_str:
                result = float(cleaned_str)
                logger.debug(f"{log_prefix}ä»å­—ç¬¦ä¸²æå–æ ‡é‡å€¼: '{value}' -> {result}")
                return result
            logger.warning(f"{log_prefix}æ— æ³•ä»å­—ç¬¦ä¸² '{value}' æå–æœ‰æ•ˆæ•°å­—ï¼Œä½¿ç”¨é»˜è®¤å€¼{default}")
            return default
        
        # å¦‚æœæ˜¯pandaså¯¹è±¡ï¼Œå°è¯•æå–æ ‡é‡å€¼
        if isinstance(value, (pd.Series, pd.DataFrame)):
            # å°è¯•è·å–ç¬¬ä¸€ä¸ªå€¼
            if value.size > 0:
                # å°è¯•ä½¿ç”¨.values.flatten()[0]ï¼ˆæœ€å¯é ï¼‰
                try:
                    result = float(value.values.flatten()[0])
                    logger.debug(f"{log_prefix}é€šè¿‡.values.flatten()[0]æå–æ ‡é‡å€¼: {result}")
                    return result
                except Exception as e:
                    # å°è¯•ä½¿ç”¨.item()
                    try:
                        result = float(value.item())
                        logger.debug(f"{log_prefix}é€šè¿‡.item()æå–æ ‡é‡å€¼: {result}")
                        return result
                    except Exception as e2:
                        # å°è¯•ä½¿ç”¨.iloc[0]
                        try:
                            valid_values = value[~pd.isna(value)]
                            if not valid_values.empty:
                                result = float(valid_values.iloc[0])
                                logger.debug(f"{log_prefix}é€šè¿‡.iloc[0]æå–æ ‡é‡å€¼: {result}")
                                return result
                        except Exception as e3:
                            pass
            
            logger.error(f"{log_prefix}æ— æ³•ä»pandaså¯¹è±¡æå–æ ‡é‡å€¼(size={value.size})ï¼Œä½¿ç”¨é»˜è®¤å€¼{default}")
            return default
        
        # å°è¯•ç›´æ¥è½¬æ¢ä¸ºæµ®ç‚¹æ•°
        result = float(value)
        logger.debug(f"{log_prefix}ç›´æ¥è½¬æ¢ä¸ºæµ®ç‚¹æ•°: {result}")
        return result
    
    except Exception as e:
        logger.error(f"{log_prefix}æ— æ³•ä»ç±»å‹ {type(value)} ä¸­æå–æ ‡é‡å€¼: {str(e)}ï¼Œä½¿ç”¨é»˜è®¤å€¼{default}")
        return default

def get_etf_basic_info(etf_code: str) -> Tuple[float, Optional[str]]:
    """
    ä»ETFåˆ—è¡¨ä¸­è·å–ETFåŸºæœ¬ä¿¡æ¯
    
    Args:
        etf_code: ETFä»£ç  (6ä½æ•°å­—)
    
    Returns:
        Tuple[float, Optional[str]]: (åŸºé‡‘è§„æ¨¡(å•ä½:äº¿å…ƒ), ä¸Šå¸‚æ—¥æœŸå­—ç¬¦ä¸²)
    """
    try:
        # ç¡®ä¿ETFä»£ç æ ¼å¼ä¸€è‡´ï¼ˆ6ä½æ•°å­—ï¼‰
        etf_code = str(etf_code).strip().zfill(6)
        
        # æ£€æŸ¥ETFåˆ—è¡¨æ˜¯å¦æœ‰æ•ˆ
        etf_list = load_all_etf_list()
        if etf_list is None or etf_list.empty:
            logger.warning("ETFåˆ—è¡¨ä¸ºç©ºæˆ–æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤å€¼")
            return 0.0, ""
        
        # ç¡®ä¿ETFåˆ—è¡¨åŒ…å«å¿…è¦çš„åˆ—
        required_columns = [ETF_CODE_COL, FUND_SIZE_COL, LISTING_DATE_COL]
        for col in required_columns:
            if col not in etf_list.columns:
                logger.warning(f"ETFåˆ—è¡¨ç¼ºå°‘å¿…è¦åˆ—: {col}")
                # å°è¯•ä»configä¸­è·å–åˆ—åæ˜ å°„
                if col == LISTING_DATE_COL and "listing_date" in Config.COLUMN_NAME_MAPPING:
                    mapped_col = Config.COLUMN_NAME_MAPPING["listing_date"]
                    if mapped_col in etf_list.columns:
                        required_columns[required_columns.index(col)] = mapped_col
                        continue
                return 0.0, ""
        
        # ç¡®ä¿ETFåˆ—è¡¨ä¸­çš„ETFä»£ç ä¹Ÿæ˜¯6ä½æ•°å­—
        etf_list = etf_list.copy()  # åˆ›å»ºå‰¯æœ¬é¿å…SettingWithCopyWarning
        etf_list.loc[:, ETF_CODE_COL] = etf_list[ETF_CODE_COL].astype(str).str.strip().str.zfill(6)
        
        etf_row = etf_list[etf_list[ETF_CODE_COL] == etf_code]
        if not etf_row.empty:
            # å¤„ç†è§„æ¨¡
            size = 0.0
            if FUND_SIZE_COL in etf_row.columns:
                size = extract_scalar_value(etf_row.iloc[0][FUND_SIZE_COL],
                                           log_prefix=f"ETF {etf_code} è§„æ¨¡: ")
            
            # å¤„ç†ä¸Šå¸‚æ—¥æœŸ
            listing_date = ""
            if LISTING_DATE_COL in etf_row.columns:
                listing_date = str(etf_row.iloc[0][LISTING_DATE_COL])
            elif "listing_date" in Config.COLUMN_NAME_MAPPING:
                mapped_col = Config.COLUMN_NAME_MAPPING["listing_date"]
                if mapped_col in etf_row.columns:
                    listing_date = str(etf_row.iloc[0][mapped_col])
            
            return size, listing_date
        
        logger.warning(f"ETF {etf_code} æœªåœ¨ETFåˆ—è¡¨ä¸­æ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤å€¼")
        return 0.0, ""
    
    except Exception as e:
        error_msg = f"è·å–ETF {etf_code} åŸºæœ¬ä¿¡æ¯å¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        # å‘é€é”™è¯¯é€šçŸ¥
        try:
            send_wechat_message(message=error_msg, message_type="error")
        except Exception as send_error:
            logger.error(f"å‘é€é”™è¯¯é€šçŸ¥å¤±è´¥: {str(send_error)}", exc_info=True)
        return 0.0, ""

def calculate_volatility(df: pd.DataFrame) -> float:
    """
    è®¡ç®—ETFä»·æ ¼æ³¢åŠ¨ç‡
    
    Args:
        df: ETFæ—¥çº¿æ•°æ®
    
    Returns:
        float: æ³¢åŠ¨ç‡
    """
    try:
        # ç¡®ä¿ä½¿ç”¨ä¸­æ–‡åˆ—å
        try:
            from utils.file_utils import ensure_chinese_columns
            df = ensure_chinese_columns(df)
        except ImportError:
            # å¦‚æœå¯¼å…¥å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨å†…ç½®çš„åˆ—åæ˜ å°„
            logger.warning("æ— æ³•å¯¼å…¥ensure_chinese_columnsï¼Œå°è¯•ä½¿ç”¨å†…ç½®åˆ—åæ˜ å°„")
            # è¿™é‡Œå¯ä»¥æ·»åŠ å†…ç½®çš„åˆ—åæ˜ å°„é€»è¾‘
            
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…è¦åˆ—
        if CLOSE_COL not in df.columns:
            logger.warning(f"ETFæ—¥çº¿æ•°æ®ç¼ºå°‘{CLOSE_COL}åˆ—ï¼Œæ— æ³•è®¡ç®—æ³¢åŠ¨ç‡")
            return 0.5  # é»˜è®¤æ³¢åŠ¨ç‡
        
        # åˆ›å»ºDataFrameçš„å‰¯æœ¬ï¼Œé¿å…SettingWithCopyWarning
        df = df.copy(deep=True)
        
        # ç¡®ä¿æ”¶ç›˜ä»·åˆ—æ˜¯æ•°å€¼ç±»å‹
        if not pd.api.types.is_numeric_dtype(df[CLOSE_COL]):
            try:
                df[CLOSE_COL] = pd.to_numeric(df[CLOSE_COL], errors="coerce").fillna(0)
            except Exception as e:
                logger.error(f"æ”¶ç›˜ä»·åˆ—è½¬æ¢å¤±è´¥: {str(e)}")
                return 0.5
        
        # è®¡ç®—æ—¥æ”¶ç›Šç‡
        # ä¿®å¤ï¼šä½¿ç”¨.locé¿å…SettingWithCopyWarning
        df.loc[:, "daily_return"] = df[CLOSE_COL].pct_change().dropna()
        
        # å¤„ç†NaNå€¼
        if "daily_return" in df.columns:
            df["daily_return"] = pd.to_numeric(df["daily_return"], errors='coerce')
            df = df.dropna(subset=["daily_return"])
        
        # è®¡ç®—æ³¢åŠ¨ç‡ï¼ˆå¹´åŒ–æ³¢åŠ¨ç‡ï¼‰
        if len(df["daily_return"]) < 2:
            logger.warning("æ”¶ç›Šç‡æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—æ³¢åŠ¨ç‡")
            return 0.5
        
        volatility = df["daily_return"].std() * np.sqrt(252)  # å¹´åŒ–æ³¢åŠ¨ç‡
        return volatility
    
    except Exception as e:
        logger.error(f"è®¡ç®—ETFæ³¢åŠ¨ç‡å¤±è´¥: {str(e)}", exc_info=True)
        return 0.5  # é»˜è®¤æ³¢åŠ¨ç‡

def calculate_liquidity_score(df: pd.DataFrame) -> float:
    """è®¡ç®—æµåŠ¨æ€§å¾—åˆ†ï¼ˆæ—¥å‡æˆäº¤é¢ï¼‰
    Args:
        df: ETFæ—¥çº¿æ•°æ®
    Returns:
        float: æµåŠ¨æ€§å¾—åˆ†
    """
    try:
        if df is None or df.empty:
            logger.warning("ä¼ å…¥çš„DataFrameä¸ºç©ºï¼ŒæµåŠ¨æ€§å¾—åˆ†è®¾ä¸º0")
            return 0.0

        # åˆ›å»ºDataFrameçš„å‰¯æœ¬ï¼Œé¿å…SettingWithCopyWarning
        df = df.copy(deep=True)

        # æ£€æŸ¥æ˜¯å¦åŒ…å«æˆäº¤é¢åˆ—
        if AMOUNT_COL not in df.columns:
            logger.warning(f"ETFæ—¥çº¿æ•°æ®ç¼ºå°‘{AMOUNT_COL}åˆ—ï¼Œæ— æ³•è®¡ç®—æµåŠ¨æ€§å¾—åˆ†")
            return 50.0

        # ç¡®ä¿æˆäº¤é¢åˆ—æ˜¯æ•°å€¼ç±»å‹
        if not pd.api.types.is_numeric_dtype(df[AMOUNT_COL]):
            try:
                df[AMOUNT_COL] = pd.to_numeric(df[AMOUNT_COL], errors="coerce").fillna(0)
            except Exception as e:
                logger.error(f"æˆäº¤é¢åˆ—è½¬æ¢å¤±è´¥: {str(e)}")
                return 50.0

        # ä¿®å¤ï¼šä¸å†è¿›è¡Œå•ä½è½¬æ¢ï¼Œå› ä¸ºdata_crawlerä¸­å·²ç»Ÿä¸€è½¬æ¢ä¸º"ä¸‡å…ƒ"
        avg_volume = df[AMOUNT_COL].mean()

        # æµåŠ¨æ€§è¯„åˆ†ï¼ˆå¯¹æ•°å°ºåº¦ï¼Œæ›´ç¬¦åˆå®é™…æ„Ÿå—ï¼‰
        # 1000ä¸‡å…ƒ=50åˆ†ï¼Œ5000ä¸‡å…ƒ=75åˆ†ï¼Œ10000ä¸‡å…ƒ=90åˆ†
        if avg_volume <= 1000:
            score = 30 + (avg_volume / 1000) * 20
        elif avg_volume <= 5000:
            score = 50 + ((avg_volume - 1000) / 4000) * 25
        elif avg_volume <= 10000:
            score = 75 + ((avg_volume - 5000) / 5000) * 15
        else:
            score = 90 + min((avg_volume - 10000) / 10000, 10)

        logger.debug(f"ETFæµåŠ¨æ€§è¯„åˆ†: {score:.2f} (æ—¥å‡æˆäº¤é¢: {avg_volume:.2f}ä¸‡å…ƒ)")
        return score
    except Exception as e:
        logger.error(f"è®¡ç®—æµåŠ¨æ€§å¾—åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        return 50.0

def calculate_risk_score(df: pd.DataFrame) -> float:
    """
    è®¡ç®—é£é™©è¯„åˆ†ï¼ˆ0-100åˆ†ï¼Œåˆ†æ•°è¶Šé«˜é£é™©è¶Šå¤§ï¼‰
    
    Args:
        df: ETFæ—¥çº¿æ•°æ®
    
    Returns:
        float: é£é™©è¯„åˆ†ï¼ˆ0-100åˆ†ï¼‰
    """
    try:
        # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®
        if len(df) < 30:
            logger.warning("ETFæ—¥çº¿æ•°æ®ä¸è¶³30å¤©ï¼Œæ— æ³•å‡†ç¡®è®¡ç®—é£é™©è¯„åˆ†")
            return 50.0  # è¿”å›ä¸­æ€§è¯„åˆ†
        
        # ç¡®ä¿ä½¿ç”¨ä¸­æ–‡åˆ—å
        try:
            from utils.file_utils import ensure_chinese_columns
            df = ensure_chinese_columns(df)
        except ImportError:
            logger.warning("æ— æ³•å¯¼å…¥ensure_chinese_columnsï¼Œå°è¯•ä½¿ç”¨å†…ç½®åˆ—åæ˜ å°„")
        
        # è®¡ç®—æ³¢åŠ¨ç‡
        volatility = calculate_volatility(df)
        
        # è®¡ç®—æŠ˜æº¢ä»·ç‡æ ‡å‡†å·®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        premium_discount_std = 0.0
        if "æŠ˜æº¢ä»·ç‡" in df.columns:
            # åˆ›å»ºDataFrameçš„å‰¯æœ¬
            df = df.copy(deep=True)
            # ç¡®ä¿æŠ˜æº¢ä»·ç‡åˆ—æ˜¯æ•°å€¼ç±»å‹
            df["æŠ˜æº¢ä»·ç‡"] = pd.to_numeric(df["æŠ˜æº¢ä»·ç‡"], errors="coerce")
            premium_discount_std = df["æŠ˜æº¢ä»·ç‡"].std()
        
        # é£é™©è¯„åˆ†ï¼ˆæ³¢åŠ¨ç‡å 70%ï¼ŒæŠ˜æº¢ä»·ç‡æ ‡å‡†å·®å 30%ï¼‰
        # æ³¢åŠ¨ç‡â‰¤0.1=30åˆ†ï¼Œ0.3=50åˆ†ï¼Œâ‰¥0.5=70åˆ†
        volatility_score = min(30 + (volatility * 200), 70)
        # æŠ˜æº¢ä»·ç‡æ ‡å‡†å·®â‰¤0.5=20åˆ†ï¼Œ1.0=30åˆ†ï¼Œâ‰¥1.5=50åˆ†
        premium_score = min(20 + (premium_discount_std * 60), 50)
        
        risk_score = volatility_score * 0.7 + premium_score * 0.3
        risk_score = max(0, min(100, risk_score))
        
        logger.debug(f"ETFé£é™©è¯„åˆ†è®¡ç®—: æ³¢åŠ¨ç‡={volatility:.4f}, æŠ˜æº¢ä»·æ ‡å‡†å·®={premium_discount_std:.4f}, é£é™©è¯„åˆ†={risk_score:.2f}")
        return risk_score
    
    except Exception as e:
        logger.error(f"è®¡ç®—é£é™©è¯„åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        return 50.0  # å‡ºé”™æ—¶è¿”å›ä¸­æ€§è¯„åˆ†

def calculate_return_score(df: pd.DataFrame) -> float:
    """
    è®¡ç®—æ”¶ç›Šè¯„åˆ†ï¼ˆ0-100åˆ†ï¼Œåˆ†æ•°è¶Šé«˜è¡¨ç¤ºæ½œåœ¨æ”¶ç›Šè¶Šå¤§ï¼‰
    
    Args:
        df: ETFæ—¥çº¿æ•°æ®
    
    Returns:
        float: æ”¶ç›Šè¯„åˆ†ï¼ˆ0-100åˆ†ï¼‰
    """
    try:
        # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®
        if len(df) < 30:
            logger.warning("ETFæ—¥çº¿æ•°æ®ä¸è¶³30å¤©ï¼Œæ— æ³•å‡†ç¡®è®¡ç®—æ”¶ç›Šè¯„åˆ†")
            return 50.0  # è¿”å›ä¸­æ€§è¯„åˆ†
        
        # ç¡®ä¿ä½¿ç”¨ä¸­æ–‡åˆ—å
        try:
            from utils.file_utils import ensure_chinese_columns
            df = ensure_chinese_columns(df)
        except ImportError:
            logger.warning("æ— æ³•å¯¼å…¥ensure_chinese_columnsï¼Œå°è¯•ä½¿ç”¨å†…ç½®åˆ—åæ˜ å°„")
        
        # ç¡®ä¿DataFrameæ˜¯å‰¯æœ¬ï¼Œé¿å…SettingWithCopyWarning
        df = df.copy(deep=True)
        
        # ç¡®ä¿æ”¶ç›˜ä»·åˆ—æ˜¯æ•°å€¼ç±»å‹
        if not pd.api.types.is_numeric_dtype(df[CLOSE_COL]):
            try:
                df[CLOSE_COL] = pd.to_numeric(df[CLOSE_COL], errors="coerce").fillna(0)
            except Exception as e:
                logger.error(f"æ”¶ç›˜ä»·åˆ—è½¬æ¢å¤±è´¥: {str(e)}")
                return 50.0
        
        # è®¡ç®—æ—¥æ”¶ç›Šç‡
        # ä¿®å¤ï¼šä½¿ç”¨.locé¿å…SettingWithCopyWarning
        df.loc[:, "daily_return"] = df[CLOSE_COL].pct_change().dropna()
        
        # å¤„ç†NaNå€¼
        if "daily_return" in df.columns:
            df["daily_return"] = pd.to_numeric(df["daily_return"], errors='coerce')
            df = df.dropna(subset=["daily_return"])
        
        # è®¡ç®—å¹´åŒ–æ”¶ç›Šç‡
        periods = len(df)
        if periods < 2:
            return 50.0
        
        total_return = (df[CLOSE_COL].iloc[-1] / df[CLOSE_COL].iloc[0]) - 1
        annualized_return = (1 + total_return) ** (252 / periods) - 1
        
        # è®¡ç®—æ³¢åŠ¨ç‡ï¼ˆç”¨äºå¤æ™®æ¯”ç‡ï¼‰
        volatility = calculate_volatility(df)
        
        # è®¡ç®—å¤æ™®æ¯”ç‡ï¼ˆæ— é£é™©åˆ©ç‡è®¾ä¸º2%ï¼‰
        risk_free_rate = 0.02
        excess_return = annualized_return - risk_free_rate
        if volatility > 0:
            sharpe_ratio = excess_return / volatility
        else:
            sharpe_ratio = excess_return
        
        # å°†å¤æ™®æ¯”ç‡è½¬æ¢ä¸º0-100åˆ†çš„è¯„åˆ†
        # å¤æ™®æ¯”ç‡â‰¤0=0åˆ†ï¼Œ0.5=50åˆ†ï¼Œ1.0=100åˆ†
        if sharpe_ratio <= 0:
            return_score = 0
        elif sharpe_ratio <= 0.5:
            return_score = sharpe_ratio * 100
        elif sharpe_ratio <= 1.0:
            return_score = 50 + (sharpe_ratio - 0.5) * 100
        else:
            return_score = 100 + min(sharpe_ratio - 1.0, 1.0) * 50
        
        # ç¡®ä¿è¯„åˆ†åœ¨0-100èŒƒå›´å†…
        return_score = max(0, min(100, return_score))
        
        logger.debug(f"ETFæ”¶ç›Šè¯„åˆ†è®¡ç®—: å¹´åŒ–æ”¶ç›Šç‡={annualized_return:.4f}, æ³¢åŠ¨ç‡={volatility:.4f}, å¤æ™®æ¯”ç‡={sharpe_ratio:.4f}, æ”¶ç›Šè¯„åˆ†={return_score:.2f}")
        return return_score
    
    except Exception as e:
        logger.error(f"è®¡ç®—æ”¶ç›Šè¯„åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        return 50.0  # å‡ºé”™æ—¶è¿”å›ä¸­æ€§è¯„åˆ†

def calculate_sentiment_score(df: pd.DataFrame) -> float:
    """
    è®¡ç®—æƒ…ç»ªæŒ‡æ ‡å¾—åˆ†ï¼ˆ0-100åˆ†ï¼Œåˆ†æ•°è¶Šé«˜è¡¨ç¤ºæƒ…ç»ªè¶Šç§¯æï¼‰
    
    Args:
        df: ETFæ—¥çº¿æ•°æ®
    
    Returns:
        float: æƒ…ç»ªæŒ‡æ ‡å¾—åˆ†
    """
    try:
        if df is None or df.empty:
            logger.warning("ä¼ å…¥çš„DataFrameä¸ºç©ºï¼Œæƒ…ç»ªå¾—åˆ†è®¾ä¸º50")
            return 50.0
        
        # åˆ›å»ºDataFrameçš„å‰¯æœ¬ï¼Œé¿å…SettingWithCopyWarning
        df = df.copy(deep=True)
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…è¦åˆ—
        if AMOUNT_COL not in df.columns or CLOSE_COL not in df.columns:
            logger.warning("ETFæ—¥çº¿æ•°æ®ç¼ºå°‘å¿…è¦åˆ—ï¼Œæ— æ³•è®¡ç®—æƒ…ç»ªå¾—åˆ†")
            return 50.0
        
        # ç¡®ä¿æˆäº¤é¢å’Œæ”¶ç›˜ä»·æ˜¯æ•°å€¼ç±»å‹
        if not pd.api.types.is_numeric_dtype(df[AMOUNT_COL]):
            try:
                df[AMOUNT_COL] = pd.to_numeric(df[AMOUNT_COL], errors="coerce").fillna(0)
            except Exception as e:
                logger.error(f"æˆäº¤é¢åˆ—è½¬æ¢å¤±è´¥: {str(e)}")
                return 50.0
        
        if not pd.api.types.is_numeric_dtype(df[CLOSE_COL]):
            try:
                df[CLOSE_COL] = pd.to_numeric(df[CLOSE_COL], errors="coerce").fillna(0)
            except Exception as e:
                logger.error(f"æ”¶ç›˜ä»·åˆ—è½¬æ¢å¤±è´¥: {str(e)}")
                return 50.0
        
        # è®¡ç®—æœ€è¿‘5å¤©çš„æˆäº¤é¢å˜åŒ–ç‡
        if len(df) >= 5:
            recent_volume = df[AMOUNT_COL].tail(5).mean()
            prev_volume = df[AMOUNT_COL].iloc[-10:-5].mean() if len(df) >= 10 else df[AMOUNT_COL].mean()
            volume_change = (recent_volume - prev_volume) / prev_volume if prev_volume > 0 else 0
        else:
            volume_change = 0
        
        # è®¡ç®—æœ€è¿‘5å¤©çš„ä»·æ ¼å˜åŒ–
        recent_price_change = (df[CLOSE_COL].iloc[-1] / df[CLOSE_COL].iloc[-5]) - 1 if len(df) >= 5 else 0
        
        # ç»¼åˆæƒ…ç»ªæŒ‡æ ‡
        sentiment_score = 50 + (volume_change * 25) + (recent_price_change * 25)
        
        # ç¡®ä¿è¯„åˆ†åœ¨0-100èŒƒå›´å†…
        sentiment_score = max(0, min(100, sentiment_score))
        
        logger.debug(f"ETFæƒ…ç»ªè¯„åˆ†: {sentiment_score:.2f} (æˆäº¤é¢å˜åŒ–ç‡: {volume_change:.2f}, ä»·æ ¼å˜åŒ–: {recent_price_change:.2f})")
        return sentiment_score
    
    except Exception as e:
        logger.error(f"è®¡ç®—æƒ…ç»ªå¾—åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        return 50.0

def calculate_fundamental_score(etf_code: str) -> float:
    """
    è®¡ç®—åŸºæœ¬é¢å¾—åˆ†ï¼ˆè§„æ¨¡ã€ä¸Šå¸‚æ—¶é—´ç­‰ï¼‰
    
    Args:
        etf_code: ETFä»£ç 
    
    Returns:
        float: åŸºæœ¬é¢å¾—åˆ†
    """
    try:
        size, listing_date = get_etf_basic_info(etf_code)
        
        # è§„æ¨¡å¾—åˆ†ï¼ˆ10äº¿=60åˆ†ï¼Œ100äº¿=100åˆ†ï¼‰
        size_score = min(max(size * 0.4 + 50, 0), 100)
        
        # ä¸Šå¸‚æ—¶é—´å¾—åˆ†ï¼ˆ1å¹´=50åˆ†ï¼Œ5å¹´=100åˆ†ï¼‰
        age_score = 50.0
        if listing_date and listing_date.strip() != "":
            try:
                # å¤„ç†ä¸åŒæ ¼å¼çš„æ—¥æœŸå­—ç¬¦ä¸²
                if isinstance(listing_date, str):
                    # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
                    date_formats = ["%Y-%m-%d", "%Y/%m/%d", "%Y%m%d"]
                    listing_date_obj = None
                    for fmt in date_formats:
                        try:
                            listing_date_obj = datetime.strptime(listing_date, fmt)
                            break
                        except:
                            continue
                    if listing_date_obj:
                        years_since_listing = (datetime.now() - listing_date_obj).days / 365
                        age_score = min(50 + years_since_listing * 10, 100)
                    else:
                        logger.warning(f"ETF {etf_code} ä¸Šå¸‚æ—¥æœŸæ ¼å¼æ— æ³•è§£æ: {listing_date}")
                        age_score = 50.0
                elif isinstance(listing_date, datetime):
                    years_since_listing = (datetime.now() - listing_date).days / 365
                    age_score = min(50 + years_since_listing * 10, 100)
                else:
                    logger.warning(f"ETF {etf_code} ä¸Šå¸‚æ—¥æœŸç±»å‹æœªçŸ¥: {type(listing_date)}")
                    age_score = 50.0
            except Exception as e:
                logger.error(f"ETF {etf_code} ä¸Šå¸‚æ—¥æœŸå¤„ç†é”™è¯¯: {str(e)}")
                age_score = 50.0
        
        # ç»¼åˆåŸºæœ¬é¢è¯„åˆ†ï¼ˆè§„æ¨¡å 70%ï¼Œä¸Šå¸‚æ—¶é—´å 30%ï¼‰
        fundamental_score = size_score * 0.7 + age_score * 0.3
        
        logger.debug(f"ETF {etf_code} åŸºæœ¬é¢è¯„åˆ†: {fundamental_score:.2f} (è§„æ¨¡: {size}äº¿å…ƒ, ä¸Šå¸‚æ—¥æœŸ: {listing_date})")
        return fundamental_score
    
    except Exception as e:
        logger.error(f"è®¡ç®—ETF {etf_code} åŸºæœ¬é¢è¯„åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        return 70.0  # é»˜è®¤ä¸­ç­‰åé«˜è¯„åˆ†

def calculate_etf_score(etf_code: str, df: pd.DataFrame) -> float:
    """
    è®¡ç®—ETFç»¼åˆè¯„åˆ†ï¼ˆ0-100åˆ†ï¼‰
    
    Args:
        etf_code: ETFä»£ç 
        df: ETFæ—¥çº¿æ•°æ®
    
    Returns:
        float: ETFç»¼åˆè¯„åˆ†
    """
    try:
        # è·å–å½“å‰åŒæ—¶åŒºæ—¶é—´
        _, beijing_now = get_current_times()
        
        # åˆ›å»ºDataFrameçš„å‰¯æœ¬ï¼Œé¿å…SettingWithCopyWarning
        if df is None or df.empty:
            logger.warning(f"ETF {etf_code} æ— æ—¥çº¿æ•°æ®ï¼Œè¯„åˆ†è®¾ä¸º0")
            return 0.0
        
        # åˆ›å»ºå®‰å…¨å‰¯æœ¬
        df = df.copy(deep=True)
        
        # ç¡®ä¿æ•°æ®æŒ‰æ—¥æœŸæ’åº
        if DATE_COL in df.columns:
            df = df.sort_values(DATE_COL)
        
        # æ£€æŸ¥ETFæ˜¯å¦ä¸ºæ–°ä¸Šå¸‚
        size, listing_date = get_etf_basic_info(etf_code)
        is_new_etf = False
        days_since_listing = 0
        if listing_date and listing_date.strip() != "":
            try:
                # å¤„ç†ä¸åŒæ ¼å¼çš„æ—¥æœŸå­—ç¬¦ä¸²
                if isinstance(listing_date, str):
                    # å°è¯•å¤šç§æ—¥æœŸæ ¼å¼
                    date_formats = ["%Y-%m-%d", "%Y/%m/%d", "%Y%m%d"]
                    listing_date_obj = None
                    for fmt in date_formats:
                        try:
                            listing_date_obj = datetime.strptime(listing_date, fmt)
                            break
                        except:
                            continue
                    if listing_date_obj:
                        days_since_listing = (beijing_now - listing_date_obj).days
                        is_new_etf = days_since_listing < 90  # ä¸Šå¸‚90å¤©å†…è§†ä¸ºæ–°ETF
                elif isinstance(listing_date, datetime):
                    days_since_listing = (beijing_now - listing_date).days
                    is_new_etf = days_since_listing < 90
            except Exception as e:
                logger.error(f"ETF {etf_code} ä¸Šå¸‚æ—¥æœŸè§£æé”™è¯¯: {str(e)}")
        
        # æ£€æŸ¥æ•°æ®é‡
        min_required_data = 30  # é»˜è®¤éœ€è¦30å¤©æ•°æ®
        if len(df) < min_required_data:
            if len(df) < 10:
                logger.warning(f"ETF {etf_code} æ•°æ®é‡ä¸¥é‡ä¸è¶³({len(df)}å¤©)ï¼Œè¯„åˆ†è®¾ä¸º0")
                return 0.0
            else:
                logger.info(f"ETF {etf_code} æ•°æ®é‡ä¸è¶³({len(df)}å¤©)ï¼Œä½¿ç”¨ç°æœ‰æ•°æ®è®¡ç®—è¯„åˆ†")
                min_required_data = len(df)
        
        # 1. æµåŠ¨æ€§å¾—åˆ†ï¼ˆæ—¥å‡æˆäº¤é¢ï¼‰
        liquidity_score = calculate_liquidity_score(df)
        
        # 2. é£é™©æ§åˆ¶å¾—åˆ†
        risk_score = calculate_risk_score(df)
        
        # 3. æ”¶ç›Šèƒ½åŠ›å¾—åˆ†
        return_score = calculate_return_score(df)
        
        # 4. æƒ…ç»ªæŒ‡æ ‡å¾—åˆ†ï¼ˆæˆäº¤é‡å˜åŒ–ç‡ï¼‰
        sentiment_score = calculate_sentiment_score(df)
        
        # 5. åŸºæœ¬é¢å¾—åˆ†ï¼ˆè§„æ¨¡ã€ä¸Šå¸‚æ—¶é—´ç­‰ï¼‰
        fundamental_score = calculate_fundamental_score(etf_code)
        
        # éªŒè¯æ‰€æœ‰å¾—åˆ†æ˜¯å¦åœ¨æœ‰æ•ˆèŒƒå›´å†… [0, 100]
        scores = {
            "liquidity": max(0, min(100, liquidity_score)),
            "risk": max(0, min(100, risk_score)),
            "return": max(0, min(100, return_score)),
            "sentiment": max(0, min(100, sentiment_score)),
            "fundamental": max(0, min(100, fundamental_score))
        }
        
        # è·å–æƒé‡
        weights = Config.SCORE_WEIGHTS.copy()
        
        # ç¡®ä¿æƒé‡å­—å…¸åŒ…å«æ‰€æœ‰å¿…è¦çš„é”®
        required_keys = ['liquidity', 'risk', 'return', 'sentiment', 'fundamental']
        for key in required_keys:
            if key not in weights:
                logger.warning(f"æƒé‡å­—å…¸ç¼ºå°‘å¿…è¦é”®: {key}, ä½¿ç”¨é»˜è®¤å€¼0.2")
                weights[key] = 0.2
        
        # ç¡®ä¿æƒé‡å’Œä¸º1
        total_weight = sum(weights.values())
        if abs(total_weight - 1.0) > 0.001:
            logger.warning(f"æƒé‡å’Œä¸ä¸º1 ({total_weight}), æ­£åœ¨å½’ä¸€åŒ–")
            for key in weights:
                weights[key] /= total_weight
        
        # è®¡ç®—ç»¼åˆè¯„åˆ†
        total_score = (
            scores["liquidity"] * weights['liquidity'] +
            scores["risk"] * weights['risk'] +
            scores["return"] * weights['return'] +
            scores["sentiment"] * weights['sentiment'] +
            scores["fundamental"] * weights['fundamental']
        )
        
        # åŒé‡éªŒè¯ï¼šç¡®ä¿æœ€ç»ˆè¯„åˆ†åœ¨0-100èŒƒå›´å†…
        total_score = max(0, min(100, total_score))
        
        # å¯¹æ–°ä¸Šå¸‚ETFåº”ç”¨æƒ©ç½šå› å­
        if is_new_etf and days_since_listing < 15:
            penalty_factor = 0.8 - (days_since_listing * 0.02)
            total_score = max(0, total_score * penalty_factor)
            logger.info(f"ETF {etf_code} ä¸ºæ–°ä¸Šå¸‚ETFï¼Œåº”ç”¨æƒ©ç½šå› å­ï¼Œæœ€ç»ˆè¯„åˆ†: {total_score:.2f}")
        
        logger.debug(f"ETF {etf_code} è¯„åˆ†è¯¦æƒ…: " +
                     f"æµåŠ¨æ€§={scores['liquidity']:.2f}({weights['liquidity']*100:.0f}%), " +
                     f"é£é™©={scores['risk']:.2f}({weights['risk']*100:.0f}%), " +
                     f"æ”¶ç›Š={scores['return']:.2f}({weights['return']*100:.0f}%), " +
                     f"æƒ…ç·’={scores['sentiment']:.2f}({weights['sentiment']*100:.0f}%), " +
                     f"åŸºæœ¬é¢={scores['fundamental']:.2f}({weights['fundamental']*100:.0f}%), " +
                     f"ç»¼åˆ={total_score:.2f}")
        
        return round(total_score, 2)
    
    except Exception as e:
        error_msg = f"è®¡ç®—ETF {etf_code} è¯„åˆ†å¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        # å‘é€é”™è¯¯é€šçŸ¥
        try:
            send_wechat_message(message=error_msg, message_type="error")
        except Exception as send_error:
            logger.error(f"å‘é€é”™è¯¯é€šçŸ¥å¤±è´¥: {str(send_error)}", exc_info=True)
        return 0.0

def calculate_component_stability_score(etf_code: str, df: pd.DataFrame) -> float:
    """
    è®¡ç®—æˆåˆ†è‚¡ç¨³å®šæ€§è¯„åˆ†
    
    Args:
        etf_code: ETFä»£ç 
        df: ETFæ—¥çº¿æ•°æ®
    
    Returns:
        float: æˆåˆ†è‚¡ç¨³å®šæ€§è¯„åˆ† (0-100)
    """
    try:
        if df is None or df.empty:
            logger.warning(f"ETF {etf_code} æ— æ—¥çº¿æ•°æ®ï¼Œæ— æ³•è®¡ç®—æˆåˆ†è‚¡ç¨³å®šæ€§è¯„åˆ†")
            return 70.0  # é»˜è®¤ä¸­ç­‰åé«˜è¯„åˆ†
        
        # åˆ›å»ºDataFrameçš„å‰¯æœ¬ï¼Œé¿å…SettingWithCopyWarning
        df = df.copy(deep=True)
        
        # è®¡ç®—æ³¢åŠ¨ç‡
        volatility = calculate_volatility(df)
        
        # æ³¢åŠ¨ç‡è¯„åˆ†ï¼ˆè¶Šä½è¶Šå¥½ï¼‰ï¼šæ³¢åŠ¨ç‡â‰¤0.1=100åˆ†ï¼Œ0.3=50åˆ†ï¼Œâ‰¥0.5=0åˆ†
        component_score = max(0, 100 - (volatility * 200))
        
        # è€ƒè™‘ETFè§„æ¨¡ï¼ˆè§„æ¨¡è¶Šå¤§ï¼Œæˆåˆ†è‚¡ç¨³å®šæ€§é€šå¸¸è¶Šé«˜ï¼‰
        size, _ = get_etf_basic_info(etf_code)
        size_score = min(max(size * 0.5, 0), 100)
        
        # ç»¼åˆè¯„åˆ†ï¼ˆæ³¢åŠ¨ç‡å 70%ï¼Œè§„æ¨¡å 30%ï¼‰
        total_score = component_score * 0.7 + size_score * 0.3
        total_score = max(0, min(100, total_score))
        
        logger.debug(f"ETF {etf_code} æˆåˆ†è‚¡ç¨³å®šæ€§è¯„åˆ†: {total_score:.2f} (æ³¢åŠ¨ç‡: {volatility:.4f}, è§„æ¨¡: {size}äº¿å…ƒ)")
        return total_score
    
    except Exception as e:
        logger.error(f"è®¡ç®—ETF {etf_code} æˆåˆ†è‚¡ç¨³å®šæ€§è¯„åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        return 70.0  # é»˜è®¤ä¸­ç­‰åé«˜è¯„åˆ†

def calculate_arbitrage_score(
    etf_code: str,
    etf_name: str,
    premium_discount: float,
    market_price: float,
    iopv: float,
    fund_size: float,
    avg_volume: float,
    historical_data: Optional[pd.DataFrame] = None,
    listing_date: Optional[str] = None
) -> float:
    """
    è®¡ç®—ETFå¥—åˆ©ç»¼åˆè¯„åˆ†
    
    Args:
        etf_code: ETFä»£ç 
        etf_name: ETFåç§°
        premium_discount: æŠ˜æº¢ä»·ç‡ï¼ˆæ ‡é‡å€¼ï¼Œä¸æ˜¯Seriesï¼‰
        market_price: å¸‚åœºä»·æ ¼
        iopv: IOPVå‡€å€¼
        fund_size: åŸºé‡‘è§„æ¨¡
        avg_volume: æ—¥å‡æˆäº¤é¢
        historical_data: å†å²æ•°æ®ï¼ˆå¯é€‰ï¼‰
        listing_date: ä¸Šå¸‚æ—¥æœŸï¼ˆå¯é€‰ï¼‰
    
    Returns:
        float: ç»¼åˆè¯„åˆ† (0-100)
    """
    try:
        # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
        MAX_DISCOUNT = -20.0  # æœ€å¤§æŠ˜ä»·ç‡ï¼ˆ-20%ï¼‰
        MAX_PREMIUM = 20.0    # æœ€å¤§æº¢ä»·ç‡ï¼ˆ20%ï¼‰
        premium_discount = max(min(premium_discount, MAX_PREMIUM), MAX_DISCOUNT)
        
        # è®°å½•å®é™…ä½¿ç”¨çš„å€¼
        logger.debug(f"ETF {etf_code} å®é™…ä½¿ç”¨çš„æŠ˜æº¢ä»·ç‡: {premium_discount:.2f}%")
        
        # è®¡ç®—åŸºç¡€ETFè¯„åˆ†
        base_score = 70.0  # é»˜è®¤å€¼ï¼Œå®é™…åº”ä»å†å²æ•°æ®è®¡ç®—
        if historical_data is not None and not historical_data.empty:
            base_score = calculate_etf_score(etf_code, historical_data)
        
        # ç¡®ä¿åŸºç¡€è¯„åˆ†åœ¨0-100èŒƒå›´å†…
        if base_score < 0 or base_score > 100:
            logger.warning(f"ETF {etf_code} åŸºç¡€è¯„åˆ†è¶…å‡ºèŒƒå›´({base_score:.2f})ï¼Œå¼ºåˆ¶é™åˆ¶åœ¨0-100")
            base_score = max(0, min(100, base_score))
        
        # è®¡ç®—æˆåˆ†è‚¡ç¨³å®šæ€§è¯„åˆ†
        component_score = calculate_component_stability_score(etf_code, historical_data)
        
        # ç¡®ä¿æˆåˆ†è‚¡ç¨³å®šæ€§è¯„åˆ†åœ¨0-100èŒƒå›´å†…
        if component_score < 0 or component_score > 100:
            logger.warning(f"ETF {etf_code} æˆåˆ†è‚¡ç¨³å®šæ€§è¯„åˆ†è¶…å‡ºèŒƒå›´({component_score:.2f})ï¼Œå¼ºåˆ¶é™åˆ¶åœ¨0-100")
            component_score = max(0, min(100, component_score))
        
        # è®¡ç®—æŠ˜æº¢ä»·ç‡è¯„åˆ†
        premium_score = 50.0  # é»˜è®¤å€¼
        
        # ============== æ–°å¢ï¼šé™„åŠ æ¡ä»¶åŠ åˆ† ==============
        # 1. è¿ç»­2å¤©æŠ˜ä»·ï¼šé¢å¤–+10åˆ†
        consecutive_discount_bonus = 0
        if premium_discount < 0 and historical_data is not None and not historical_data.empty:
            # ç¡®ä¿æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®
            if len(historical_data) >= 2:
                # è·å–å‰ä¸€å¤©çš„æŠ˜æº¢ä»·ç‡
                prev_premium = historical_data["æŠ˜æº¢ä»·ç‡"].iloc[-2]
                # æ£€æŸ¥å‰ä¸€å¤©æ˜¯å¦ä¹Ÿæ˜¯æŠ˜ä»·
                if prev_premium < 0:
                    consecutive_discount_bonus = 10
                    logger.debug(f"ETF {etf_code} è¿ç»­2å¤©æŠ˜ä»·ï¼Œè·å¾—è¿ç»­æŠ˜ä»·åŠ åˆ†: +{consecutive_discount_bonus}åˆ†")
        
        # 2. æŠ˜ä»·å¹…åº¦å¤§äºè¡Œä¸šå¹³å‡ï¼šé¢å¤–+5åˆ†
        industry_avg_bonus = 0
        if premium_discount < 0:
            # ä»é…ç½®ä¸­è·å–è¡Œä¸šå¹³å‡æŠ˜ä»·ç‡ï¼ˆè´Ÿå€¼ï¼‰
            industry_avg_discount = getattr(Config, 'INDUSTRY_AVG_DISCOUNT', -0.15)
            # å¦‚æœå½“å‰æŠ˜ä»·ç‡å°äºè¡Œä¸šå¹³å‡ï¼ˆå³æŠ˜ä»·å¹…åº¦æ›´å¤§ï¼‰
            if premium_discount < industry_avg_discount:
                industry_avg_bonus = 5
                logger.debug(f"ETF {etf_code} æŠ˜ä»·å¹…åº¦({premium_discount:.2f}%)å¤§äºè¡Œä¸šå¹³å‡({industry_avg_discount:.2f}%)ï¼Œè·å¾—è¡Œä¸šå¹³å‡åŠ åˆ†: +{industry_avg_bonus}åˆ†")
        
        # å°†åˆé™„åŠ æ¡ä»¶åŠ åˆ†åˆ°åŸºç¡€è¯„åˆ†ä¸­
        base_score = min(100, base_score + consecutive_discount_bonus + industry_avg_bonus)
        logger.debug(f"ETF {etf_code} é™„åŠ æ¡ä»¶åŠ åˆ†: è¿ç»­æŠ˜ä»·+{consecutive_discount_bonus}åˆ†, è¡Œä¸šå¹³å‡+{industry_avg_bonus}åˆ†, è°ƒæ•´ååŸºç¡€è¯„åˆ†={base_score:.2f}")
        # ============== æ–°å¢ç»“æŸ ==============
        
        # æŠ˜ä»·æƒ…å†µ
        if premium_discount < 0:
            abs_premium = abs(premium_discount)
            if abs_premium >= Config.DISCOUNT_THRESHOLD * 1.5:
                premium_score = 100.0
            elif abs_premium >= Config.DISCOUNT_THRESHOLD:
                # ç¡®ä¿åˆ†æ¯ä¸ä¸º0
                if Config.DISCOUNT_THRESHOLD * 0.5 > 0:
                    premium_score = 80.0 + (abs_premium - Config.DISCOUNT_THRESHOLD) * 20.0 / (Config.DISCOUNT_THRESHOLD * 0.5)
                else:
                    premium_score = 100.0
            else:
                # ç¡®ä¿åˆ†æ¯ä¸ä¸º0
                if Config.DISCOUNT_THRESHOLD > 0:
                    premium_score = 50.0 + (abs_premium * 30.0 / Config.DISCOUNT_THRESHOLD)
                else:
                    premium_score = 50.0 + (abs_premium * 30.0)
        # æº¢ä»·æƒ…å†µ
        else:
            if premium_discount <= Config.PREMIUM_THRESHOLD * 0.5:
                premium_score = 100.0
            elif premium_discount <= Config.PREMIUM_THRESHOLD:
                # ç¡®ä¿åˆ†æ¯ä¸ä¸º0
                if Config.PREMIUM_THRESHOLD * 0.5 > 0:
                    premium_score = 80.0 - (premium_discount - Config.PREMIUM_THRESHOLD * 0.5) * 40.0 / (Config.PREMIUM_THRESHOLD * 0.5)
                else:
                    premium_score = 100.0
            else:
                # ç¡®ä¿åˆ†æ¯ä¸ä¸º0
                if Config.PREMIUM_THRESHOLD > 0:
                    premium_score = 50.0 - (premium_discount - Config.PREMIUM_THRESHOLD) * 20.0 / (Config.PREMIUM_THRESHOLD * 1.0)
                else:
                    premium_score = 50.0 - (premium_discount * 20.0)
        
        # ç¡®ä¿æŠ˜æº¢ä»·ç‡è¯„åˆ†åœ¨0-100èŒƒå›´å†…
        if premium_score < 0 or premium_score > 100:
            logger.warning(f"ETF {etf_code} æŠ˜æº¢ä»·ç‡è¯„åˆ†è¶…å‡ºèŒƒå›´({premium_score:.2f})ï¼Œå¼ºåˆ¶é™åˆ¶åœ¨0-100")
            premium_score = max(0, min(100, premium_score))
        
        # è·å–è¯„åˆ†æƒé‡
        weights = Config.ARBITRAGE_SCORE_WEIGHTS.copy()
        
        # ç¡®ä¿æƒé‡å­—å…¸åŒ…å«æ‰€æœ‰å¿…è¦çš„é”®
        required_keys = ['premium_discount', 'liquidity', 'risk', 'return', 'market_sentiment', 'fundamental', 'component_stability']
        for key in required_keys:
            if key not in weights:
                logger.warning(f"æƒé‡å­—å…¸ç¼ºå°‘å¿…è¦é”®: {key}, ä½¿ç”¨é»˜è®¤å€¼0.1")
                weights[key] = 0.1
        
        # ç¡®ä¿æƒé‡å’Œä¸º1
        total_weight = sum(weights.values())
        if abs(total_weight - 1.0) > 0.001:
            logger.warning(f"æƒé‡å’Œä¸ä¸º1 ({total_weight}), æ­£åœ¨å½’ä¸€åŒ–")
            for key in weights:
                weights[key] /= total_weight
        
        # éªŒè¯æ¯ä¸ªæƒé‡æ˜¯å¦åœ¨åˆç†èŒƒå›´å†…
        for key, weight in weights.items():
            if weight < 0 or weight > 1:
                logger.error(f"æƒé‡ {key} è¶…å‡ºèŒƒå›´({weight:.2f})ï¼Œå¼ºåˆ¶é™åˆ¶åœ¨0-1")
                weights[key] = max(0, min(1, weight))
        
        # ç»¼åˆè¯„åˆ†ï¼ˆåŠ æƒå¹³å‡ï¼‰
        total_score = (
            base_score * (weights['liquidity'] + weights['risk'] + weights['return'] + weights['market_sentiment'] + weights['fundamental']) +
            component_score * weights['component_stability'] +
            premium_score * weights['premium_discount']
        )
        
        # åŒé‡éªŒè¯ï¼šç¡®ä¿è¯„åˆ†åœ¨0-100èŒƒå›´å†…
        if total_score < 0 or total_score > 100:
            logger.error(f"ETF {etf_code} å¥—åˆ©ç»¼åˆè¯„åˆ†è¶…å‡ºèŒƒå›´({total_score:.2f})ï¼Œå¼ºåˆ¶é™åˆ¶åœ¨0-100")
            total_score = max(0, min(100, total_score))
        
        # æ·»åŠ è¯¦ç»†æ—¥å¿—ï¼Œä¾¿äºé—®é¢˜æ’æŸ¥
        logger.debug(f"ETF {etf_code} å¥—åˆ©ç»¼åˆè¯„åˆ†è¯¦æƒ…: " +
                     f"åŸºç¡€è¯„åˆ†={base_score:.2f}(æƒé‡{weights['liquidity'] + weights['risk'] + weights['return'] + weights['market_sentiment'] + weights['fundamental']:.2f}), " +
                     f"æˆåˆ†è‚¡ç¨³å®šæ€§={component_score:.2f}(æƒé‡{weights['component_stability']:.2f}), " +
                     f"æŠ˜æº¢ä»·ç‡={premium_score:.2f}(æƒé‡{weights['premium_discount']:.2f}), " +
                     f"è¿ç»­æŠ˜ä»·åŠ åˆ†={consecutive_discount_bonus}, " +
                     f"è¡Œä¸šå¹³å‡åŠ åˆ†={industry_avg_bonus}, " +
                     f"æœ€ç»ˆè¯„åˆ†={total_score:.2f}")
        
        return total_score
    
    except Exception as e:
        logger.error(f"è®¡ç®—ETF {etf_code} å¥—åˆ©ç»¼åˆè¯„åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        return 0.0

def get_top_rated_etfs(
    top_n=None, 
    min_score=60, 
    min_fund_size=10.0, 
    min_avg_volume=5000.0
) -> pd.DataFrame:
    """
    ä»å…¨å¸‚åœºETFä¸­ç­›é€‰é«˜åˆ†ETF
    
    Args:
        top_n: è¿”å›å‰Nåï¼Œä¸ºNoneåˆ™è¿”å›æ‰€æœ‰é«˜äºmin_scoreçš„ETF
        min_score: æœ€ä½è¯„åˆ†é˜ˆå€¼
        min_fund_size: æœ€å°åŸºé‡‘è§„æ¨¡(äº¿å…ƒ)
        min_avg_volume: æœ€å°æ—¥å‡æˆäº¤é¢(ä¸‡å…ƒ)
    
    Returns:
        pd.DataFrame: åŒ…å«ETFä»£ç ã€åç§°ã€è¯„åˆ†ç­‰ä¿¡æ¯çš„DataFrame
    """
    try:
        metadata_df = load_etf_metadata()
        
        if metadata_df is None or metadata_df.empty:
            logger.warning("å…ƒæ•°æ®ä¸ºç©ºï¼Œæ— æ³•è·å–ETFåˆ—è¡¨")
            return pd.DataFrame()
        
        all_codes = metadata_df["etf_code"].tolist()
        if not all_codes:
            logger.warning("å…ƒæ•°æ®ä¸­æ— ETFä»£ç ")
            return pd.DataFrame()
        
        score_list = []
        logger.info(f"å¼€å§‹è®¡ç®— {len(all_codes)} åªETFçš„ç»¼åˆè¯„åˆ†...")
        
        for etf_code in all_codes:
            try:
                df = load_etf_daily_data(etf_code)
                if df.empty:
                    logger.debug(f"ETF {etf_code} æ— æ—¥çº¿æ•°æ®ï¼Œè·³è¿‡è¯„åˆ†")
                    continue
                
                # ç¡®ä¿ETFä»£ç æ ¼å¼ä¸€è‡´ï¼ˆ6ä½æ•°å­—ï¼‰
                etf_code = str(etf_code).strip().zfill(6)
                
                # è®¡ç®—ETFè¯„åˆ†
                score = calculate_etf_score(etf_code, df)
                if score < min_score:
                    continue
                
                # è·å–ETFåŸºæœ¬ä¿¡æ¯ï¼ˆä»æœ¬åœ°å…ƒæ•°æ®è·å–ï¼‰
                size = 0.0
                listing_date = ""
                
                size = metadata_df[metadata_df["etf_code"] == etf_code]["size"].values[0]
                listing_date = metadata_df[metadata_df["etf_code"] == etf_code]["listing_date"].values[0]
                etf_name = get_etf_name(etf_code)
                
                # è®¡ç®—æ—¥å‡æˆäº¤é¢
                avg_volume = 0.0
                if AMOUNT_COL in df.columns:
                    recent_30d = df.tail(30)
                    if len(recent_30d) > 0:
                        # ä¿®å¤ï¼šä¸å†è¿›è¡Œå•ä½è½¬æ¢ï¼Œå› ä¸ºdata_crawlerä¸­å·²ç»Ÿä¸€è½¬æ¢ä¸º"ä¸‡å…ƒ"
                        avg_volume = recent_30d[AMOUNT_COL].mean()
                
                # ä»…ä¿ç•™æ»¡è¶³æ¡ä»¶çš„ETF
                if size >= min_fund_size and avg_volume >= min_avg_volume:
                    score_list.append({
                        "ETFä»£ç ": etf_code,
                        "ETFåç§°": etf_name,
                        "è¯„åˆ†": score,
                        "è§„æ¨¡": size,
                        "æ—¥å‡æˆäº¤é¢": avg_volume,
                        "ä¸Šå¸‚æ—¥æœŸ": listing_date
                    })
                
                logger.debug(f"ETF {etf_code} è¯„åˆ†: {score}, è§„æ¨¡: {size}äº¿å…ƒ, æ—¥å‡æˆäº¤é¢: {avg_volume}ä¸‡å…ƒ")
            except Exception as e:
                logger.error(f"å¤„ç†ETF {etf_code} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}", exc_info=True)
                continue
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¬¦åˆæ¡ä»¶çš„ETF
        if not score_list:
            warning_msg = (f"æ²¡æœ‰ETFè¾¾åˆ°æœ€ä½è¯„åˆ†é˜ˆå€¼ {min_score}ï¼Œ" +
                           f"æˆ–æœªæ»¡è¶³è§„æ¨¡({min_fund_size}äº¿å…ƒ)å’Œæ—¥å‡æˆäº¤é¢({min_avg_volume}ä¸‡å…ƒ)è¦æ±‚")
            logger.info(warning_msg)
            return pd.DataFrame()
        
        # åˆ›å»ºè¯„åˆ†DataFrame
        score_df = pd.DataFrame(score_list).sort_values("è¯„åˆ†", ascending=False)
        total_etfs = len(score_df)
        
        # è®¡ç®—å‰X%çš„ETFæ•°é‡
        top_percent = Config.SCORE_TOP_PERCENT
        top_count = max(10, int(total_etfs * top_percent / 100))
        
        # è®°å½•ç­›é€‰ç»“æœ
        logger.info(f"è¯„åˆ†å®Œæˆã€‚å…±{total_etfs}åªETFè¯„åˆ†â‰¥{min_score}ï¼Œå–å‰{top_percent}%({top_count}åª)")
        logger.info(f"åº”ç”¨ç­›é€‰å‚æ•°: è§„æ¨¡â‰¥{min_fund_size}äº¿å…ƒ, æ—¥å‡æˆäº¤é¢â‰¥{min_avg_volume}ä¸‡å…ƒ")
        
        # è¿”å›ç»“æœ
        if top_n is not None and top_n > 0:
            return score_df.head(top_n)
        return score_df.head(top_count)
    
    except Exception as e:
        error_msg = f"è·å–é«˜åˆ†ETFåˆ—è¡¨æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"
        logger.error(error_msg, exc_info=True)
        # å‘é€é”™è¯¯é€šçŸ¥
        send_wechat_message(message=error_msg, message_type="error")
        return pd.DataFrame()

def get_etf_score_history(etf_code: str, days: int = 30) -> pd.DataFrame:
    """
    è·å–ETFå†å²è¯„åˆ†æ•°æ®
    
    Args:
        etf_code: ETFä»£ç 
        days: æŸ¥è¯¢å¤©æ•°
    
    Returns:
        pd.DataFrame: è¯„åˆ†å†å²æ•°æ®
    """
    try:
        history = []
        beijing_now = get_beijing_time()
        
        for i in range(days):
            date = (beijing_now - timedelta(days=i)).date().strftime("%Y-%m-%d")
            score_file = os.path.join(Config.SCORE_HISTORY_DIR, f"{etf_code}_{date}.json")
            
            if os.path.exists(score_file):
                try:
                    with open(score_file, 'r') as f:
                        score_data = json.load(f)
                    history.append({
                        "æ—¥æœŸ": date,
                        "è¯„åˆ†": score_data.get("score", 0.0),
                        "æ’å": score_data.get("rank", 0)
                    })
                except Exception as e:
                    logger.error(f"è¯»å–è¯„åˆ†å†å²æ–‡ä»¶ {score_file} å¤±è´¥: {str(e)}")
        
        if not history:
            logger.info(f"æœªæ‰¾åˆ°ETF {etf_code} çš„è¯„åˆ†å†å²æ•°æ®")
            return pd.DataFrame()
        
        return pd.DataFrame(history)
    
    except Exception as e:
        error_msg = f"è·å–ETF {etf_code} è¯„åˆ†å†å²æ•°æ®å¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        # å‘é€é”™è¯¯é€šçŸ¥
        send_wechat_message(message=error_msg, message_type="error")
        return pd.DataFrame()

def analyze_etf_score_trend(etf_code: str) -> str:
    """
    åˆ†æETFè¯„åˆ†è¶‹åŠ¿
    
    Args:
        etf_code: ETFä»£ç 
    
    Returns:
        str: åˆ†æç»“æœ
    """
    try:
        # è·å–è¯„åˆ†å†å²
        history_df = get_etf_score_history(etf_code)
        if history_df.empty:
            return f"ã€{etf_code} è¯„åˆ†è¶‹åŠ¿ã€‘\nâ€¢ æ— å†å²è¯„åˆ†æ•°æ®"
        
        # è®¡ç®—è¶‹åŠ¿
        latest_score = history_df.iloc[0]["è¯„åˆ†"]
        avg_score = history_df["è¯„åˆ†"].mean()
        trend = "ä¸Šå‡" if latest_score > avg_score else "ä¸‹é™"
        
        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        report = f"ã€{etf_code} è¯„åˆ†è¶‹åŠ¿ã€‘\n"
        report += f"â€¢ å½“å‰è¯„åˆ†: {latest_score:.2f}\n"
        report += f"â€¢ è¿‘æœŸå¹³å‡è¯„åˆ†: {avg_score:.2f}\n"
        report += f"â€¢ è¯„åˆ†è¶‹åŠ¿: {trend}\n"
        
        # æ·»åŠ å»ºè®®
        if trend == "ä¸Šå‡":
            report += "ğŸ’¡ å»ºè®®ï¼šè¯„åˆ†æŒç»­ä¸Šå‡ï¼Œå¯å…³æ³¨è¯¥ETF"
        else:
            report += "ğŸ’¡ å»ºè®®ï¼šè¯„åˆ†æŒç»­ä¸‹é™ï¼Œéœ€è°¨æ…è€ƒè™‘"
        
        return report
    
    except Exception as e:
        error_msg = f"åˆ†æETF {etf_code} è¯„åˆ†è¶‹åŠ¿å¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        # å‘é€é”™è¯¯é€šçŸ¥
        send_wechat_message(message=error_msg, message_type="error")
        return f"ã€{etf_code} è¯„åˆ†è¶‹åŠ¿ã€‘\nâ€¢ åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—"

# æ¨¡å—åˆå§‹åŒ–
try:
    # ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨
    Config.init_dirs()
    
    # æ£€æŸ¥ETFåˆ—è¡¨æ˜¯å¦è¿‡æœŸ
    if is_file_outdated(Config.ALL_ETFS_PATH, Config.ETF_LIST_UPDATE_INTERVAL):
        warning_msg = "ETFåˆ—è¡¨å·²è¿‡æœŸï¼Œè¯„åˆ†ç³»ç»Ÿå¯èƒ½ä½¿ç”¨æ—§æ•°æ®"
        logger.warning(warning_msg)
        # å‘é€è­¦å‘Šé€šçŸ¥
        send_wechat_message(message=warning_msg, message_type="error")
    
    # åˆå§‹åŒ–æ—¥å¿—
    logger.info("ETFè¯„åˆ†ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
except Exception as e:
    error_msg = f"ETFè¯„åˆ†ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}"
    logger.error(error_msg, exc_info=True)
    
    try:
        # é€€å›åˆ°åŸºç¡€æ—¥å¿—é…ç½®
        logging.basicConfig(
            level="INFO",
            format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
            handlers=[logging.StreamHandler()]
        )
        logging.error(error_msg)
    except Exception as basic_log_error:
        print(f"åŸºç¡€æ—¥å¿—é…ç½®å¤±è´¥: {str(basic_log_error)}")
        print(error_msg)
    
    # å‘é€é”™è¯¯é€šçŸ¥
    try:
        send_wechat_message(message=error_msg, message_type="error")
    except Exception as send_error:
        logger.error(f"å‘é€é”™è¯¯é€šçŸ¥å¤±è´¥: {str(send_error)}", exc_info=True)
