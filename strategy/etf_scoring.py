#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ETFè¯„åˆ†ç³»ç»Ÿ
åŸºäºå¤šç»´åº¦æŒ‡æ ‡å¯¹ETFè¿›è¡Œç»¼åˆè¯„åˆ†
ç‰¹åˆ«ä¼˜åŒ–äº†æ¶ˆæ¯æ¨é€æ ¼å¼ï¼Œç¡®ä¿ä½¿ç”¨ç»Ÿä¸€çš„æ¶ˆæ¯æ¨¡æ¿
"""

import pandas as pd
import numpy as np
import logging
import os
import json
import time
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional, Tuple, Union
from config import Config
from utils.date_utils import (
    get_current_times,
    get_beijing_time,
    get_utc_time,
    is_file_outdated
)
from utils.file_utils import load_etf_daily_data, load_etf_metadata, ensure_chinese_columns
from data_crawler.all_etfs import get_all_etf_codes, get_etf_name
from wechat_push.push import send_wechat_message

# åˆå§‹åŒ–æ—¥å¿—
logger = logging.getLogger(__name__)

# å¸¸é‡å®šä¹‰
DATE_COL = "æ—¥æœŸ" if "æ—¥æœŸ" in Config.STANDARD_COLUMNS else "date"
CLOSE_COL = "æ”¶ç›˜" if "æ”¶ç›˜" in Config.STANDARD_COLUMNS else "close"
AMOUNT_COL = "æˆäº¤é¢" if "æˆäº¤é¢" in Config.STANDARD_COLUMNS else "amount"
ETF_CODE_COL = "ETFä»£ç "
FUND_SIZE_COL = "åŸºé‡‘è§„æ¨¡"

def extract_scalar_value(value, default=0.0, log_prefix=""):
    """
    å®‰å…¨åœ°ä»å„ç§ç±»å‹ä¸­æå–æ ‡é‡å€¼
    
    Args:
        value: å¯èƒ½æ˜¯æ ‡é‡ã€Seriesã€DataFrameã€å­—ç¬¦ä¸²ç­‰
        default: é»˜è®¤å€¼ï¼Œå¦‚æœæ— æ³•æå–æ ‡é‡å€¼
        log_prefix: æ—¥å¿—å‰ç¼€ï¼Œç”¨äºæ ‡è¯†è°ƒç”¨ä½ç½®
    
    Returns:
        float: æ ‡é‡å€¼
    """
    try:
        # å¦‚æœå·²ç»æ˜¯æ ‡é‡å€¼ï¼Œç›´æ¥è¿”å›
        if isinstance(value, (int, float)):
            return float(value)
        
        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è½¬æ¢ä¸ºæµ®ç‚¹æ•°
        if isinstance(value, str):
            # å°è¯•ç§»é™¤éæ•°å­—å­—ç¬¦
            cleaned_str = ''.join(c for c in value if c.isdigit() or c in ['.', '-'])
            if cleaned_str:
                result = float(cleaned_str)
                logger.debug(f"{log_prefix}ä»å­—ç¬¦ä¸²æå–æ ‡é‡å€¼: '{value}' -> {result}")
                return result
            logger.warning(f"{log_prefix}æ— æ³•ä»å­—ç¬¦ä¸² '{value}' æå–æœ‰æ•ˆæ•°å­—ï¼Œä½¿ç”¨é»˜è®¤å€¼{default}")
            return default
        
        # å¦‚æœæ˜¯pandaså¯¹è±¡ï¼Œå°è¯•æå–æ ‡é‡å€¼
        if isinstance(value, (pd.Series, pd.DataFrame)):
            # å°è¯•è·å–ç¬¬ä¸€ä¸ªå€¼
            if value.size > 0:
                # å°è¯•ä½¿ç”¨.values.flatten()[0]ï¼ˆæœ€å¯é ï¼‰
                try:
                    result = float(value.values.flatten()[0])
                    logger.debug(f"{log_prefix}é€šè¿‡.values.flatten()[0]æå–æ ‡é‡å€¼: {result}")
                    return result
                except Exception as e:
                    # å°è¯•ä½¿ç”¨.item()
                    try:
                        result = float(value.item())
                        logger.debug(f"{log_prefix}é€šè¿‡.item()æå–æ ‡é‡å€¼: {result}")
                        return result
                    except Exception as e2:
                        # å°è¯•ä½¿ç”¨.iloc[0]
                        try:
                            valid_values = value[~pd.isna(value)]
                            if not valid_values.empty:
                                result = float(valid_values.iloc[0])
                                logger.debug(f"{log_prefix}é€šè¿‡.iloc[0]æå–æ ‡é‡å€¼: {result}")
                                return result
                        except Exception as e3:
                            pass
            
            logger.error(f"{log_prefix}æ— æ³•ä»pandaså¯¹è±¡æå–æ ‡é‡å€¼(size={value.size})ï¼Œä½¿ç”¨é»˜è®¤å€¼{default}")
            return default
        
        # å°è¯•ç›´æ¥è½¬æ¢ä¸ºæµ®ç‚¹æ•°
        result = float(value)
        logger.debug(f"{log_prefix}ç›´æ¥è½¬æ¢ä¸ºæµ®ç‚¹æ•°: {result}")
        return result
    
    except Exception as e:
        logger.error(f"{log_prefix}æ— æ³•ä»ç±»å‹ {type(value)} ä¸­æå–æ ‡é‡å€¼: {str(e)}ï¼Œä½¿ç”¨é»˜è®¤å€¼{default}")
        return default

def calculate_liquidity_score(df: pd.DataFrame) -> float:
    """
    è®¡ç®—æµåŠ¨æ€§è¯„åˆ†ï¼ˆ0-100åˆ†ï¼Œåˆ†æ•°è¶Šé«˜è¡¨ç¤ºæµåŠ¨æ€§è¶Šå¥½ï¼‰
    
    Args:
        df: ETFæ—¥çº¿æ•°æ®
    
    Returns:
        float: æµåŠ¨æ€§è¯„åˆ†
    """
    try:
        # åˆ›å»ºDataFrameçš„æ·±æ‹·è´ - è¿™æ˜¯å…³é”®ä¿®å¤ç‚¹
        df = df.copy(deep=True)
        
        # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®
        if len(df) < 30:
            logger.warning(f"æ•°æ®é‡ä¸è¶³({len(df)}å¤©)ï¼ŒæµåŠ¨æ€§è¯„åˆ†å¯èƒ½ä¸å‡†ç¡®")
        
        # ç¡®ä¿ä½¿ç”¨ä¸­æ–‡åˆ—å
        df = ensure_chinese_columns(df)
        
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        required_columns = ["æ—¥æœŸ", "æ”¶ç›˜", "æˆäº¤é¢"]
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            logger.error(f"æµåŠ¨æ€§è¯„åˆ†æ‰€éœ€åˆ—ç¼ºå¤±: {', '.join(missing_columns)}")
            return 50.0  # è¿”å›é»˜è®¤å€¼
        
        # è®¡ç®—æ—¥å‡æˆäº¤é¢ï¼ˆå•ä½ï¼šä¸‡å…ƒï¼‰
        avg_volume = 0.0
        if AMOUNT_COL in df.columns:
            # å–æœ€è¿‘30å¤©æ•°æ®
            recent_30d = df.tail(30)
            if len(recent_30d) > 0:
                # ç¡®ä¿æˆäº¤é¢åˆ—æ˜¯æ•°å€¼ç±»å‹
                if not pd.api.types.is_numeric_dtype(recent_30d[AMOUNT_COL]):
                    # ä½¿ç”¨.locç¡®ä¿å®‰å…¨èµ‹å€¼
                    recent_30d = recent_30d.copy()
                    recent_30d.loc[:, AMOUNT_COL] = pd.to_numeric(recent_30d[AMOUNT_COL], errors='coerce')
                
                avg_volume = recent_30d[AMOUNT_COL].mean()
        
        # æµåŠ¨æ€§è¯„åˆ†æ ‡å‡†ï¼š
        # 1000ä¸‡ä»¥ä¸‹ï¼š30-50åˆ†
        # 1000-5000ä¸‡ï¼š50-75åˆ†
        # 5000-10000ä¸‡ï¼š75-90åˆ†
        # 10000ä¸‡ä»¥ä¸Šï¼š90-100åˆ†
        if avg_volume <= 1000:
            score = 30 + (avg_volume / 1000) * 20
        elif avg_volume <= 5000:
            score = 50 + ((avg_volume - 1000) / 4000) * 25
        elif avg_volume <= 10000:
            score = 75 + ((avg_volume - 5000) / 5000) * 15
        else:
            score = 90 + min((avg_volume - 10000) / 10000, 10)
        
        logger.debug(f"ETFæµåŠ¨æ€§è¯„åˆ†: {score:.2f} (æ—¥å‡æˆäº¤é¢: {avg_volume:.2f}ä¸‡å…ƒ)")
        return score
    
    except Exception as e:
        logger.error(f"è®¡ç®—æµåŠ¨æ€§å¾—åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        return 50.0

def calculate_risk_score(df: pd.DataFrame) -> float:
    """
    è®¡ç®—é£é™©è¯„åˆ†ï¼ˆ0-100åˆ†ï¼Œåˆ†æ•°è¶Šé«˜é£é™©è¶Šå¤§ï¼‰
    
    Args:
        df: ETFæ—¥çº¿æ•°æ®
    
    Returns:
        float: é£é™©è¯„åˆ†ï¼ˆ0-100åˆ†ï¼‰
    """
    try:
        # åˆ›å»ºDataFrameçš„æ·±æ‹·è´
        df = df.copy(deep=True)
        
        # ç¡®ä¿ä½¿ç”¨ä¸­æ–‡åˆ—å
        df = ensure_chinese_columns(df)
        
        # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®
        if len(df) < 30:
            logger.warning(f"æ•°æ®é‡ä¸è¶³({len(df)}å¤©)ï¼Œé£é™©è¯„åˆ†å¯èƒ½ä¸å‡†ç¡®")
        
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        required_columns = ["æ—¥æœŸ", "æ”¶ç›˜"]
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            logger.error(f"é£é™©è¯„åˆ†æ‰€éœ€åˆ—ç¼ºå¤±: {', '.join(missing_columns)}")
            return 50.0  # è¿”å›é»˜è®¤å€¼
        
        # è®¡ç®—æ³¢åŠ¨ç‡
        if CLOSE_COL in df.columns and len(df) > 1:
            # åˆ›å»ºå‰¯æœ¬ä»¥é¿å…SettingWithCopyWarning
            df = df.copy(deep=True)
            
            # ç¡®ä¿æ”¶ç›˜ä»·åˆ—æ˜¯æ•°å€¼ç±»å‹
            if not pd.api.types.is_numeric_dtype(df[CLOSE_COL]):
                df.loc[:, CLOSE_COL] = pd.to_numeric(df[CLOSE_COL], errors='coerce')
            
            # è®¡ç®—æ—¥æ”¶ç›Šç‡
            df.loc[:, "daily_return"] = df[CLOSE_COL].pct_change()
            
            # å¤„ç†NaNå€¼
            df = df.dropna(subset=["daily_return"])
            
            if not df.empty:
                volatility = df["daily_return"].std() * np.sqrt(252)  # å¹´åŒ–æ³¢åŠ¨ç‡
            else:
                volatility = 0.2  # é»˜è®¤æ³¢åŠ¨ç‡
            
            # æ³¢åŠ¨ç‡è¯„åˆ†ï¼ˆè¶Šä½è¶Šå¥½ï¼‰ï¼š
            # æ³¢åŠ¨ç‡â‰¤0.1=100åˆ†ï¼Œ0.2=75åˆ†ï¼Œ0.3=50åˆ†ï¼Œ0.4=25åˆ†ï¼Œâ‰¥0.5=0åˆ†
            if volatility <= 0.1:
                score = 100.0
            elif volatility <= 0.2:
                score = 100 - (volatility - 0.1) * 250
            elif volatility <= 0.3:
                score = 75 - (volatility - 0.2) * 250
            elif volatility <= 0.4:
                score = 50 - (volatility - 0.3) * 250
            else:
                score = 25 - (volatility - 0.4) * 250
            
            # ç¡®ä¿è¯„åˆ†åœ¨0-100èŒƒå›´å†…
            score = max(0, min(100, score))
        else:
            logger.warning("æ•°æ®ä¸­ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æ•°æ®é‡ä¸è¶³ï¼Œä½¿ç”¨é»˜è®¤é£é™©è¯„åˆ†")
            score = 50.0
        
        logger.debug(f"ETFé£é™©è¯„åˆ†: {score:.2f} (æ³¢åŠ¨ç‡: {volatility:.4f})")
        return score
    
    except Exception as e:
        logger.error(f"è®¡ç®—é£é™©å¾—åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        return 50.0

def calculate_return_score(df: pd.DataFrame) -> float:
    """
    è®¡ç®—æ”¶ç›Šèƒ½åŠ›è¯„åˆ†ï¼ˆ0-100åˆ†ï¼Œåˆ†æ•°è¶Šé«˜è¡¨ç¤ºæ”¶ç›Šèƒ½åŠ›è¶Šå¼ºï¼‰
    
    Args:
        df: ETFæ—¥çº¿æ•°æ®
    
    Returns:
        float: æ”¶ç›Šèƒ½åŠ›è¯„åˆ†
    """
    try:
        # åˆ›å»ºDataFrameçš„æ·±æ‹·è´
        df = df.copy(deep=True)
        
        # ç¡®ä¿ä½¿ç”¨ä¸­æ–‡åˆ—å
        df = ensure_chinese_columns(df)
        
        # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®
        if len(df) < 30:
            logger.warning(f"æ•°æ®é‡ä¸è¶³({len(df)}å¤©)ï¼Œæ”¶ç›Šè¯„åˆ†å¯èƒ½ä¸å‡†ç¡®")
        
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        required_columns = ["æ—¥æœŸ", "æ”¶ç›˜"]
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            logger.error(f"æ”¶ç›Šè¯„åˆ†æ‰€éœ€åˆ—ç¼ºå¤±: {', '.join(missing_columns)}")
            return 50.0  # è¿”å›é»˜è®¤å€¼
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…è¦åˆ—
        if CLOSE_COL not in df.columns:
            logger.error(f"æ•°æ®ä¸­ç¼ºå°‘å¿…è¦åˆ—: {CLOSE_COL}")
            return 50.0
        
        # ç¡®ä¿ä»·æ ¼åˆ—æ˜¯æ•°å€¼ç±»å‹
        if not pd.api.types.is_numeric_dtype(df[CLOSE_COL]):
            try:
                # ä½¿ç”¨.locç¡®ä¿å®‰å…¨èµ‹å€¼
                df.loc[:, CLOSE_COL] = pd.to_numeric(df[CLOSE_COL], errors='coerce')
                df = df.dropna(subset=[CLOSE_COL])
            except:
                logger.error(f"ä»·æ ¼åˆ— {CLOSE_COL} æ— æ³•è½¬æ¢ä¸ºæ•°å€¼ç±»å‹")
                return 50.0
        
        # è®¡ç®—å¹´åŒ–æ”¶ç›Šç‡
        if len(df) > 1:
            # è®¡ç®—æ€»æ”¶ç›Šç‡
            total_return = (df[CLOSE_COL].iloc[-1] / df[CLOSE_COL].iloc[0]) - 1
            
            # è®¡ç®—å¹´åŒ–æ”¶ç›Šç‡
            years = len(df) / 252
            if years > 0:
                annualized_return = (1 + total_return) ** (1 / years) - 1
            else:
                annualized_return = 0
            
            # æ”¶ç›Šç‡è¯„åˆ†æ ‡å‡†
            if annualized_return <= 0:
                score = 0.0
            elif annualized_return <= 0.02:
                score = annualized_return * 1500
            elif annualized_return <= 0.05:
                score = 30 + (annualized_return - 0.02) * 1000
            elif annualized_return <= 0.08:
                score = 60 + (annualized_return - 0.05) * 833.3
            else:
                score = 85 + min((annualized_return - 0.08) * 1000, 15)
            
            # ç¡®ä¿è¯„åˆ†åœ¨0-100èŒƒå›´å†…
            score = max(0, min(100, score))
        else:
            logger.warning("æ•°æ®ä¸­ç¼ºå°‘æ”¶ç›˜ä»·æˆ–æ•°æ®é‡ä¸è¶³ï¼Œä½¿ç”¨é»˜è®¤æ”¶ç›Šè¯„åˆ†")
            score = 50.0
        
        logger.debug(f"ETFæ”¶ç›Šè¯„åˆ†: {score:.2f} (å¹´åŒ–æ”¶ç›Šç‡: {annualized_return:.2%})")
        return score
    
    except Exception as e:
        logger.error(f"è®¡ç®—æ”¶ç›Šå¾—åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        return 50.0

def calculate_sentiment_score(df: pd.DataFrame) -> float:
    """
    è®¡ç®—å¸‚åœºæƒ…ç»ªè¯„åˆ†ï¼ˆ0-100åˆ†ï¼Œåˆ†æ•°è¶Šé«˜è¡¨ç¤ºå¸‚åœºæƒ…ç»ªè¶Šç§¯æï¼‰
    
    Args:
        df: ETFæ—¥çº¿æ•°æ®
    
    Returns:
        float: æƒ…ç»ªè¯„åˆ†
    """
    try:
        # åˆ›å»ºDataFrameçš„æ·±æ‹·è´
        df = df.copy(deep=True)
        
        # ç¡®ä¿ä½¿ç”¨ä¸­æ–‡åˆ—å
        df = ensure_chinese_columns(df)
        
        # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®
        if len(df) < 30:
            logger.warning(f"æ•°æ®é‡ä¸è¶³({len(df)}å¤©)ï¼Œæƒ…ç»ªè¯„åˆ†å¯èƒ½ä¸å‡†ç¡®")
        
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        required_columns = ["æ—¥æœŸ", "æˆäº¤é¢"]
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            logger.error(f"æƒ…ç»ªè¯„åˆ†æ‰€éœ€åˆ—ç¼ºå¤±: {', '.join(missing_columns)}")
            return 50.0  # è¿”å›é»˜è®¤å€¼
        
        # è®¡ç®—æœ€è¿‘5å¤©çš„æˆäº¤é¢å˜åŒ–ç‡
        volume_change = 0.0
        if AMOUNT_COL in df.columns and len(df) >= 5:
            # ç¡®ä¿æˆäº¤é¢åˆ—æ˜¯æ•°å€¼ç±»å‹
            if not pd.api.types.is_numeric_dtype(df[AMOUNT_COL]):
                df.loc[:, AMOUNT_COL] = pd.to_numeric(df[AMOUNT_COL], errors='coerce')
            
            volume_5d = df[AMOUNT_COL].tail(5)
            volume_change = (volume_5d.iloc[-1] / volume_5d.iloc[0]) - 1
        
        # è®¡ç®—æœ€è¿‘5å¤©çš„ä»·æ ¼å˜åŒ–
        recent_price_change = 0.0
        if CLOSE_COL in df.columns and len(df) >= 5:
            # ç¡®ä¿æ”¶ç›˜ä»·åˆ—æ˜¯æ•°å€¼ç±»å‹
            if not pd.api.types.is_numeric_dtype(df[CLOSE_COL]):
                df.loc[:, CLOSE_COL] = pd.to_numeric(df[CLOSE_COL], errors='coerce')
            
            recent_price_change = (df[CLOSE_COL].iloc[-1] / df[CLOSE_COL].iloc[-5]) - 1
        
        # ç»¼åˆæƒ…ç»ªæŒ‡æ ‡
        sentiment_score = 50 + (volume_change * 25) + (recent_price_change * 25)
        
        # ç¡®ä¿è¯„åˆ†åœ¨0-100èŒƒå›´å†…
        sentiment_score = max(0, min(100, sentiment_score))
        
        logger.debug(f"ETFæƒ…ç»ªè¯„åˆ†: {sentiment_score:.2f} (æˆäº¤é¢å˜åŒ–ç‡: {volume_change:.2f}, ä»·æ ¼å˜åŒ–: {recent_price_change:.2f})")
        return sentiment_score
    
    except Exception as e:
        logger.error(f"è®¡ç®—æƒ…ç»ªå¾—åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        return 50.0

def calculate_fundamental_score(etf_code: str) -> float:
    """
    è®¡ç®—åŸºæœ¬é¢å¾—åˆ†ï¼ˆè§„æ¨¡ï¼‰
    
    Args:
        etf_code: ETFä»£ç 
    
    Returns:
        float: åŸºæœ¬é¢å¾—åˆ†
    """
    try:
        size = get_etf_basic_info(etf_code)
        
        # è§„æ¨¡å¾—åˆ†ï¼ˆ10äº¿=60åˆ†ï¼Œ100äº¿=100åˆ†ï¼‰
        size_score = min(max(size * 0.4 + 50, 0), 100)
        
        # ç§»é™¤ä¸Šå¸‚æ—¶é—´å¾—åˆ†ï¼Œå°†æƒé‡å…¨éƒ¨ç»™è§„æ¨¡
        fundamental_score = size_score  # 100%æƒé‡ç»™è§„æ¨¡
        
        logger.debug(f"ETF {etf_code} åŸºæœ¬é¢è¯„åˆ†: {fundamental_score:.2f} (è§„æ¨¡: {size}äº¿å…ƒ)")
        return fundamental_score
    
    except Exception as e:
        logger.error(f"è®¡ç®—ETF {etf_code} åŸºæœ¬é¢è¯„åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        return 70.0  # é»˜è®¤ä¸­ç­‰åé«˜è¯„åˆ†

def calculate_component_stability_score(etf_code: str, df: pd.DataFrame) -> float:
    """
    è®¡ç®—æˆåˆ†è‚¡ç¨³å®šæ€§è¯„åˆ†
    
    Args:
        etf_code: ETFä»£ç 
        df: ETFæ—¥çº¿æ•°æ®
    
    Returns:
        float: æˆåˆ†è‚¡ç¨³å®šæ€§è¯„åˆ† (0-100)
    """
    try:
        if df is None or df.empty:
            logger.warning(f"ETF {etf_code} æ— æ—¥çº¿æ•°æ®ï¼Œæ— æ³•è®¡ç®—æˆåˆ†è‚¡ç¨³å®šæ€§è¯„åˆ†")
            return 70.0  # é»˜è®¤ä¸­ç­‰åé«˜è¯„åˆ†
        
        # åˆ›å»ºDataFrameçš„å‰¯æœ¬ï¼Œé¿å…SettingWithCopyWarning
        df = df.copy(deep=True)
        
        # è®¡ç®—æ³¢åŠ¨ç‡
        volatility = calculate_volatility(df)
        
        # æ³¢åŠ¨ç‡è¯„åˆ†ï¼ˆè¶Šä½è¶Šå¥½ï¼‰ï¼šæ³¢åŠ¨ç‡â‰¤0.1=100åˆ†ï¼Œ0.3=50åˆ†ï¼Œâ‰¥0.5=0åˆ†
        component_score = max(0, 100 - (volatility * 200))
        
        # è€ƒè™‘ETFè§„æ¨¡ï¼ˆè§„æ¨¡è¶Šå¤§ï¼Œæˆåˆ†è‚¡ç¨³å®šæ€§é€šå¸¸è¶Šé«˜ï¼‰
        size = get_etf_basic_info(etf_code)
        size_score = min(max(size * 0.5, 0), 100)
        
        # ç»¼åˆè¯„åˆ†ï¼ˆæ³¢åŠ¨ç‡å 70%ï¼Œè§„æ¨¡å 30%ï¼‰
        total_score = component_score * 0.7 + size_score * 0.3
        
        logger.debug(f"ETF {etf_code} æˆåˆ†è‚¡ç¨³å®šæ€§è¯„åˆ†: {total_score:.2f} (æ³¢åŠ¨ç‡: {volatility:.4f}, è§„æ¨¡: {size}äº¿å…ƒ)")
        return total_score
    
    except Exception as e:
        logger.error(f"è®¡ç®—ETF {etf_code} æˆåˆ†è‚¡ç¨³å®šæ€§è¯„åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        return 70.0  # é»˜è®¤ä¸­ç­‰åé«˜è¯„åˆ†

def calculate_volatility(df: pd.DataFrame) -> float:
    """
    è®¡ç®—ETFä»·æ ¼æ³¢åŠ¨ç‡
    
    Args:
        df: ETFæ—¥çº¿æ•°æ®
    
    Returns:
        float: æ³¢åŠ¨ç‡
    """
    try:
        # åˆ›å»ºDataFrameçš„æ·±æ‹·è´
        df = df.copy(deep=True)
        
        # ç¡®ä¿ä½¿ç”¨ä¸­æ–‡åˆ—å
        df = ensure_chinese_columns(df)
        
        # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
        required_columns = ["æ—¥æœŸ", "æ”¶ç›˜"]
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            logger.error(f"æ³¢åŠ¨ç‡è®¡ç®—æ‰€éœ€åˆ—ç¼ºå¤±: {', '.join(missing_columns)}")
            return 0.2  # è¿”å›é»˜è®¤æ³¢åŠ¨ç‡
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¿…è¦åˆ—
        if CLOSE_COL not in df.columns:
            logger.error(f"æ•°æ®ä¸­ç¼ºå°‘å¿…è¦åˆ—: {CLOSE_COL}")
            return 0.2
        
        # æ£€æŸ¥æ”¶ç›˜ä»·åˆ—æ˜¯å¦ä¸ºæ•°å€¼ç±»å‹
        if not pd.api.types.is_numeric_dtype(df[CLOSE_COL]):
            try:
                # ä½¿ç”¨.locç¡®ä¿å®‰å…¨èµ‹å€¼
                df.loc[:, CLOSE_COL] = pd.to_numeric(df[CLOSE_COL], errors='coerce')
            except Exception as e:
                logger.error(f"æ”¶ç›˜ä»·åˆ—è½¬æ¢å¤±è´¥: {str(e)}")
                return 0.2  # é»˜è®¤æ³¢åŠ¨ç‡
        
        # åˆ›å»ºå‰¯æœ¬ä»¥é¿å…SettingWithCopyWarning
        df = df.copy(deep=True)
        
        # è®¡ç®—æ—¥æ”¶ç›Šç‡
        df.loc[:, "daily_return"] = df[CLOSE_COL].pct_change()
        
        # å¤„ç†NaNå€¼
        if "daily_return" in df.columns:
            df = df.dropna(subset=["daily_return"])
        
        # è®¡ç®—å¹´åŒ–æ³¢åŠ¨ç‡
        if not df.empty:
            volatility = df["daily_return"].std() * np.sqrt(252)
        else:
            volatility = 0.2  # é»˜è®¤æ³¢åŠ¨ç‡
        
        # å¤„ç†å¼‚å¸¸å€¼
        volatility = min(max(volatility, 0), 1)
        
        return volatility
    
    except Exception as e:
        logger.error(f"è®¡ç®—æ³¢åŠ¨ç‡å¤±è´¥: {str(e)}", exc_info=True)
        return 0.2  # é»˜è®¤ä¸­ç­‰æ³¢åŠ¨ç‡

def get_etf_basic_info(etf_code: str) -> float:
    """
    ä»ETFåˆ—è¡¨ä¸­è·å–ETFåŸºæœ¬ä¿¡æ¯
    
    Args:
        etf_code: ETFä»£ç  (6ä½æ•°å­—)
    
    Returns:
        float: åŸºé‡‘è§„æ¨¡(å•ä½:äº¿å…ƒ)
    """
    try:
        # ç¡®ä¿ETFä»£ç æ ¼å¼ä¸€è‡´ï¼ˆ6ä½æ•°å­—ï¼‰
        etf_code = str(etf_code).strip().zfill(6)
        
        # æ£€æŸ¥ETFåˆ—è¡¨æ˜¯å¦æœ‰æ•ˆ
        etf_codes = get_all_etf_codes()
        
        # åˆ›å»ºDataFrame
        etf_list = pd.DataFrame(etf_codes, columns=['ETFä»£ç '])
        
        if etf_list is None or etf_list.empty:
            logger.warning("ETFåˆ—è¡¨ä¸ºç©ºæˆ–æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤å€¼")
            return 0.0
        
        # ç¡®ä¿ETFåˆ—è¡¨åŒ…å«å¿…è¦çš„åˆ—
        required_columns = [ETF_CODE_COL, FUND_SIZE_COL]
        for col in required_columns:
            if col not in etf_list.columns:
                logger.warning(f"ETFåˆ—è¡¨ç¼ºå°‘å¿…è¦åˆ—: {col}")
                return 0.0
        
        # åˆ›å»ºå‰¯æœ¬é¿å…SettingWithCopyWarning
        etf_list = etf_list.copy(deep=True)
        
        # ä¿®å¤ï¼šæ›´å®‰å…¨çš„ç±»å‹è½¬æ¢æ–¹æ³•
        if ETF_CODE_COL in etf_list.columns:
            # æ£€æŸ¥åˆ—æ˜¯å¦åŒ…å«éå­—ç¬¦ä¸²å€¼
            has_non_string = etf_list[ETF_CODE_COL].apply(lambda x: not isinstance(x, str)).any()
            
            # å¦‚æœåˆ—åŒ…å«éå­—ç¬¦ä¸²å€¼ï¼Œæˆ–è€…åˆ—æ˜¯æ•°å€¼ç±»å‹ï¼Œåˆ™è¿›è¡Œè½¬æ¢
            if has_non_string or pd.api.types.is_numeric_dtype(etf_list[ETF_CODE_COL]):
                etf_list.loc[:, ETF_CODE_COL] = etf_list[ETF_CODE_COL].astype(str)
        
        # ç¡®ä¿ETFåˆ—è¡¨ä¸­çš„ETFä»£ç ä¹Ÿæ˜¯6ä½æ•°å­—
        etf_list.loc[:, ETF_CODE_COL] = etf_list[ETF_CODE_COL].str.strip().str.zfill(6)
        
        etf_row = etf_list[etf_list[ETF_CODE_COL] == etf_code]
        if not etf_row.empty:
            # å¤„ç†è§„æ¨¡
            size = 0.0
            if FUND_SIZE_COL in etf_row.columns:
                size = extract_scalar_value(
                    etf_row.iloc[0][FUND_SIZE_COL],
                    log_prefix=f"ETF {etf_code} è§„æ¨¡: "
                )
            return size
        
        logger.warning(f"ETF {etf_code} æœªåœ¨ETFåˆ—è¡¨ä¸­æ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤å€¼")
        return 0.0
    
    except Exception as e:
        error_msg = f"è·å–ETF {etf_code} åŸºæœ¬ä¿¡æ¯å¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        return 0.0

def calculate_etf_score(etf_code: str, df: pd.DataFrame) -> float:
    """
    è®¡ç®—ETFç»¼åˆè¯„åˆ†ï¼ˆ0-100åˆ†ï¼‰
    
    Args:
        etf_code: ETFä»£ç 
        df: ETFæ—¥çº¿æ•°æ®
    
    Returns:
        float: ETFç»¼åˆè¯„åˆ†
    """
    try:
        # è·å–å½“å‰åŒæ—¶åŒºæ—¶é—´
        _, beijing_now = get_current_times()
        
        # åˆ›å»ºDataFrameçš„å‰¯æœ¬ï¼Œé¿å…SettingWithCopyWarning
        if df is None or df.empty:
            logger.warning(f"ETF {etf_code} æ— æ—¥çº¿æ•°æ®ï¼Œè¯„åˆ†è®¾ä¸º0")
            return 0.0
        
        # åˆ›å»ºå®‰å…¨å‰¯æœ¬
        df = df.copy(deep=True)
        
        # ã€æ—¥æœŸdatetimeç±»å‹è§„åˆ™ã€‘ç¡®ä¿æ—¥æœŸåˆ—æ˜¯datetimeç±»å‹
        if DATE_COL in df.columns:
            try:
                # ä»…åœ¨æ—¥æœŸåˆ—å­˜åœ¨æ—¶è½¬æ¢ä¸ºdatetimeç±»å‹
                df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors='coerce')
                # æŒ‰æ—¥æœŸæ’åº
                df = df.sort_values(DATE_COL)
            except Exception as e:
                logger.error(f"æ—¥æœŸåˆ—è½¬æ¢å¤±è´¥: {str(e)}")
                df = df.sort_values(DATE_COL)
        
        # ç¡®ä¿ä½¿ç”¨ä¸­æ–‡åˆ—å
        df = ensure_chinese_columns(df)
        
        # æ£€æŸ¥æ•°æ®é‡
        min_required_data = 30  # é»˜è®¤éœ€è¦30å¤©æ•°æ®
        if len(df) < min_required_data:
            if len(df) < 10:
                logger.warning(f"ETF {etf_code} æ•°æ®é‡ä¸¥é‡ä¸è¶³({len(df)}å¤©)ï¼Œè¯„åˆ†è®¾ä¸º0")
                return 0.0
            else:
                logger.info(f"ETF {etf_code} æ•°æ®é‡ä¸è¶³({len(df)}å¤©)ï¼Œä½¿ç”¨ç°æœ‰æ•°æ®è®¡ç®—è¯„åˆ†")
                min_required_data = len(df)
        
        # å–æœ€è¿‘min_required_dataå¤©æ•°æ®
        recent_data = df.tail(min_required_data)
        
        # 1. æµåŠ¨æ€§å¾—åˆ†ï¼ˆæ—¥å‡æˆäº¤é¢ï¼‰
        liquidity_score = calculate_liquidity_score(recent_data)
        
        # 2. é£é™©æ§åˆ¶å¾—åˆ†
        risk_score = calculate_risk_score(recent_data)
        
        # 3. æ”¶ç›Šèƒ½åŠ›å¾—åˆ†
        return_score = calculate_return_score(recent_data)
        
        # 4. æƒ…ç»ªæŒ‡æ ‡å¾—åˆ†ï¼ˆæˆäº¤é‡å˜åŒ–ç‡ï¼‰
        sentiment_score = calculate_sentiment_score(recent_data)
        
        # 5. åŸºæœ¬é¢å¾—åˆ†ï¼ˆè§„æ¨¡ï¼‰
        fundamental_score = calculate_fundamental_score(etf_code)
        
        # éªŒè¯æ‰€æœ‰å¾—åˆ†æ˜¯å¦åœ¨æœ‰æ•ˆèŒƒå›´å†… [0, 100]
        scores = {
            "liquidity": max(0, min(100, liquidity_score)),
            "risk": max(0, min(100, risk_score)),
            "return": max(0, min(100, return_score)),
            "sentiment": max(0, min(100, sentiment_score)),
            "fundamental": max(0, min(100, fundamental_score))
        }
        
        # è·å–æƒé‡
        weights = Config.SCORE_WEIGHTS.copy()
        
        # ç¡®ä¿æƒé‡å­—å…¸åŒ…å«æ‰€æœ‰å¿…è¦çš„é”®
        required_keys = ['liquidity', 'risk', 'return', 'sentiment', 'fundamental']
        for key in required_keys:
            if key not in weights:
                logger.warning(f"æƒé‡å­—å…¸ç¼ºå°‘å¿…è¦é”®: {key}, ä½¿ç”¨é»˜è®¤å€¼0.2")
                weights[key] = 0.2
        
        # ç¡®ä¿æƒé‡å’Œä¸º1
        total_weight = sum(weights.values())
        # ä¿®å¤ï¼šä½¿ç”¨å®¹å·®æ¯”è¾ƒæµ®ç‚¹æ•°
        if abs(total_weight - 1.0) > 1e-10:
            logger.warning(f"æƒé‡å’Œä¸ä¸º1 ({total_weight:.2f})ï¼Œè‡ªåŠ¨è°ƒæ•´")
            for key in weights:
                weights[key] = weights[key] / total_weight
        
        # è®¡ç®—ç»¼åˆè¯„åˆ†ï¼ˆåŠ æƒå¹³å‡ï¼‰
        total_score = (
            scores["liquidity"] * weights['liquidity'] +
            scores["risk"] * weights['risk'] +
            scores["return"] * weights['return'] +
            scores["sentiment"] * weights['sentiment'] +
            scores["fundamental"] * weights['fundamental']
        )
        
        # åŒé‡éªŒè¯ï¼šç¡®ä¿è¯„åˆ†åœ¨0-100èŒƒå›´å†…
        total_score = max(0, min(100, total_score))
        
        logger.debug(f"ETF {etf_code} è¯„åˆ†è¯¦æƒ…: " +
                     f"æµåŠ¨æ€§={scores['liquidity']:.2f}({weights['liquidity']*100:.0f}%), " +
                     f"é£é™©={scores['risk']:.2f}({weights['risk']*100:.0f}%), " +
                     f"æ”¶ç›Š={scores['return']:.2f}({weights['return']*100:.0f}%), " +
                     f"æƒ…ç»ª={scores['sentiment']:.2f}({weights['sentiment']*100:.0f}%), " +
                     f"åŸºæœ¬é¢={scores['fundamental']:.2f}({weights['fundamental']*100:.0f}%), " +
                     f"ç»¼åˆ={total_score:.2f}")
        
        return round(total_score, 2)
    
    except Exception as e:
        error_msg = f"è®¡ç®—ETF {etf_code} ç»¼åˆè¯„åˆ†å¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        return 0.0

def get_etf_score_history(etf_code: str, days: int = 30) -> pd.DataFrame:
    """
    è·å–ETFå†å²è¯„åˆ†æ•°æ®
    
    Args:
        etf_code: ETFä»£ç 
        days: æŸ¥è¯¢å¤©æ•°
    
    Returns:
        pd.DataFrame: è¯„åˆ†å†å²æ•°æ®
    """
    try:
        history = []
        beijing_now = get_beijing_time()
        
        for i in range(days):
            # ã€æ—¥æœŸdatetimeç±»å‹è§„åˆ™ã€‘ç¡®ä¿æ—¥æœŸæ˜¯datetimeç±»å‹
            date = (beijing_now - timedelta(days=i)).strftime("%Y-%m-%d")
            score_file = os.path.join(Config.SCORE_HISTORY_DIR, f"{etf_code}_{date}.json")
            
            if os.path.exists(score_file):
                try:
                    with open(score_file, 'r') as f:
                        score_data = json.load(f)
                    history.append({
                        "æ—¥æœŸ": date,
                        "è¯„åˆ†": score_data.get("score", 0.0),
                        "æ’å": score_data.get("rank", 0)
                    })
                except Exception as e:
                    logger.error(f"è¯»å–è¯„åˆ†å†å²æ–‡ä»¶ {score_file} å¤±è´¥: {str(e)}")
        
        if not history:
            logger.info(f"æœªæ‰¾åˆ°ETF {etf_code} çš„è¯„åˆ†å†å²æ•°æ®")
            return pd.DataFrame()
        
        return pd.DataFrame(history)
    
    except Exception as e:
        error_msg = f"è·å–ETF {etf_code} è¯„åˆ†å†å²æ•°æ®å¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        # å‘é€é”™è¯¯é€šçŸ¥
        send_wechat_message(
            message=error_msg,
            message_type="error"
        )
        return pd.DataFrame()

def analyze_etf_score_trend(etf_code: str) -> str:
    """
    åˆ†æETFè¯„åˆ†è¶‹åŠ¿
    
    Args:
        etf_code: ETFä»£ç 
    
    Returns:
        str: åˆ†æç»“æœ
    """
    try:
        # è·å–è¯„åˆ†å†å²
        history_df = get_etf_score_history(etf_code)
        if history_df.empty:
            return f"ã€{etf_code} è¯„åˆ†è¶‹åŠ¿ã€‘â€¢ æ— å†å²è¯„åˆ†æ•°æ®"
        
        # è®¡ç®—è¶‹åŠ¿
        latest_score = history_df.iloc[0]["è¯„åˆ†"]
        avg_score = history_df["è¯„åˆ†"].mean()
        trend = "ä¸Šå‡" if latest_score > avg_score else "ä¸‹é™"
        
        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        report = f"ã€{etf_code} è¯„åˆ†è¶‹åŠ¿ã€‘"
        report += f"â€¢ å½“å‰è¯„åˆ†: {latest_score:.2f}"
        report += f"â€¢ è¿‘æœŸå¹³å‡è¯„åˆ†: {avg_score:.2f}"
        report += f"â€¢ è¯„åˆ†è¶‹åŠ¿: {trend}"
        
        # æ·»åŠ å»ºè®®
        if trend == "ä¸Šå‡":
            report += "ğŸ’¡ å»ºè®®ï¼šè¯„åˆ†æŒç»­ä¸Šå‡ï¼Œå¯å…³æ³¨è¯¥ETF"
        else:
            report += "ğŸ’¡ å»ºè®®ï¼šè¯„åˆ†æŒç»­ä¸‹é™ï¼Œéœ€è°¨æ…è€ƒè™‘"
        
        return report
    
    except Exception as e:
        error_msg = f"åˆ†æETF {etf_code} è¯„åˆ†è¶‹åŠ¿å¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        # å‘é€é”™è¯¯é€šçŸ¥
        send_wechat_message(
            message=error_msg,
            message_type="error"
        )
        return f"ã€{etf_code} è¯„åˆ†è¶‹åŠ¿ã€‘â€¢ åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—"

def calculate_arbitrage_score(etf_code: str,
                            etf_name: str,
                            premium_discount: float,  # è¿™å·²ç»æ˜¯æŠ˜æº¢ä»·ç‡ï¼Œä¸éœ€è¦å†è®¡ç®—
                            market_price: float,
                            iopv: float,
                            fund_size: float,
                            avg_volume: float,
                            historical_data: Optional[pd.DataFrame] = None) -> float:
    """
    è®¡ç®—ETFå¥—åˆ©ç»¼åˆè¯„åˆ†
    
    Args:
        etf_code: ETFä»£ç 
        etf_name: ETFåç§°
        premium_discount: æŠ˜æº¢ä»·ç‡ï¼ˆæ ‡é‡å€¼ï¼Œä¸æ˜¯Seriesï¼‰
        market_price: å¸‚åœºä»·æ ¼
        iopv: IOPVå‡€å€¼
        fund_size: åŸºé‡‘è§„æ¨¡
        avg_volume: æ—¥å‡æˆäº¤é¢
        historical_data: å†å²æ•°æ®ï¼ˆå¯é€‰ï¼‰
    
    Returns:
        float: ç»¼åˆè¯„åˆ† (0-100)
    """
    try:
        # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
        MAX_DISCOUNT = -20.0  # æœ€å¤§æŠ˜ä»·ç‡ï¼ˆ-20%ï¼‰
        MAX_PREMIUM = 20.0    # æœ€å¤§æº¢ä»·ç‡ï¼ˆ20%ï¼‰
        premium_discount = max(min(premium_discount, MAX_PREMIUM), MAX_DISCOUNT)
        
        # è®°å½•å®é™…ä½¿ç”¨çš„å€¼
        logger.debug(f"ETF {etf_code} å®é™…ä½¿ç”¨çš„æŠ˜æº¢ä»·ç‡: {premium_discount:.2f}%")
        
        # è®¡ç®—åŸºç¡€ETFè¯„åˆ†
        base_score = 70.0  # é»˜è®¤å€¼ï¼Œå®é™…åº”ä»å†å²æ•°æ®è®¡ç®—
        if historical_data is not None and not historical_data.empty:
            base_score = calculate_etf_score(etf_code, historical_data)
        
        # ç¡®ä¿åŸºç¡€è¯„åˆ†åœ¨0-100èŒƒå›´å†…
        if base_score < 0 or base_score > 100:
            logger.warning(f"ETF {etf_code} åŸºç¡€è¯„åˆ†è¶…å‡ºèŒƒå›´({base_score:.2f})ï¼Œå¼ºåˆ¶é™åˆ¶åœ¨0-100")
            base_score = max(0, min(100, base_score))
        
        # è®¡ç®—æˆåˆ†è‚¡ç¨³å®šæ€§è¯„åˆ†
        component_score = calculate_component_stability_score(etf_code, historical_data)
        
        # ç¡®ä¿æˆåˆ†è‚¡ç¨³å®šæ€§è¯„åˆ†åœ¨0-100èŒƒå›´å†…
        if component_score < 0 or component_score > 100:
            logger.warning(f"ETF {etf_code} æˆåˆ†è‚¡ç¨³å®šæ€§è¯„åˆ†è¶…å‡ºèŒƒå›´({component_score:.2f})ï¼Œå¼ºåˆ¶é™åˆ¶åœ¨0-100")
            component_score = max(0, min(100, component_score))
        
        # ä¿®å¤ï¼šæŠ˜ä»·æƒ…å†µ - æŠ˜ä»·ç‡è¶Šé«˜ï¼ˆç»å¯¹å€¼è¶Šå¤§ï¼‰ï¼Œè¯„åˆ†åº”è¯¥è¶Šé«˜
        if premium_discount < 0:
            abs_premium = abs(premium_discount)
            # æŠ˜ä»·ç‡è¶Šé«˜ï¼ˆç»å¯¹å€¼è¶Šå¤§ï¼‰ï¼Œè¯„åˆ†åº”è¯¥è¶Šé«˜
            if abs_premium >= Config.DISCOUNT_THRESHOLD * 3:
                premium_score = 100.0
            elif abs_premium >= Config.DISCOUNT_THRESHOLD * 2:
                premium_score = 90.0
            elif abs_premium >= Config.DISCOUNT_THRESHOLD * 1.5:
                premium_score = 80.0
            elif abs_premium >= Config.DISCOUNT_THRESHOLD:
                premium_score = 70.0
            else:
                premium_score = 0.0
        # ä¿®å¤ï¼šæº¢ä»·æƒ…å†µ - æº¢ä»·ç‡è¶Šé«˜ï¼Œè¯„åˆ†åº”è¯¥è¶Šé«˜
        else:
            # æº¢ä»·ç‡è¶Šé«˜ï¼Œè¯„åˆ†åº”è¯¥è¶Šé«˜
            if premium_discount >= Config.PREMIUM_THRESHOLD * 3:
                premium_score = 100.0
            elif premium_discount >= Config.PREMIUM_THRESHOLD * 2:
                premium_score = 90.0
            elif premium_discount >= Config.PREMIUM_THRESHOLD * 1.5:
                premium_score = 80.0
            elif premium_discount >= Config.PREMIUM_THRESHOLD:
                premium_score = 70.0
            else:
                premium_score = 0.0
        
        # ç¡®ä¿æŠ˜æº¢ä»·ç‡è¯„åˆ†åœ¨0-100èŒƒå›´å†…
        if premium_score < 0 or premium_score > 100:
            logger.warning(f"ETF {etf_code} æŠ˜æº¢ä»·ç‡è¯„åˆ†è¶…å‡ºèŒƒå›´({premium_score:.2f})ï¼Œå¼ºåˆ¶é™åˆ¶åœ¨0-100")
            premium_score = max(0, min(100, premium_score))
        
        # è·å–è¯„åˆ†æƒé‡
        weights = Config.ARBITRAGE_SCORE_WEIGHTS.copy()
        
        # ç¡®ä¿æƒé‡å­—å…¸åŒ…å«æ‰€æœ‰å¿…è¦çš„é”®
        required_keys = ['premium_discount', 'liquidity', 'risk', 'return', 'market_sentiment', 'fundamental', 'component_stability']
        for key in required_keys:
            if key not in weights:
                logger.warning(f"æƒé‡å­—å…¸ç¼ºå°‘å¿…è¦é”®: {key}, ä½¿ç”¨é»˜è®¤å€¼0.1")
                weights[key] = 0.1
        
        # ç¡®ä¿æƒé‡å’Œä¸º1
        total_weight = sum(weights.values())
        # ä¿®å¤ï¼šä½¿ç”¨å®¹å·®æ¯”è¾ƒæµ®ç‚¹æ•°
        if abs(total_weight - 1.0) > 1e-10:
            logger.warning(f"æƒé‡å’Œä¸ä¸º1 ({total_weight:.2f})ï¼Œè‡ªåŠ¨è°ƒæ•´")
            for key in weights:
                weights[key] = weights[key] / total_weight
        
        # ç»¼åˆè¯„åˆ†ï¼ˆåŠ æƒå¹³å‡ï¼‰
        total_score = (
            base_score * (weights['liquidity'] + weights['risk'] + weights['return'] + weights['market_sentiment'] + weights['fundamental']) +
            component_score * weights['component_stability'] +
            premium_score * weights['premium_discount']
        )
        
        # åŒé‡éªŒè¯ï¼šç¡®ä¿è¯„åˆ†åœ¨0-100èŒƒå›´å†…
        if total_score < 0 or total_score > 100:
            logger.error(f"ETF {etf_code} å¥—åˆ©ç»¼åˆè¯„åˆ†è¶…å‡ºèŒƒå›´({total_score:.2f})ï¼Œå¼ºåˆ¶é™åˆ¶åœ¨0-100")
            total_score = max(0, min(100, total_score))
        
        # æ·»åŠ è¯¦ç»†æ—¥å¿—ï¼Œä¾¿äºé—®é¢˜æ’æŸ¥
        logger.debug(f"ETF {etf_code} å¥—åˆ©ç»¼åˆè¯„åˆ†è¯¦æƒ…: " +
                     f"åŸºç¡€è¯„åˆ†={base_score:.2f}(æƒé‡{weights['liquidity'] + weights['risk'] + weights['return'] + weights['market_sentiment'] + weights['fundamental']:.2f}), " +
                     f"æˆåˆ†è‚¡ç¨³å®šæ€§={component_score:.2f}(æƒé‡{weights['component_stability']:.2f}), " +
                     f"æŠ˜æº¢ä»·ç‡={premium_score:.2f}(æƒé‡{weights['premium_discount']:.2f}), " +
                     f"æœ€ç»ˆè¯„åˆ†={total_score:.2f}")
        
        return total_score
    
    except Exception as e:
        logger.error(f"è®¡ç®—ETF {etf_code} å¥—åˆ©ç»¼åˆè¯„åˆ†å¤±è´¥: {str(e)}", exc_info=True)
        return 0.0

def get_top_rated_etfs(top_n=None,
                     min_score=60,
                     min_fund_size=10.0,
                     min_avg_volume=5000.0) -> pd.DataFrame:
    """
    ä»å…¨å¸‚åœºETFä¸­ç­›é€‰é«˜åˆ†ETF
    
    Args:
        top_n: è¿”å›å‰Nåï¼Œä¸ºNoneåˆ™è¿”å›æ‰€æœ‰é«˜äºmin_scoreçš„ETF
        min_score: æœ€ä½è¯„åˆ†é˜ˆå€¼
        min_fund_size: æœ€å°åŸºé‡‘è§„æ¨¡(äº¿å…ƒ)
        min_avg_volume: æœ€å°æ—¥å‡æˆäº¤é¢(ä¸‡å…ƒ)
    
    Returns:
        pd.DataFrame: åŒ…å«ETFä»£ç ã€åç§°ã€è¯„åˆ†ç­‰ä¿¡æ¯çš„DataFrame
    """
    try:
        metadata_df = load_etf_metadata()
        if metadata_df is None or metadata_df.empty:
            logger.warning("å…ƒæ•°æ®ä¸ºç©ºï¼Œæ— æ³•è·å–ETFåˆ—è¡¨")
            return pd.DataFrame()
        
        # ç¡®ä¿ETFä»£ç å”¯ä¸€
        all_codes = metadata_df["ETFä»£ç "].drop_duplicates().tolist()
        if not all_codes:
            logger.warning("å…ƒæ•°æ®ä¸­æ— ETFä»£ç ")
            return pd.DataFrame()
        
        score_list = []
        logger.info(f"å¼€å§‹è®¡ç®— {len(all_codes)} åªETFçš„ç»¼åˆè¯„åˆ†...")
        
        # ç”¨äºè¿›åº¦è·Ÿè¸ª
        total = len(all_codes)
        processed = 0
        last_log_time = time.time()
        
        for idx, etf_code in enumerate(all_codes):
            try:
                df = load_etf_daily_data(etf_code)
                if df.empty:
                    logger.debug(f"ETF {etf_code} æ— æ—¥çº¿æ•°æ®ï¼Œè·³è¿‡è¯„åˆ†")
                    continue
                
                # ã€æ—¥æœŸdatetimeç±»å‹è§„åˆ™ã€‘ç¡®ä¿æ—¥æœŸåˆ—æ˜¯datetimeç±»å‹
                if not df.empty and DATE_COL in df.columns:
                    try:
                        df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors='coerce')
                        df = df.sort_values(DATE_COL)
                    except Exception as e:
                        logger.error(f"æ—¥æœŸåˆ—è½¬æ¢å¤±è´¥: {str(e)}")
                        df = df.sort_values(DATE_COL)
                
                # ç¡®ä¿ETFä»£ç æ ¼å¼ä¸€è‡´ï¼ˆ6ä½æ•°å­—ï¼‰
                etf_code = str(etf_code).strip().zfill(6)
                
                # è®¡ç®—ETFè¯„åˆ†
                score = calculate_etf_score(etf_code, df)
                if score < min_score:
                    continue
                
                # è·å–ETFåŸºæœ¬ä¿¡æ¯ï¼ˆä»æœ¬åœ°å…ƒæ•°æ®è·å–ï¼‰
                size = 0.0
                size_row = metadata_df[metadata_df["ETFä»£ç "] == etf_code]
                if not size_row.empty and "åŸºé‡‘è§„æ¨¡" in metadata_df.columns:
                    size = extract_scalar_value(
                        size_row.iloc[0]["åŸºé‡‘è§„æ¨¡"],
                        log_prefix=f"ETF {etf_code} è§„æ¨¡: "
                    )
                
                etf_name = get_etf_name(etf_code)
                
                # è®¡ç®—æ—¥å‡æˆäº¤é¢
                avg_volume = 0.0
                if AMOUNT_COL in df.columns:
                    recent_30d = df.tail(30)
                    if len(recent_30d) > 0:
                        avg_volume = recent_30d[AMOUNT_COL].mean()
                
                # æ·»åŠ è¿›åº¦æ—¥å¿— - ç®€åŒ–è¾“å‡º
                processed += 1
                current_time = time.time()
                
                # æ¯å¤„ç†100åªETFæˆ–æ¯5ç§’è®°å½•ä¸€æ¬¡è¿›åº¦
                if processed % 100 == 0 or (current_time - last_log_time) >= 5:
                    progress = (processed / total) * 100
                    logger.info(f"æ­£åœ¨è®¡ç®—ETFè¯„åˆ†: {processed}/{total} ({progress:.1f}%)")
                    last_log_time = current_time
                
                # ä»…ä¿ç•™æ»¡è¶³æ¡ä»¶çš„ETF
                if size >= min_fund_size and avg_volume >= min_avg_volume:
                    score_list.append({
                        "ETFä»£ç ": etf_code,
                        "ETFåç§°": etf_name,
                        "è¯„åˆ†": score,
                        "è§„æ¨¡": size,
                        "æ—¥å‡æˆäº¤é¢": avg_volume
                    })
            except Exception as e:
                logger.error(f"å¤„ç†ETF {etf_code} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}", exc_info=True)
                continue
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¬¦åˆæ¡ä»¶çš„ETF
        if not score_list:
            warning_msg = (f"æ²¡æœ‰ETFè¾¾åˆ°æœ€ä½è¯„åˆ†é˜ˆå€¼ {min_score}ï¼Œ" +
                          f"æˆ–æœªæ»¡è¶³è§„æ¨¡({min_fund_size}äº¿å…ƒ)å’Œæ—¥å‡æˆäº¤é¢({min_avg_volume}ä¸‡å…ƒ)è¦æ±‚")
            logger.info(warning_msg)
            return pd.DataFrame()
        
        # åˆ›å»ºè¯„åˆ†DataFrame
        score_df = pd.DataFrame(score_list).sort_values("è¯„åˆ†", ascending=False)
        total_etfs = len(score_df)
        
        # è®°å½•æœ€ç»ˆç»“æœ
        logger.info(f"è¯„åˆ†å®Œæˆã€‚å…±{total_etfs}åªETFè¯„åˆ†â‰¥{min_score}")
        logger.info(f"åº”ç”¨ç­›é€‰å‚æ•°: è§„æ¨¡â‰¥{min_fund_size}äº¿å…ƒ, æ—¥å‡æˆäº¤é¢â‰¥{min_avg_volume}ä¸‡å…ƒ")
        
        # è¿”å›ç»“æœ
        if top_n is not None and top_n > 0:
            return score_df.head(top_n)
        return score_df.head(max(10, int(total_etfs * Config.SCORE_TOP_PERCENT / 100)))
    
    except Exception as e:
        error_msg = f"è·å–é«˜è¯„åˆ†ETFåˆ—è¡¨å¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        send_wechat_message(
            message=error_msg,
            message_type="error"
        )
        return pd.DataFrame()

def calculate_position_strategy() -> str:
    """
    è®¡ç®—ä»“ä½ç­–ç•¥
    
    Returns:
        str: ä»“ä½ç­–ç•¥å»ºè®®
    """
    try:
        # è·å–é«˜è¯„åˆ†ETFåˆ—è¡¨
        top_etfs = get_top_rated_etfs(top_n=10)
        
        if top_etfs.empty:
            return "æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„é«˜è¯„åˆ†ETFï¼Œå»ºè®®ä¿æŒè§‚æœ›"
        
        # ç”Ÿæˆä»“ä½ç­–ç•¥å»ºè®®
        report = "ã€ä»“ä½ç­–ç•¥å»ºè®®ã€‘\n"
        report += f"æ¨èå…³æ³¨çš„ETF (å‰{len(top_etfs)}å):\n"
        
        for idx, row in top_etfs.iterrows():
            report += f"{idx+1}. {row['ETFä»£ç ']} {row['ETFåç§°']} (è¯„åˆ†: {row['è¯„åˆ†']:.2f}, è§„æ¨¡: {row['è§„æ¨¡']:.2f}äº¿å…ƒ)\n"
        
        # æ ¹æ®ETFæ•°é‡å’Œè¯„åˆ†ç¡®å®šä»“ä½
        if len(top_etfs) >= 5:
            report += "\nå»ºè®®ä»“ä½: 70%-90%\n"
            report += "ç†ç”±: å¸‚åœºæœºä¼šè¾ƒå¤šï¼Œå¯é€‚å½“æé«˜ä»“ä½"
        elif len(top_etfs) >= 3:
            report += "\nå»ºè®®ä»“ä½: 50%-70%\n"
            report += "ç†ç”±: å¸‚åœºå­˜åœ¨æœºä¼šï¼Œä½†éœ€ä¿æŒè°¨æ…"
        else:
            report += "\nå»ºè®®ä»“ä½: 30%-50%\n"
            report += "ç†ç”±: å¸‚åœºæœºä¼šæœ‰é™ï¼Œå»ºè®®é™ä½ä»“ä½"
        
        return report
    
    except Exception as e:
        error_msg = f"è®¡ç®—ä»“ä½ç­–ç•¥å¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        return "ä»“ä½ç­–ç•¥è®¡ç®—å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ—¥å¿—"

# æ¨¡å—åˆå§‹åŒ–
try:
    # ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨
    Config.init_dirs()
    
    # æ£€æŸ¥ETFåˆ—è¡¨æ˜¯å¦è¿‡æœŸ
    if is_file_outdated(Config.ALL_ETFS_PATH, Config.ETF_LIST_UPDATE_INTERVAL):
        warning_msg = "ETFåˆ—è¡¨å·²è¿‡æœŸï¼Œè¯„åˆ†ç³»ç»Ÿå¯èƒ½ä½¿ç”¨æ—§æ•°æ®"
        logger.warning(warning_msg)
        # å‘é€è­¦å‘Šé€šçŸ¥
        send_wechat_message(
            message=warning_msg,
            message_type="warning"
        )
    
    logger.info("ETFè¯„åˆ†ç³»ç»Ÿæ¨¡å—åˆå§‹åŒ–å®Œæˆ")
except Exception as e:
    error_msg = f"ETFè¯„åˆ†ç³»ç»Ÿæ¨¡å—åˆå§‹åŒ–å¤±è´¥: {str(e)}"
    logger.error(error_msg, exc_info=True)
    
    try:
        # é€€å›åˆ°åŸºç¡€æ—¥å¿—é…ç½®
        import logging
        logging.basicConfig(
            level="INFO",
            format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
            handlers=[logging.StreamHandler()]
        )
        logging.error(error_msg)
    except Exception as basic_log_error:
        print(f"åŸºç¡€æ—¥å¿—é…ç½®å¤±è´¥: {str(basic_log_error)}")
        print(error_msg)
    
    # å‘é€é”™è¯¯é€šçŸ¥
    try:
        from wechat_push.push import send_wechat_message
        send_wechat_message(
            message=f"ETFè¯„åˆ†ç³»ç»Ÿæ¨¡å—åˆå§‹åŒ–å¤±è´¥: {str(e)}",
            message_type="error"
        )
    except Exception as send_error:
        logger.error(f"å‘é€é”™è¯¯é€šçŸ¥å¤±è´¥: {str(send_error)}", exc_info=True)
