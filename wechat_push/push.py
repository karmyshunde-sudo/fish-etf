#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¾®ä¿¡æ¨é€æ¨¡å—
æä¾›ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯æ¨é€åŠŸèƒ½ï¼Œæ”¯æŒæ–‡æœ¬å’ŒMarkdownæ ¼å¼
ç‰¹åˆ«ä¼˜åŒ–äº†æ—¶åŒºå¤„ç†ï¼Œç¡®ä¿æ‰€æœ‰æ—¶é—´æ˜¾ç¤ºä¸ºåŒ—äº¬æ—¶é—´
"""

import os
import requests
import time
import logging
import json
import pandas as pd
from typing import Optional, Dict, Any, List, Union
from datetime import datetime, timedelta
from config import Config
from utils.date_utils import (
    get_current_times,
    get_beijing_time,
    get_utc_time
)

# åˆå§‹åŒ–æ—¥å¿—
logger = logging.getLogger(__name__)

# æ¶ˆæ¯å‘é€é¢‘ç‡æ§åˆ¶
_last_send_time = 0.0  # ä½¿ç”¨æµ®ç‚¹æ•°ï¼Œé¿å…æ—¶åŒºé—®é¢˜
_MIN_SEND_INTERVAL = 3.5  # æœ€å°å‘é€é—´éš”(ç§’)ï¼Œç¡®ä¿æ¯åˆ†é’Ÿä¸è¶…è¿‡17æ¡æ¶ˆæ¯
_MAX_MESSAGE_LENGTH = 2000  # ä¼ä¸šå¾®ä¿¡æ¶ˆæ¯æœ€å¤§é•¿åº¦(å­—ç¬¦)
_MESSAGE_CHUNK_SIZE = 1500  # æ¶ˆæ¯åˆ†å—å¤§å°(å­—ç¬¦)

# å‘é€å¤±è´¥é‡è¯•é…ç½®
_MAX_RETRIES = 3
_RETRY_DELAYS = [2, 4, 8]  # é‡è¯•å»¶è¿Ÿ(ç§’)ï¼ŒæŒ‡æ•°é€€é¿ç­–ç•¥
_REQUEST_TIMEOUT = 5.0  # è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)

# é”™è¯¯æ¶ˆæ¯ç¼“å­˜ï¼Œç”¨äºé¿å…é‡å¤å‘é€ç›¸åŒé”™è¯¯
_error_message_cache = {}  # å­˜å‚¨é”™è¯¯æ¶ˆæ¯åŠå…¶ä¸Šæ¬¡å‘é€æ—¶é—´
# é”™è¯¯æ¶ˆæ¯å†·å´æ—¶é—´ï¼ˆç§’ï¼‰
_ERROR_COOLDOWN = 300  # 5åˆ†é’Ÿå†…ç›¸åŒé”™è¯¯åªå‘é€ä¸€æ¬¡

def get_github_actions_url() -> str:
    """è·å–GitHub Actionsè¿è¡Œæ—¥å¿—é“¾æ¥"""
    github_run_id = os.getenv("GITHUB_RUN_ID", "unknown")
    github_repository = os.getenv("GITHUB_REPOSITORY", "karmyshunde-sudo/fish-etf")
    
    if github_run_id == "unknown" or not github_run_id:
        return "æ— æ³•è·å–æ—¥å¿—é“¾æ¥"
    
    return f"https://github.com/{github_repository}/actions/runs/{github_run_id}"

def _extract_scalar_value(value, default=0.0, log_prefix=""):
    """
    å®‰å…¨åœ°ä»å„ç§ç±»å‹ä¸­æå–æ ‡é‡å€¼
    
    Args:
        value: å¯èƒ½æ˜¯æ ‡é‡ã€Seriesã€DataFrameã€å­—ç¬¦ä¸²ç­‰
        default: é»˜è®¤å€¼ï¼Œå¦‚æœæ— æ³•æå–æ ‡é‡å€¼
        log_prefix: æ—¥å¿—å‰ç¼€ï¼Œç”¨äºæ ‡è¯†è°ƒç”¨ä½ç½®
    
    Returns:
        float: æ ‡é‡å€¼
    """
    try:
        # å¦‚æœå·²ç»æ˜¯æ ‡é‡å€¼ï¼Œç›´æ¥è¿”å›
        if isinstance(value, (int, float)):
            return float(value)
        
        # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è½¬æ¢ä¸ºæµ®ç‚¹æ•°
        if isinstance(value, str):
            # å°è¯•ç§»é™¤éæ•°å­—å­—ç¬¦
            cleaned_str = ''.join(c for c in value if c.isdigit() or c in ['.', '-'])
            if cleaned_str:
                result = float(cleaned_str)
                logger.debug(f"{log_prefix}ä»å­—ç¬¦ä¸²æå–æ ‡é‡å€¼: '{value}' -> {result}")
                return result
            logger.warning(f"{log_prefix}æ— æ³•ä»å­—ç¬¦ä¸² '{value}' æå–æœ‰æ•ˆæ•°å­—ï¼Œä½¿ç”¨é»˜è®¤å€¼{default}")
            return default
        
        # å¦‚æœæ˜¯pandaså¯¹è±¡ï¼Œå°è¯•æå–æ ‡é‡å€¼
        if isinstance(value, (pd.Series, pd.DataFrame)):
            # å°è¯•è·å–ç¬¬ä¸€ä¸ªå€¼
            if value.size > 0:
                # å°è¯•ä½¿ç”¨.values.flatten()[0]ï¼ˆæœ€å¯é ï¼‰
                try:
                    result = float(value.values.flatten()[0])
                    logger.debug(f"{log_prefix}é€šè¿‡.values.flatten()[0]æå–æ ‡é‡å€¼: {result}")
                    return result
                except Exception as e:
                    # å°è¯•ä½¿ç”¨.item()
                    try:
                        result = float(value.item())
                        logger.debug(f"{log_prefix}é€šè¿‡.item()æå–æ ‡é‡å€¼: {result}")
                        return result
                    except Exception as e2:
                        # å°è¯•ä½¿ç”¨.iloc[0]
                        try:
                            valid_values = value[~pd.isna(value)]
                            if not valid_values.empty:
                                result = float(valid_values.iloc[0])
                                logger.debug(f"{log_prefix}é€šè¿‡.iloc[0]æå–æ ‡é‡å€¼: {result}")
                                return result
                        except Exception as e3:
                            pass
            
            logger.error(f"{log_prefix}æ— æ³•ä»pandaså¯¹è±¡æå–æ ‡é‡å€¼(size={value.size})ï¼Œä½¿ç”¨é»˜è®¤å€¼{default}")
            return default
        
        # å°è¯•ç›´æ¥è½¬æ¢ä¸ºæµ®ç‚¹æ•°
        result = float(value)
        logger.debug(f"{log_prefix}ç›´æ¥è½¬æ¢ä¸ºæµ®ç‚¹æ•°: {result}")
        return result
    
    except Exception as e:
        logger.error(f"{log_prefix}æ— æ³•ä»ç±»å‹ {type(value)} ä¸­æå–æ ‡é‡å€¼: {str(e)}ï¼Œä½¿ç”¨é»˜è®¤å€¼{default}")
        return default

def _extract_error_type(error_message: str) -> str:
    """
    ä»é”™è¯¯æ¶ˆæ¯ä¸­æå–é”™è¯¯ç±»å‹
    
    Args:
        error_message: å®Œæ•´çš„é”™è¯¯æ¶ˆæ¯
    
    Returns:
        str: é”™è¯¯ç±»å‹æ ‡è¯†
    """
    # æå–Tracebackä¸­çš„å…³é”®é”™è¯¯ä¿¡æ¯
    if "Traceback" in error_message:
        # å°è¯•æå–æœ€åä¸€è¡Œé”™è¯¯
        lines = error_message.split("\n")
        for line in reversed(lines):
            if "Error" in line or "Exception" in line or "KeyError" in line:
                return line.strip()
    
    # æå–"KeyError: 'xxx'"æ ¼å¼
    if "KeyError" in error_message:
        import re
        match = re.search(r"KeyError: '([^']+)'", error_message)
        if match:
            return f"KeyError: '{match.group(1)}'"
    
    # è¿”å›å‰50ä¸ªå­—ç¬¦ä½œä¸ºé”™è¯¯ç±»å‹
    return error_message[:50]

def _should_send_error(error_type: str) -> bool:
    """
    æ£€æŸ¥æ˜¯å¦åº”è¯¥å‘é€é”™è¯¯æ¶ˆæ¯
    
    Args:
        error_type: é”™è¯¯ç±»å‹æ ‡è¯†
    
    Returns:
        bool: æ˜¯å¦åº”è¯¥å‘é€
    """
    current_time = time.time()
    
    # æ£€æŸ¥æ˜¯å¦åœ¨å†·å´æœŸå†…
    if error_type in _error_message_cache:
        last_sent = _error_message_cache[error_type]
        # å¦‚æœåœ¨å†·å´æœŸå†…ï¼Œè§†ä¸ºé‡å¤æ¶ˆæ¯
        if current_time - last_sent < _ERROR_COOLDOWN:
            return False
    
    # æ›´æ–°ç¼“å­˜
    _error_message_cache[error_type] = current_time
    return True

def _should_send_message(message_tag: str) -> bool:
    """
    æ£€æŸ¥æ˜¯å¦åº”è¯¥å‘é€æ¶ˆæ¯ï¼ˆé¿å…ç›¸åŒç±»å‹æ¶ˆæ¯è¿‡äºé¢‘ç¹ï¼‰
    
    Args:
        message_tag: æ¶ˆæ¯ç±»å‹æ ‡è¯†
    
    Returns:
        bool: æ˜¯å¦åº”è¯¥å‘é€
    """
    current_time = time.time()
    
    # æ£€æŸ¥æ˜¯å¦åœ¨å†·å´æœŸå†…
    if message_tag in _error_message_cache:
        last_sent = _error_message_cache[message_tag]
        if current_time - last_sent < _ERROR_COOLDOWN:
            return False
    
    return True

def _update_last_send_time(message_tag: str) -> None:
    """
    æ›´æ–°æ¶ˆæ¯æœ€åå‘é€æ—¶é—´
    
    Args:
        message_tag: æ¶ˆæ¯ç±»å‹æ ‡è¯†
    """
    _error_message_cache[message_tag] = time.time()

def _get_message_tag(message: str) -> str:
    """
    è·å–æ¶ˆæ¯ç±»å‹æ ‡è¯†
    
    Args:
        message: æ¶ˆæ¯å†…å®¹
    
    Returns:
        str: æ¶ˆæ¯ç±»å‹æ ‡è¯†
    """
    # æå–å…³é”®æ ‡è¯†
    if "KeyError" in message:
        import re
        match = re.search(r"KeyError: '([^']+)'", message)
        if match:
            return f"KeyError_{match.group(1)}"
    
    if "SettingWithCopyWarning" in message:
        return "SettingWithCopyWarning"
    
    if "api freq out of limit" in message:
        return "API_Freq_Limit"
    
    # æŒ‰æ¶ˆæ¯å‰ç¼€åˆ†ç±»
    if message.startswith("ã€ç³»ç»Ÿé”™è¯¯ã€‘"):
        return "System_Error"
    if message.startswith("ã€ETFç­–ç•¥æ—¥æŠ¥ã€‘"):
        return "Daily_Report"
    if message.startswith("ã€ETFç­–ç•¥ã€‘"):
        return "Strategy_Message"
    
    # é»˜è®¤ä½¿ç”¨æ¶ˆæ¯çš„å“ˆå¸Œå€¼å‰10ä½
    import hashlib
    return hashlib.md5(message[:100].encode()).hexdigest()[:10]

def _check_message_length(message: str) -> List[str]:
    """
    æ£€æŸ¥æ¶ˆæ¯é•¿åº¦å¹¶è¿›è¡Œåˆ†ç‰‡å¤„ç†
    :param message: åŸå§‹æ¶ˆæ¯
    :return: åˆ†ç‰‡åçš„æ¶ˆæ¯åˆ—è¡¨
    """
    if not message or len(message) <= _MAX_MESSAGE_LENGTH:
        return [message]
    
    logger.warning(f"æ¶ˆæ¯è¿‡é•¿({len(message)}å­—ç¬¦)ï¼Œè¿›è¡Œåˆ†ç‰‡å¤„ç†")
    
    # æŒ‰æ®µè½åˆ†å‰²æ¶ˆæ¯
    paragraphs = message.split('\n\n')
    chunks = []
    current_chunk = ""
    
    for paragraph in paragraphs:
        # å¦‚æœå½“å‰å—åŠ ä¸Šæ–°æ®µè½ä¸ä¼šè¶…è¿‡é™åˆ¶
        if len(current_chunk) + len(paragraph) + 2 <= _MESSAGE_CHUNK_SIZE:
            if current_chunk:
                current_chunk += "\n\n" + paragraph
            else:
                current_chunk = paragraph
        else:
            # å¦‚æœå½“å‰å—æœ‰å†…å®¹ï¼Œå…ˆä¿å­˜
            if current_chunk:
                chunks.append(current_chunk)
                current_chunk = ""
            
            # å¦‚æœæ®µè½æœ¬èº«å°±å¾ˆé•¿ï¼Œéœ€è¦è¿›ä¸€æ­¥åˆ†å‰²
            if len(paragraph) > _MESSAGE_CHUNK_SIZE:
                # æŒ‰å¥å­åˆ†å‰²
                sentences = paragraph.split('\n')
                for sentence in sentences:
                    if len(current_chunk) + len(sentence) + 1 <= _MESSAGE_CHUNK_SIZE:
                        if current_chunk:
                            current_chunk += "\n" + sentence
                        else:
                            current_chunk = sentence
                    else:
                        if current_chunk:
                            chunks.append(current_chunk)
                            current_chunk = sentence
                        else:
                            # å•å¥å°±è¶…è¿‡é™åˆ¶ï¼Œå¼ºåˆ¶åˆ†å‰²
                            chunks.append(sentence[:_MESSAGE_CHUNK_SIZE])
                            current_chunk = sentence[_MESSAGE_CHUNK_SIZE:]
            else:
                current_chunk = paragraph
    
    # æ·»åŠ æœ€åä¸€ä¸ªå—
    if current_chunk:
        chunks.append(current_chunk)
    
    # æ·»åŠ åˆ†ç‰‡æ ‡è®°
    if len(chunks) > 1:
        for i, chunk in enumerate(chunks):
            chunks[i] = f"ã€æ¶ˆæ¯åˆ†ç‰‡ {i+1}/{len(chunks)}ã€‘\n\n{chunk}"
    
    logger.info(f"æ¶ˆæ¯å·²åˆ†å‰²ä¸º {len(chunks)} ä¸ªåˆ†ç‰‡")
    return chunks

def _rate_limit() -> None:
    """
    é€Ÿç‡é™åˆ¶ï¼Œé¿å…æ¶ˆæ¯å‘é€è¿‡äºé¢‘ç¹
    ä¸¥æ ¼éµå®ˆä¼ä¸šå¾®ä¿¡APIè°ƒç”¨é¢‘ç‡é™åˆ¶
    """
    global _last_send_time
    current_time = time.time()
    elapsed = current_time - _last_send_time
    
    # ç¡®ä¿è‡³å°‘é—´éš”_MIN_SEND_INTERVALç§’
    if elapsed < _MIN_SEND_INTERVAL:
        sleep_time = _MIN_SEND_INTERVAL - elapsed
        logger.debug(f"é€Ÿç‡é™åˆ¶ï¼šç­‰å¾… {sleep_time:.2f} ç§’ä»¥éµå®ˆAPIè°ƒç”¨é¢‘ç‡é™åˆ¶")
        time.sleep(sleep_time)
    
    # æ›´æ–°æœ€åå‘é€æ—¶é—´
    _last_send_time = time.time()

def _send_single_message(webhook: str, message: str, retry_count: int = 0) -> bool:
    """
    å‘é€å•æ¡æ¶ˆæ¯åˆ°ä¼ä¸šå¾®ä¿¡
    :param webhook: ä¼ä¸šå¾®ä¿¡Webhookåœ°å€
    :param message: æ¶ˆæ¯å†…å®¹
    :param retry_count: å½“å‰é‡è¯•æ¬¡æ•°
    :return: æ˜¯å¦å‘é€æˆåŠŸ
    """
    try:
        # é€Ÿç‡é™åˆ¶
        _rate_limit()
        
        # ä¼ä¸šå¾®ä¿¡æ–‡æœ¬æ¶ˆæ¯æ ¼å¼
        payload = {
            "msgtype": "text",
            "text": {
                "content": message
            }
        }
        
        logger.debug(f"å‘é€æ¶ˆæ¯åˆ°ä¼ä¸šå¾®ä¿¡ (é‡è¯• {retry_count}): {message[:100]}...")
        response = requests.post(webhook, json=payload, timeout=_REQUEST_TIMEOUT)
        response.raise_for_status()
        result = response.json()
        
        if result.get("errcode") == 0:
            logger.info("å¾®ä¿¡æ¶ˆæ¯å‘é€æˆåŠŸ")
            return True
        else:
            error_msg = result.get('errmsg', 'æœªçŸ¥é”™è¯¯')
            logger.error(f"å¾®ä¿¡æ¶ˆæ¯å‘é€å¤±è´¥: {error_msg}")
            return False
            
    except requests.exceptions.Timeout:
        logger.error(f"å¾®ä¿¡æ¶ˆæ¯å‘é€è¶…æ—¶ (é‡è¯• {retry_count})")
        return False
    except requests.exceptions.ConnectionError:
        logger.error(f"ç½‘ç»œè¿æ¥é”™è¯¯ (é‡è¯• {retry_count})")
        return False
    except requests.exceptions.RequestException as e:
        logger.error(f"è¯·æ±‚å¼‚å¸¸: {str(e)} (é‡è¯• {retry_count})")
        return False
    except Exception as e:
        logger.error(f"å‘é€æ¶ˆæ¯æ—¶å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {str(e)} (é‡è¯• {retry_count})", exc_info=True)
        return False

def _get_recommendation(score: float) -> str:
    """
    æ ¹æ®è¯„åˆ†è·å–æ¨èçº§åˆ«
    
    Args:
        score: ETFè¯„åˆ†ï¼ˆ0-100åˆ†ï¼‰
    
    Returns:
        str: æ¨èçº§åˆ«
    """
    try:
        score = float(score)
        if score >= 80:
            return "å¼ºçƒˆæ¨èä¹°å…¥"
        elif score >= 60:
            return "æ¨èä¹°å…¥"
        elif score >= 40:
            return "å¯ä»¥è€ƒè™‘ä¹°å…¥"
        elif score >= 20:
            return "è§‚æœ›"
        else:
            return "ä¸å»ºè®®ä¹°å…¥"
    except Exception as e:
        logger.error(f"è·å–æ¨èçº§åˆ«å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨é»˜è®¤å€¼'ä¸å»ºè®®ä¹°å…¥'")
        return "ä¸å»ºè®®ä¹°å…¥"

def _format_discount_message(df: pd.DataFrame) -> List[str]:
    """
    æ ¼å¼åŒ–æŠ˜ä»·æœºä¼šæ¶ˆæ¯ï¼Œåˆ†é¡µå¤„ç†
    
    Args:
        df: æŠ˜ä»·æœºä¼šDataFrame
    
    Returns:
        List[str]: åˆ†é¡µåçš„æ¶ˆæ¯åˆ—è¡¨
    """
    try:
        # æŒ‰æŠ˜ä»·ç‡é™åºæ’åºï¼ˆæœ€é«˜æŠ˜ä»·ä¼˜å…ˆï¼‰
        df = df.sort_values(by='æŠ˜æº¢ä»·ç‡', ascending=True).reset_index(drop=True)
        
        if df.empty:
            return ["ã€æŠ˜ä»·æœºä¼šã€‘\næœªå‘ç°æœ‰æ•ˆæŠ˜ä»·å¥—åˆ©æœºä¼š"]
        
        # æ¯é¡µæ˜¾ç¤ºçš„ETFæ•°é‡
        ETFS_PER_PAGE = 5
        total_etfs = len(df)
        total_pages = (total_etfs + ETFS_PER_PAGE - 1) // ETFS_PER_PAGE  # å‘ä¸Šå–æ•´
        
        # è·å–å½“å‰åŒæ—¶åŒºæ—¶é—´
        utc_now, beijing_now = get_current_times()
        
        # ç”ŸæˆGitHubæ—¥å¿—é“¾æ¥
        log_url = get_github_actions_url()
        
        messages = []
        
        # ç¬¬1é¡µï¼šå°é¢é¡µ
        if total_pages > 0:
            page1 = (
                "ã€ä»¥ä¸‹ETFå¸‚åœºä»·æ ¼ä½äºå‡€å€¼ï¼Œå¯ä»¥è€ƒè™‘ä¹°å…¥ã€‘\n\n"
                f"ğŸ’“å…±{total_etfs}åªETFï¼Œåˆ†{total_pages}æ¡æ¶ˆæ¯æ¨é€ï¼Œè¿™æ˜¯ç¬¬1/{total_pages}æ¡æ¶ˆæ¯\n\n"
                "ğŸ’¡ è¯´æ˜ï¼šå½“ETFå¸‚åœºä»·æ ¼ä½äºIOPVï¼ˆåŸºé‡‘ä»½é¢å‚è€ƒå‡€å€¼ï¼‰æ—¶ï¼Œè¡¨æ˜ETFæŠ˜ä»·äº¤æ˜“\n"
                f"ğŸ“Š ç­›é€‰æ¡ä»¶ï¼šåŸºé‡‘è§„æ¨¡â‰¥{Config.GLOBAL_MIN_FUND_SIZE}äº¿å…ƒï¼Œæ—¥å‡æˆäº¤é¢â‰¥{Config.GLOBAL_MIN_AVG_VOLUME}ä¸‡å…ƒ\n"
                f"ğŸ’° äº¤æ˜“æˆæœ¬ï¼š{Config.TRADE_COST_RATE*100:.2f}%ï¼ˆå«å°èŠ±ç¨å’Œä½£é‡‘ï¼‰\n"
                f"ğŸ¯ æŠ˜ä»·é˜ˆå€¼ï¼šæŠ˜ä»·ç‡è¶…è¿‡{Config.DISCOUNT_THRESHOLD*100:.2f}%\n"
                f"â­ ç»¼åˆè¯„åˆ†ï¼šâ‰¥{Config.ARBITRAGE_SCORE_THRESHOLD:.1f}"
            )
            messages.append(page1)
        
        # åç»­é¡µï¼šETFè¯¦æƒ…ï¼ˆæ¯é¡µ5åªETFï¼‰
        for page in range(total_pages):
            start_idx = page * ETFS_PER_PAGE
            end_idx = min(start_idx + ETFS_PER_PAGE, total_etfs)
            
            # ç”Ÿæˆå½“å‰é¡µçš„ETFè¯¦æƒ…
            content = f"ã€ç°ä»·æ¯”å‡€å€¼ä½ï¼Œä¹°å…¥ã€‚ {page+1}/{total_pages}ã€‘\n"
            
            for i, (_, row) in enumerate(df.iloc[start_idx:end_idx].iterrows(), start_idx + 1):
                etf_code = str(row.get('ETFä»£ç ', 'æœªçŸ¥'))
                etf_name = str(row.get('ETFåç§°', 'æœªçŸ¥'))
                
                premium_discount = _extract_scalar_value(row.get('æŠ˜æº¢ä»·ç‡', 0.0), log_prefix=f"ETF {etf_code} æŠ˜æº¢ä»·ç‡: ")
                market_price = _extract_scalar_value(row.get('å¸‚åœºä»·æ ¼', 0.0), log_prefix=f"ETF {etf_code} å¸‚åœºä»·æ ¼: ")
                iopv = _extract_scalar_value(row.get('IOPV', 0.0), log_prefix=f"ETF {etf_code} IOPV: ")
                fund_size = _extract_scalar_value(row.get('è§„æ¨¡', 0.0), log_prefix=f"ETF {etf_code} è§„æ¨¡: ")
                avg_volume = _extract_scalar_value(row.get('æ—¥å‡æˆäº¤é¢', 0.0), log_prefix=f"ETF {etf_code} æ—¥å‡æˆäº¤é¢: ")
                score = _extract_scalar_value(row.get('ç»¼åˆè¯„åˆ†', 0.0), log_prefix=f"ETF {etf_code} ç»¼åˆè¯„åˆ†: ")
                
                # æ˜ç¡®æŒ‡å‡ºè¯„åˆ†æ˜¯å¦ä½äºé˜ˆå€¼
                score_info = f"{abs(score):.2f}åˆ†"
                if score < Config.ARBITRAGE_SCORE_THRESHOLD:
                    score_info += f" âš ï¸(ä½äºé˜ˆå€¼{Config.ARBITRAGE_SCORE_THRESHOLD:.1f})"
                
                content += (
                    f"\n{i}. {etf_name} ({etf_code})\n"
                    f"   â­ ç»¼åˆè¯„åˆ†: {score_info}\n"
                    f"   ğŸ’¹ æŠ˜ä»·ç‡: {abs(premium_discount):.2f}%\n"
                    f"   ğŸ“ˆ å¸‚åœºä»·æ ¼: {market_price:.3f}å…ƒ\n"
                    f"   ğŸ“Š IOPV: {iopv:.3f}å…ƒ\n"
                    f"   ğŸ¦ åŸºé‡‘è§„æ¨¡: {fund_size:.2f}äº¿å…ƒ\n"
                    f"   ğŸ’° æ—¥å‡æˆäº¤é¢: {avg_volume:.2f}ä¸‡å…ƒ\n"
                )
                
                # æ·»åŠ é¢å¤–è¯´æ˜ï¼Œç‰¹åˆ«æ˜¯å¯¹é«˜æŠ˜ä»·ä½†ä½è¯„åˆ†çš„æƒ…å†µ
                if abs(premium_discount) > 5.0 and score < Config.ARBITRAGE_SCORE_THRESHOLD:
                    content += f"   ğŸ“Œ è¯´æ˜: é«˜æŠ˜ä»·æœºä¼š({abs(premium_discount):.2f}%)ï¼Œä½†ç»¼åˆè¯„åˆ†è¾ƒä½ï¼Œå»ºè®®è°¨æ…æ“ä½œ\n"
                elif abs(premium_discount) > Config.DISCOUNT_THRESHOLD * 2:
                    content += f"   ğŸ“Œ è¯´æ˜: æé«˜æŠ˜ä»·æœºä¼šï¼Œå»ºè®®é‡ç‚¹å…³æ³¨\n"
                elif score < Config.ARBITRAGE_SCORE_THRESHOLD:
                    content += f"   ğŸ“Œ è¯´æ˜: æŠ˜ä»·ç‡è¾¾æ ‡ï¼Œä½†ç»¼åˆè¯„åˆ†è¾ƒä½ï¼Œå»ºè®®è°¨æ…æ“ä½œ\n"
            
            messages.append(content)
        
        return messages
    
    except Exception as e:
        error_msg = f"ç”ŸæˆæŠ˜ä»·æ¶ˆæ¯å†…å®¹å¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        return [f"ã€æŠ˜ä»·ç­–ç•¥ã€‘ç”Ÿæˆæ¶ˆæ¯å†…å®¹æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·æ£€æŸ¥æ—¥å¿—"]

# æº¢ä»·æ¶ˆæ¯å‡½æ•°åŒæ­¥ä¿®æ”¹
def _format_premium_message(df: pd.DataFrame) -> List[str]:
    """
    æ ¼å¼åŒ–æº¢ä»·æœºä¼šæ¶ˆæ¯ï¼Œåˆ†é¡µå¤„ç†
    
    Args:
        df: æº¢ä»·æœºä¼šDataFrame
    
    Returns:
        List[str]: åˆ†é¡µåçš„æ¶ˆæ¯åˆ—è¡¨
    """
    try:
        # æŒ‰æº¢ä»·ç‡é™åºæ’åºï¼ˆæœ€é«˜æº¢ä»·ä¼˜å…ˆï¼‰
        df = df.sort_values(by='æŠ˜æº¢ä»·ç‡', ascending=False).reset_index(drop=True)
        
        if df.empty:
            return ["ã€æº¢ä»·æœºä¼šã€‘\næœªå‘ç°æœ‰æ•ˆæº¢ä»·å¥—åˆ©æœºä¼š"]
        
        # æ¯é¡µæ˜¾ç¤ºçš„ETFæ•°é‡
        ETFS_PER_PAGE = 5
        total_etfs = len(df)
        total_pages = (total_etfs + ETFS_PER_PAGE - 1) // ETFS_PER_PAGE  # å‘ä¸Šå–æ•´
        
        # è·å–å½“å‰åŒæ—¶åŒºæ—¶é—´
        utc_now, beijing_now = get_current_times()
        
        messages = []
        
        # ç¬¬1é¡µï¼šå°é¢é¡µ
        if total_pages > 0:
            page1 = (
                "ã€ä»¥ä¸‹ETFå¸‚åœºä»·æ ¼é«˜äºå‡€å€¼ï¼Œå¯ä»¥è€ƒè™‘å–å‡ºã€‘\n\n"
                f"ğŸ’“å…±{total_etfs}åªETFï¼Œåˆ†{total_pages}æ¡æ¶ˆæ¯æ¨é€ï¼Œè¿™æ˜¯ç¬¬1/{total_pages}æ¡æ¶ˆæ¯\n\n"
                "ğŸ’¡ è¯´æ˜ï¼šå½“ETFå¸‚åœºä»·æ ¼é«˜äºIOPVï¼ˆåŸºé‡‘ä»½é¢å‚è€ƒå‡€å€¼ï¼‰æ—¶ï¼Œè¡¨æ˜ETFæº¢ä»·äº¤æ˜“\n"
                f"ğŸ“Š ç­›é€‰æ¡ä»¶ï¼šåŸºé‡‘è§„æ¨¡â‰¥{Config.GLOBAL_MIN_FUND_SIZE}äº¿å…ƒï¼Œæ—¥å‡æˆäº¤é¢â‰¥{Config.GLOBAL_MIN_AVG_VOLUME}ä¸‡å…ƒ\n"
                f"ğŸ’° äº¤æ˜“æˆæœ¬ï¼š{Config.TRADE_COST_RATE*100:.2f}%ï¼ˆå«å°èŠ±ç¨å’Œä½£é‡‘ï¼‰\n"
                f"ğŸ¯ æº¢ä»·é˜ˆå€¼ï¼šæº¢ä»·ç‡è¶…è¿‡{Config.PREMIUM_THRESHOLD*100:.2f}%\n"
                f"â­ ç»¼åˆè¯„åˆ†ï¼šâ‰¥{Config.ARBITRAGE_SCORE_THRESHOLD:.1f}"
            )
            messages.append(page1)
        
        # åç»­é¡µï¼šETFè¯¦æƒ…ï¼ˆæ¯é¡µ5åªETFï¼‰
        for page in range(total_pages):
            start_idx = page * ETFS_PER_PAGE
            end_idx = min(start_idx + ETFS_PER_PAGE, total_etfs)
            
            # ç”Ÿæˆå½“å‰é¡µçš„ETFè¯¦æƒ…
            content = f"ã€ç°ä»·æ¯”å‡€å€¼é«˜ï¼Œå–å‡ºã€‚ {page+1}/{total_pages}ã€‘\n"
            
            for i, (_, row) in enumerate(df.iloc[start_idx:end_idx].iterrows(), start_idx + 1):
                etf_code = str(row.get('ETFä»£ç ', 'æœªçŸ¥'))
                etf_name = str(row.get('ETFåç§°', 'æœªçŸ¥'))
                
                premium_discount = _extract_scalar_value(row.get('æŠ˜æº¢ä»·ç‡', 0.0), log_prefix=f"ETF {etf_code} æŠ˜æº¢ä»·ç‡: ")
                market_price = _extract_scalar_value(row.get('å¸‚åœºä»·æ ¼', 0.0), log_prefix=f"ETF {etf_code} å¸‚åœºä»·æ ¼: ")
                iopv = _extract_scalar_value(row.get('IOPV', 0.0), log_prefix=f"ETF {etf_code} IOPV: ")
                fund_size = _extract_scalar_value(row.get('è§„æ¨¡', 0.0), log_prefix=f"ETF {etf_code} è§„æ¨¡: ")
                avg_volume = _extract_scalar_value(row.get('æ—¥å‡æˆäº¤é¢', 0.0), log_prefix=f"ETF {etf_code} æ—¥å‡æˆäº¤é¢: ")
                score = _extract_scalar_value(row.get('ç»¼åˆè¯„åˆ†', 0.0), log_prefix=f"ETF {etf_code} ç»¼åˆè¯„åˆ†: ")
                
                # æ˜ç¡®æŒ‡å‡ºè¯„åˆ†æ˜¯å¦ä½äºé˜ˆå€¼
                score_info = f"{score:.2f}åˆ†"
                if score < Config.ARBITRAGE_SCORE_THRESHOLD:
                    score_info += f" âš ï¸(ä½äºé˜ˆå€¼{Config.ARBITRAGE_SCORE_THRESHOLD:.1f})"
                
                content += (
                    f"\n{i}. {etf_name} ({etf_code})\n"
                    f"   â­ ç»¼åˆè¯„åˆ†: {score_info}\n"
                    f"   ğŸ’¹ æº¢ä»·ç‡: {abs(premium_discount):.2f}%\n"
                    f"   ğŸ“ˆ å¸‚åœºä»·æ ¼: {market_price:.3f}å…ƒ\n"
                    f"   ğŸ“Š IOPV: {iopv:.3f}å…ƒ\n"
                    f"   ğŸ¦ åŸºé‡‘è§„æ¨¡: {fund_size:.2f}äº¿å…ƒ\n"
                    f"   ğŸ’° æ—¥å‡æˆäº¤é¢: {avg_volume:.2f}ä¸‡å…ƒ\n"
                )
                
                # æ·»åŠ é¢å¤–è¯´æ˜ï¼Œç‰¹åˆ«æ˜¯å¯¹é«˜æº¢ä»·ä½†ä½è¯„åˆ†çš„æƒ…å†µ
                if premium_discount > 5.0 and score < Config.ARBITRAGE_SCORE_THRESHOLD:
                    content += f"   ğŸ“Œ è¯´æ˜: é«˜æº¢ä»·æœºä¼š({premium_discount:.2f}%)ï¼Œä½†ç»¼åˆè¯„åˆ†è¾ƒä½ï¼Œå»ºè®®è°¨æ…æ“ä½œ\n"
                elif premium_discount > Config.PREMIUM_THRESHOLD * 2:
                    content += f"   ğŸ“Œ è¯´æ˜: æé«˜æº¢ä»·æœºä¼šï¼Œå»ºè®®é‡ç‚¹å…³æ³¨\n"
                elif score < Config.ARBITRAGE_SCORE_THRESHOLD:
                    content += f"   ğŸ“Œ è¯´æ˜: æº¢ä»·ç‡è¾¾æ ‡ï¼Œä½†ç»¼åˆè¯„åˆ†è¾ƒä½ï¼Œå»ºè®®è°¨æ…æ“ä½œ\n"
            
            messages.append(content)
        
        return messages
    
    except Exception as e:
        error_msg = f"ç”Ÿæˆæº¢ä»·æ¶ˆæ¯å†…å®¹å¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        return [f"ã€æº¢ä»·ç­–ç•¥ã€‘ç”Ÿæˆæ¶ˆæ¯å†…å®¹æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·æ£€æŸ¥æ—¥å¿—"]

def _format_position_message(strategies: Dict[str, str]) -> List[str]:
    """
    æ ¼å¼åŒ–ä»“ä½ç­–ç•¥æ¶ˆæ¯ï¼Œåˆ†é¡µå¤„ç†
    
    Args:
        strategies: ç­–ç•¥å­—å…¸
    
    Returns:
        List[str]: åˆ†é¡µåçš„æ¶ˆæ¯åˆ—è¡¨
    """
    try:
        # æ¯é¡µæ˜¾ç¤ºçš„ç­–ç•¥æ•°é‡
        STRATEGIES_PER_PAGE = 1  # æ¯é¡µåªæ˜¾ç¤ºä¸€ä¸ªä»“ä½ç±»å‹
        total_strategies = len(strategies)
        total_pages = (total_strategies + STRATEGIES_PER_PAGE - 1) // STRATEGIES_PER_PAGE  # å‘ä¸Šå–æ•´
        
        # è·å–å½“å‰åŒæ—¶åŒºæ—¶é—´
        utc_now, beijing_now = get_current_times()
        
        # ç”ŸæˆGitHubæ—¥å¿—é“¾æ¥
        log_url = get_github_actions_url()
        
        # é¡µè„šæ¨¡æ¿
        footer = (
            "\n==================\n"
            f"ğŸ“… UTCæ—¶é—´: {utc_now.strftime('%Y-%m-%d %H:%M:%S')}\n"
            f"ğŸ“… åŒ—äº¬æ—¶é—´: {beijing_now.strftime('%Y-%m-%d %H:%M:%S')}\n"
            "==================\n"
            # f"ğŸ”— ã€GITï¼šfish-etfã€‘: {log_url}\n"
            "ğŸ“Š ç¯å¢ƒï¼šã€GITï¼šfish-etfã€‘"
        )
        
        messages = []
        
        # ç”Ÿæˆæ¯é¡µçš„ç­–ç•¥è¯¦æƒ…
        for page, (position_type, strategy) in enumerate(strategies.items(), 1):
            content = (
                f"ã€ETFä»“ä½æ“ä½œæç¤ºã€‘\n"
                f"ï¼ˆæ¯ä¸ªä»“ä½ä»…æŒæœ‰1åªETFï¼Œæ“ä½œå»ºè®®åŸºäºæœ€æ–°æ•°æ®ï¼‰\n\n"
                f"ã€{position_type}ã€‘\n{strategy}"
            )
            
            # æ·»åŠ é¡µè„š
            # content += footer
            messages.append(content)
        
        return messages
    
    except Exception as e:
        error_msg = f"ç”Ÿæˆä»“ä½æ¶ˆæ¯å†…å®¹å¤±è´¥: {str(e)}"
        logger.error(error_msg, exc_info=True)
        return [f"ã€ä»“ä½ç­–ç•¥ã€‘ç”Ÿæˆæ¶ˆæ¯å†…å®¹æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·æ£€æŸ¥æ—¥å¿—"]

def _apply_message_template(message: Union[str, pd.DataFrame, Dict], message_type: str) -> Union[str, List[str]]:
    """
    åº”ç”¨å¯¹åº”ç±»å‹çš„æ¶ˆæ¯æ¨¡æ¿
    :param message: åŸå§‹æ¶ˆæ¯å†…å®¹ï¼ˆå¯ä»¥æ˜¯å­—ç¬¦ä¸²ã€DataFrameæˆ–å­—å…¸ï¼‰
    :param message_type: æ¶ˆæ¯ç±»å‹
    :return: æ ¼å¼åŒ–åçš„æ¶ˆæ¯ï¼ˆå­—ç¬¦ä¸²æˆ–æ¶ˆæ¯åˆ—è¡¨ï¼‰
    """
    try:
        # è·å–å½“å‰åŒæ—¶åŒºæ—¶é—´
        utc_now, beijing_now = get_current_times()
        log_url = get_github_actions_url()
        
        # å…¨å±€æ¶ˆæ¯è„šæ¨¡æ¿
        footer = (
            "\n==================\n"
            f"ğŸ“… åŒ—äº¬æ—¶é—´: {beijing_now.strftime('%Y-%m-%d %H:%M:%S')}\n"
            "ğŸ“Š ç¯å¢ƒï¼šGit-fish-etf"
        )
        
        # æ ¹æ®æ¶ˆæ¯ç±»å‹åº”ç”¨ä¸åŒçš„æ¨¡æ¿
        if message_type == "task":
            return f"{message}{footer}"
        elif message_type == "position":
            return f"{message}{footer}"
        elif message_type == "error":
            return f"âš ï¸ {message}{footer}"
        elif message_type == "daily_report":
            return f"{message}{footer}"
        else:
            return f"{message}{footer}"
    except Exception as e:
        logger.error(f"åº”ç”¨æ¶ˆæ¯æ¨¡æ¿å¤±è´¥: {str(e)}", exc_info=True)
        # è¿”å›ä¸€ä¸ªåŸºæœ¬æ ¼å¼çš„æ¶ˆæ¯
        return (
            f"{message}"
            "\n==================\n"
            "ğŸ“… æ—¶é—´: æ— æ³•è·å–\n"
            "\n==================\n"
            "ğŸ“Š æ•°æ®æ¥æºï¼šGit-fish-etf\n"
            "âš ï¸ æ³¨æ„: æ¶ˆæ¯æ ¼å¼åŒ–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯\n"
        )

def send_wechat_message(message: Union[str, pd.DataFrame, Dict], 
                       message_type: str = "default",
                       webhook: Optional[str] = None) -> bool:
    """
    å‘é€æ¶ˆæ¯åˆ°ä¼ä¸šå¾®ä¿¡ï¼Œè‡ªåŠ¨åº”ç”¨æ¶ˆæ¯æ¨¡æ¿
    
    Args:
        message: æ¶ˆæ¯å†…å®¹ï¼ˆçº¯ä¸šåŠ¡å†…å®¹ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²ã€DataFrameæˆ–å­—å…¸ï¼‰
        message_type: æ¶ˆæ¯ç±»å‹ï¼ˆtask, discount, premium, position, error, daily_reportç­‰ï¼‰
        webhook: ä¼ä¸šå¾®ä¿¡Webhookåœ°å€
        
    Returns:
        bool: æ˜¯å¦æˆåŠŸå‘é€
    """
    try:
        # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºæ¶ˆæ¯
        if message is None:
            logger.warning("å°è¯•å‘é€ç©ºæ¶ˆæ¯ï¼Œå·²å¿½ç•¥")
            return False
        
        # ç±»å‹å®‰å…¨è½¬æ¢ï¼šç¡®ä¿messageæ˜¯å­—ç¬¦ä¸²
        if isinstance(message, pd.DataFrame):
            # æ£€æŸ¥DataFrameæ˜¯å¦ä¸ºç©º
            if message.empty:
                logger.warning("å°è¯•å‘é€ç©ºDataFrameï¼Œå·²å¿½ç•¥")
                return False
            # è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼ˆä½¿ç”¨æ›´å‹å¥½çš„æ ¼å¼ï¼‰
            messages = _format_dataframe_as_string(message)
        elif isinstance(message, dict):
            # å¦‚æœæ˜¯å­—å…¸ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºç©º
            if not message:
                logger.warning("å°è¯•å‘é€ç©ºå­—å…¸ï¼Œå·²å¿½ç•¥")
                return False
            messages = [str(message)]
        else:
            messages = [str(message)]
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºå­—ç¬¦ä¸²
        if not any(msg.strip() for msg in messages):
            logger.warning("å°è¯•å‘é€ç©ºå­—ç¬¦ä¸²æ¶ˆæ¯ï¼Œå·²å¿½ç•¥")
            return False
        
        # ç‰¹æ®Šå¤„ç†é”™è¯¯æ¶ˆæ¯ï¼Œé¿å…é¢‘ç¹å‘é€
        if message_type == "error":
            # æå–é”™è¯¯ç±»å‹ï¼ˆä¾‹å¦‚"KeyError: 'fundamental'"ï¼‰
            error_type = _extract_error_type(messages[0])
            
            # æ£€æŸ¥æ˜¯å¦åœ¨å†·å´æœŸå†…
            if not _should_send_error(error_type):
                logger.info(f"é”™è¯¯æ¶ˆæ¯åœ¨å†·å´æœŸå†…ï¼Œè·³è¿‡å‘é€: {error_type}")
                return False
        
        # ä»ç¯å¢ƒå˜é‡è·å–Webhookï¼ˆä¼˜å…ˆäºé…ç½®æ–‡ä»¶ï¼‰
        if webhook is None:
            webhook = os.getenv("WECOM_WEBHOOK", Config.WECOM_WEBHOOK)
        if not webhook:
            logger.error("ä¼ä¸šå¾®ä¿¡Webhookæœªé…ç½®ï¼Œæ— æ³•å‘é€æ¶ˆæ¯")
            return False
            
        # åº”ç”¨æ¶ˆæ¯æ¨¡æ¿å¹¶å‘é€æ‰€æœ‰åˆ†é¡µæ¶ˆæ¯
        all_success = True
        for msg in messages:
            # ä»…å¯¹positionç±»å‹åº”ç”¨åº•éƒ¨æ ¼å¼
            if message_type == "position":
                # ã€æ—¥æœŸdatetimeç±»å‹è§„åˆ™ã€‘ç¡®ä¿æ—¥æœŸåœ¨å†…å­˜ä¸­æ˜¯datetimeç±»å‹
                beijing_time = get_beijing_time()
                utc_time = get_utc_time()
                # æ·»åŠ åº•éƒ¨æ ¼å¼
                footer = f"\n\n==================\n"
                footer += f"ğŸ“… UTCæ—¶é—´: {utc_time.strftime('%Y-%m-%d %H:%M:%S')}\n"
                footer += f"ğŸ“… åŒ—äº¬æ—¶é—´: {beijing_time.strftime('%Y-%m-%d %H:%M:%S')}\n"
                footer += "ğŸ“Š ç¯å¢ƒï¼šç”Ÿäº§\n"
                footer += f"ğŸ“… åŒ—äº¬æ—¶é—´: {beijing_time.strftime('%Y-%m-%d %H:%M:%S')}\n"
                footer += "ğŸ“Š ç¯å¢ƒï¼šGit-fish-etf"
                
                full_message = msg + footer
            else:
                full_message = _apply_message_template(msg, message_type)
            
            # æ£€æŸ¥æ¶ˆæ¯é•¿åº¦å¹¶è¿›è¡Œåˆ†ç‰‡
            messages_to_send = _check_message_length(full_message)
            
            for i, msg_part in enumerate(messages_to_send):
                # é€Ÿç‡é™åˆ¶
                _rate_limit()
                
                # é‡è¯•æœºåˆ¶
                success = False
                for retry in range(_MAX_RETRIES):
                    if _send_single_message(webhook, msg_part, retry):
                        success = True
                        break
                    else:
                        if retry < _MAX_RETRIES - 1:
                            delay = _RETRY_DELAYS[retry]
                            logger.warning(f"å‘é€å¤±è´¥ï¼Œ{delay}ç§’åé‡è¯• ({retry+1}/{_MAX_RETRIES})")
                            time.sleep(delay)
                            
                if not success:
                    logger.error(f"æ¶ˆæ¯åˆ†ç‰‡ {i+1} å‘é€å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°")
                    all_success = False
                
        return all_success
        
    except Exception as e:
        logger.error(f"å‘é€å¾®ä¿¡æ¶ˆæ¯æ—¶å‘ç”Ÿæœªé¢„æœŸé”™è¯¯: {str(e)}", exc_info=True)
        return False

def _format_dataframe_as_string(df: pd.DataFrame) -> List[str]:
    """
    å°† DataFrameæ ¼å¼åŒ–ä¸ºå¤šæ¡æ¶ˆæ¯ï¼ˆæ¯æ¡ä¸è¶…è¿‡2000å­—ç¬¦ï¼‰
    
    Args:
        df: è¦æ ¼å¼åŒ–çš„DataFrame
        
    Returns:
        List[str]: åˆ†é¡µåçš„æ¶ˆæ¯åˆ—è¡¨
    """
    try:
        if df.empty:
            return ["æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ•°æ®"]
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ETFç‰¹å®šåˆ—
        has_etf_info = "ETFä»£ç " in df.columns and "ETFåç§°" in df.columns
        has_premium_discount = "æŠ˜æº¢ä»·ç‡" in df.columns
        
        if has_etf_info and has_premium_discount:
            # ç›´æ¥è°ƒç”¨å·²å®šä¹‰çš„ä¸“ç”¨æ ¼å¼åŒ–å‡½æ•°
            if df["æŠ˜æº¢ä»·ç‡"].min() < 0:
                return _format_discount_message(df)
            else:
                return _format_premium_message(df)
        
        # éETFåœºæ™¯
        logger.warning("å°è¯•æ ¼å¼åŒ–éETFæ•°æ®ï¼Œè¿™å¯èƒ½è¡¨ç¤ºä»£ç é€»è¾‘æœ‰è¯¯")
        return [f"æ‰¾åˆ° {len(df)} æ¡æ•°æ®ï¼Œä½†ä¸æ˜¯ETFæ•°æ®æ ¼å¼"]
    
    except Exception as e:
        logger.error(f"æ ¼å¼åŒ–DataFrameä¸ºå­—ç¬¦ä¸²å¤±è´¥: {str(e)}", exc_info=True)
        return ["æ•°æ®æ ¼å¼åŒ–é”™è¯¯ï¼Œè¯·æ£€æŸ¥æ—¥å¿—"]

def send_wechat_markdown(message: str, 
                        message_type: str = "default",
                        webhook: Optional[str] = None) -> bool:
    """
    å‘é€Markdownæ ¼å¼æ¶ˆæ¯åˆ°ä¼ä¸šå¾®ä¿¡
    
    Args:
        message: Markdownæ ¼å¼æ¶ˆæ¯
        message_type: æ¶ˆæ¯ç±»å‹
        webhook: ä¼ä¸šå¾®ä¿¡Webhookåœ°å€
        
    Returns:
        bool: æ˜¯å¦æˆåŠŸå‘é€
    """
    try:
        # ä»ç¯å¢ƒå˜é‡è·å–Webhookï¼ˆä¼˜å…ˆäºé…ç½®æ–‡ä»¶ï¼‰
        if webhook is None:
            webhook = os.getenv("WECOM_WEBHOOK", Config.WECOM_WEBHOOK)
        
        if not webhook:
            logger.error("ä¼ä¸šå¾®ä¿¡Webhookæœªé…ç½®ï¼Œæ— æ³•å‘é€æ¶ˆæ¯")
            return False
        
        # é€Ÿç‡é™åˆ¶
        _rate_limit()
        
        # è·å–å½“å‰åŒæ—¶åŒºæ—¶é—´
        utc_now, beijing_now = get_current_times()
        
        # ç”ŸæˆGitHubæ—¥å¿—é“¾æ¥
        log_url = get_github_actions_url()
        
        # æ·»åŠ ç»Ÿä¸€çš„é¡µè„š
        footer = (
            "\n\n"
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
            f"ğŸ•’ **UTCæ—¶é—´**: {utc_now.strftime('%Y-%m-%d %H:%M:%S')}\n"
            f"ğŸ“… **åŒ—äº¬æ—¶é—´**: {beijing_now.strftime('%Y-%m-%d %H:%M:%S')}\n"
            "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
            # f"ğŸ”— ã€GITï¼šfish-etfã€‘: {log_url}\n"
            f"ğŸ”— ã€GITï¼šfish-etfã€‘\n"
        )
        
        # å®Œæ•´æ¶ˆæ¯
        # full_message = message + footer
        full_message = message
        
        # ä¼ä¸šå¾®ä¿¡Markdownæ¶ˆæ¯æ ¼å¼
        payload = {
            "msgtype": "markdown",
            "markdown": {
                "content": full_message
            }
        }
        
        logger.debug(f"å‘é€Markdownæ¶ˆæ¯åˆ°ä¼ä¸šå¾®ä¿¡: {message[:100]}...")
        response = requests.post(webhook, json=payload, timeout=_REQUEST_TIMEOUT)  # ä¿®æ”¹ä¸ºä½¿ç”¨_REQUEST_TIMEOUT
        response.raise_for_status()
        result = response.json()
        
        if result.get("errcode") == 0:
            logger.info("å¾®ä¿¡Markdownæ¶ˆæ¯å‘é€æˆåŠŸ")
            return True
        else:
            error_msg = result.get('errmsg', 'æœªçŸ¥é”™è¯¯')
            logger.error(f"å¾®ä¿¡Markdownæ¶ˆæ¯å‘é€å¤±è´¥: {error_msg}")
            return False
            
    except Exception as e:
        logger.error(f"å‘é€å¾®ä¿¡Markdownæ¶ˆæ¯æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}", exc_info=True)
        return False

def send_task_completion_notification(task: str, result: Dict[str, Any]):
    """
    å‘é€ä»»åŠ¡å®Œæˆé€šçŸ¥åˆ°ä¼ä¸šå¾®ä¿¡
    
    Args:
        task: ä»»åŠ¡åç§°
        result: ä»»åŠ¡æ‰§è¡Œç»“æœ
    """
    try:
        if result["status"] == "success":
            status_emoji = "âœ…"
            status_msg = "æˆåŠŸ"
        elif result["status"] == "skipped":
            status_emoji = "â­ï¸"
            status_msg = "å·²è·³è¿‡"
        else:
            status_emoji = "âŒ"
            status_msg = "å¤±è´¥"
        
        # æ„å»ºä»»åŠ¡æ€»ç»“æ¶ˆæ¯
        summary_msg = (
            f"ã€ä»»åŠ¡æ‰§è¡Œã€‘{task}\n\n"
            f"{status_emoji} **çŠ¶æ€**: {status_msg}\n"
            f"ğŸ“ **è¯¦æƒ…**: {result.get('message', 'æ— è¯¦ç»†ä¿¡æ¯')}\n"
        )
        
        # æ·»åŠ ä»»åŠ¡ç‰¹å®šä¿¡æ¯
        if task == "update_etf_list" and result["status"] == "success":
            # ä»æ¶ˆæ¯ä¸­æå–ETFæ•°é‡ï¼ˆæ ¼å¼ï¼š"å…¨å¸‚åœºETFåˆ—è¡¨æ›´æ–°å®Œæˆï¼Œå…±XXXåª"ï¼‰
            count = 0
            message = result.get('message', '')
            if "å…±" in message and "åª" in message:
                try:
                    count = int(message.split("å…±")[1].split("åª")[0])
                except:
                    pass
            summary_msg += f"ğŸ“Š **ETFæ•°é‡**: {count}åª\n"
            
            # æ·»åŠ æ•°æ®æ¥æºä¿¡æ¯
            source = result.get('source', 'æœªçŸ¥')
            summary_msg += f"æ¥æº: {source}\n"
            
            # æ·»åŠ åˆ—è¡¨æœ‰æ•ˆæœŸä¿¡æ¯
            try:
                file_path = Config.ALL_ETFS_PATH
                if os.path.exists(file_path):
                    last_modified = datetime.fromtimestamp(os.path.getmtime(file_path))
                    expiration = last_modified + timedelta(days=Config.ETF_LIST_UPDATE_INTERVAL)
                    summary_msg += f"ğŸ“… **ç”Ÿæˆæ—¶é—´**: {last_modified.strftime('%Y-%m-%d %H:%M')}\n"
                    summary_msg += f"â³ **è¿‡æœŸæ—¶é—´**: {expiration.strftime('%Y-%m-%d %H:%M')}\n"
            except Exception as e:
                logger.error(f"è·å–ETFåˆ—è¡¨æ–‡ä»¶ä¿¡æ¯å¤±è´¥: {str(e)}")
                summary_msg += "ğŸ“… **åˆ—è¡¨æœ‰æ•ˆæœŸä¿¡æ¯**: è·å–å¤±è´¥\n"
        
        elif task == "crawl_etf_daily" and result["status"] == "success":
            summary_msg += "ğŸ“ˆ **æ•°æ®çˆ¬å–**: å®Œæˆ\n"
            
        elif task == "calculate_arbitrage" and result["status"] == "success":
            summary_msg += "ğŸ” **å¥—åˆ©æœºä¼š**: å·²æ¨é€\n"
            
        elif task == "calculate_position" and result["status"] == "success":
            summary_msg += "ğŸ’¼ **ä»“ä½ç­–ç•¥**: å·²æ¨é€\n"
        
        # å‘é€ä»»åŠ¡æ€»ç»“é€šçŸ¥ï¼ˆä½¿ç”¨taskç±»å‹ï¼‰
        send_wechat_message(summary_msg, message_type="task")
        logger.info(f"å·²å‘é€ä»»åŠ¡å®Œæˆé€šçŸ¥: {task} - {status_msg}")
        
    except Exception as e:
        logger.error(f"å‘é€ä»»åŠ¡å®Œæˆé€šçŸ¥å¤±è´¥: {str(e)}", exc_info=True)

def test_webhook_connection(webhook: Optional[str] = None) -> bool:
    """
    æµ‹è¯•ä¼ä¸šå¾®ä¿¡Webhookè¿æ¥æ˜¯å¦æ­£å¸¸
    
    Args:
        webhook: ä¼ä¸šå¾®ä¿¡Webhookåœ°å€
        
    Returns:
        bool: è¿æ¥æ˜¯å¦æ­£å¸¸
    """
    try:
        if webhook is None:
            webhook = os.getenv("WECOM_WEBHOOK", Config.WECOM_WEBHOOK)
        
        if not webhook:
            logger.error("ä¼ä¸šå¾®ä¿¡Webhookæœªé…ç½®")
            return False
        
        # è·å–å½“å‰åŒæ—¶åŒºæ—¶é—´
        utc_now, beijing_now = get_current_times()
        
        # å‘é€æµ‹è¯•æ¶ˆæ¯
        test_message = (
            "âœ… **ã€æµ‹è¯•æ¶ˆæ¯ã€‘**\n\n"
            "**çŠ¶æ€**: ä¼ä¸šå¾®ä¿¡Webhookè¿æ¥æµ‹è¯•æˆåŠŸ\n"
            f"**ğŸ“…æµ‹è¯•æ—¶é—´**: {beijing_now.strftime('%Y-%m-%d %H:%M:%S')}ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰\n\n"
            "\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
            f"ğŸ•’ **UTCæ—¶é—´**: {utc_now.strftime('%Y-%m-%d %H:%M:%S')}\n"
            f"ğŸ“… **åŒ—äº¬æ—¶é—´**: {beijing_now.strftime('%Y-%m-%d %H:%M:%S')}\n"
            "\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n"
            f"ğŸ”— æ¶ˆæ¯æ¥æºã€GITï¼šfish-etfã€‘\n"
        )
        
        logger.info("å¼€å§‹æµ‹è¯•Webhookè¿æ¥")
        success = send_wechat_message(test_message, message_type="default", webhook=webhook)
        
        if success:
            logger.info("Webhookè¿æ¥æµ‹è¯•æˆåŠŸ")
        else:
            logger.error("Webhookè¿æ¥æµ‹è¯•å¤±è´¥")
        
        return success
        
    except Exception as e:
        logger.error(f"æµ‹è¯•Webhookè¿æ¥æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}", exc_info=True)
        return False

# æ¨¡å—åˆå§‹åŒ–
try:
    # ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨
    Config.init_dirs()
    
    # åˆå§‹åŒ–é”™è¯¯ç¼“å­˜
    _error_message_cache = {}
    
    # æ¸…ç†è¿‡æœŸçš„é”™è¯¯æ¶ˆæ¯ç¼“å­˜ï¼ˆæ¯å¤©æ¸…ç†ä¸€æ¬¡ï¼‰
    def _cleanup_error_cache():
        current_time = time.time()
        expired_keys = []
        for msg, timestamp in _error_message_cache.items():
            if current_time - timestamp > 86400:  # 24å°æ—¶
                expired_keys.append(msg)
        
        for key in expired_keys:
            del _error_message_cache[key]
        
        if expired_keys:
            logger.debug(f"æ¸…ç†äº† {len(expired_keys)} æ¡è¿‡æœŸçš„é”™è¯¯æ¶ˆæ¯ç¼“å­˜")
    
    # å®šæœŸæ¸…ç†ç¼“å­˜
    import threading
    def _cache_cleanup_thread():
        while True:
            time.sleep(3600)  # æ¯å°æ—¶æ¸…ç†ä¸€æ¬¡
            _cleanup_error_cache()
    
    cleanup_thread = threading.Thread(target=_cache_cleanup_thread, daemon=True)
    cleanup_thread.start()
    
    # åˆå§‹åŒ–æ—¥å¿—
    logger.info("å¾®ä¿¡æ¨é€æ¨¡å—åˆå§‹åŒ–å®Œæˆ")
    
    # æµ‹è¯•Webhookè¿æ¥ï¼ˆä»…åœ¨è°ƒè¯•æ¨¡å¼ä¸‹ï¼‰
    if os.getenv("DEBUG", "").lower() in ("true", "1", "yes"):
        logger.info("è°ƒè¯•æ¨¡å¼å¯ç”¨ï¼Œæµ‹è¯•Webhookè¿æ¥")
        test_webhook_connection()
except Exception as e:
    logger.error(f"å¾®ä¿¡æ¨é€æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {str(e)}", exc_info=True)
    
    try:
        # é€€å›åˆ°åŸºç¡€æ—¥å¿—é…ç½®
        logging.basicConfig(
            level="INFO",
            format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
            handlers=[logging.StreamHandler()]
        )
        logging.error(f"å¾®ä¿¡æ¨é€æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {str(e)}")
    except Exception as basic_log_error:
        print(f"åŸºç¡€æ—¥å¿—é…ç½®å¤±è´¥: {str(basic_log_error)}")
        print(f"å¾®ä¿¡æ¨é€æ¨¡å—åˆå§‹åŒ–å¤±è´¥: {str(e)}")
